{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "from rouge import Rouge, FilesRouge\n",
    "from torchnlp._third_party.lazy_loader import LazyLoader\n",
    "from torchnlp.metrics import get_moses_multi_bleu\n",
    "\n",
    "def full_moses_multi_bleu(original, generation):\n",
    "    '''\n",
    "    Note: need to add space before punctuations\n",
    "    :original: string\n",
    "    :generation: string\n",
    "    '''\n",
    "    filereference = '../../to_gpt2/generation_ori.txt'\n",
    "    filehypothesis = '../../to_gpt2/generation_gen.txt'\n",
    "    save(filereference, original ,overwrite = True, print_ = False)\n",
    "    save(filehypothesis, generation ,overwrite = True, print_ = False)\n",
    "\n",
    "    bleu_cmd = ['perl', 'multi-bleu.perl', filehypothesis]\n",
    "    with open(filereference, \"r\") as read_pred:\n",
    "        bleu_out = subprocess.check_output(bleu_cmd, stdin=read_pred, stderr=subprocess.STDOUT)\n",
    "        bleu_out = bleu_out.decode(\"utf-8\")\n",
    "        \n",
    "        \n",
    "        BLEU = re.search(r\"BLEU = (.+?),\", bleu_out).group(1)\n",
    "        bleu_out = bleu_out.split(', ')\n",
    "        B1, B2, B3, B4, BP = bleu_out[-4].replace(' (BP=', '/').split('/')\n",
    "        ratio = bleu_out[-3].replace('ratio=', '')\n",
    "        hyp_len=bleu_out[-2].replace('hyp_len=', '')\n",
    "        ref_len=bleu_out[-1].replace('ref_len=', '').replace(')\\n', '')\n",
    "\n",
    "        ans = {'BLEU': BLEU, \n",
    "               'B1': B1, 'B2':B2, 'B3':B3, 'B4':B4, 'BP': BP, \n",
    "               'ratio':ratio, 'hyp_len': hyp_len, 'ref_len':ref_len}\n",
    "        ans = {i: float(v) for i, v in ans.items()}\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dependency import parent_dir\n",
    "from common.basics import *\n",
    "from common.save import save_pickle, load_pickle, save\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.evaluation import evaluation\n",
    "from utils.metrics import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "database = load_pickle('../big_data/database.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ev(evaluation):\n",
    "    \"\"\" load the generation results and ground truth, then calculate the specified metrics \"\"\"\n",
    "    def __init__(self, filename, tag):\n",
    "        '''\n",
    "        Args:\n",
    "          filename: A directory to the files\n",
    "          tag: A name we assign to the directory, can be any string\n",
    "        \n",
    "        '''\n",
    "        self.dic = self.load_dic({}, filename, tag)\n",
    "        self.ori = tag\n",
    "        self.gens = []\n",
    "        self.sp = spacy.load('en_core_web_lg')\n",
    "        self.rouge = Rouge()\n",
    "        self.filesrouge = FilesRouge()\n",
    "\n",
    "    def ingr_f1(self, root = True):\n",
    "        value, number = [], []\n",
    "        for i, v in tqdm.tqdm(self.dic.items()):\n",
    "            true, pred = v['%s_ingr'%(self.ori)], v['%s_ingr'%(self.gen)]\n",
    "            if root:\n",
    "                true, pred = self.ingr(true), self.ingr(pred)\n",
    "            scores = metrics(true, pred)\n",
    "            value.append(scores.f1())\n",
    "            number.append(len(set(pred)))\n",
    "        avg = sum(value)/len(value)\n",
    "        return {'ingredient_f1':avg, 'average ingr number':sum(number)/len(number) } \n",
    "        \n",
    "    def jaccard(self, generate = 'ingr'):\n",
    "        assert generate in ['ingr','instr','human']\n",
    "        jaccard = []\n",
    "        for i, v in tqdm.tqdm(self.dic.items()):\n",
    "            if generate == 'ingr':\n",
    "                true, pred = v['%s_ingr'%(self.ori)], v['%s_ingr'%(self.gen)]\n",
    "                true, pred = self.ingr(true), self.ingr(pred)\n",
    "            elif generate == 'instr':\n",
    "                true, pred = v['%s_ingr'%(self.ori)], v['%s_instr'%(self.gen)]\n",
    "                true, pred = self.ingr(true), self.instr(pred)\n",
    "            elif generate == 'human':   \n",
    "                true, pred = v['%s_ingr'%(self.ori)], v['%s_instr'%(self.ori)]\n",
    "                true, pred = self.ingr(true), self.instr(pred)\n",
    "            true, pred = set(true), set(pred)\n",
    "            \n",
    "            intersect = len(true & pred)\n",
    "            similarity = intersect /(len(true)+len(pred) - intersect)\n",
    "            jaccard.append(similarity)\n",
    "    \n",
    "        return {generate: sum(jaccard)/len(jaccard)}\n",
    "    \n",
    "    def instr(self, directions):\n",
    "        instr = self.sp(directions)\n",
    "        root_instr = []\n",
    "        for chunk in instr.noun_chunks:\n",
    "            idx_rootnoun = chunk.end - 1\n",
    "            str_rootnoun = instr[idx_rootnoun].lemma_\n",
    "            if str_rootnoun in database:\n",
    "                root_instr.append(str_rootnoun)\n",
    "        return root_instr\n",
    "    \n",
    "    def ingr(self, lst):\n",
    "        '''\n",
    "        Args: lst: a list of ingredient names\n",
    "        used when len(lst) must equal to root_match\n",
    "        '''\n",
    "        hl = [[{'text':x, 'highlight': None} for x in i.split(' ')] for i in lst]\n",
    "        root_match = []\n",
    "        for i, ingr in enumerate(lst):\n",
    "            if ' ' not in ingr:\n",
    "                hl[i][0]['highlight'] = 'wrong'\n",
    "                doc = self.sp(ingr)\n",
    "                root_match.append(doc[0].lemma_)\n",
    "            else:\n",
    "                phrase = 'Mix the %s and water.'%ingr\n",
    "                doc = self.sp(phrase)\n",
    "                \n",
    "                last_chunk = None\n",
    "                for chunk in doc.noun_chunks:\n",
    "                    if chunk.text != 'water':\n",
    "                        last_chunk = chunk\n",
    "                if not last_chunk:\n",
    "                    root_match.append('CANNOT_DETECT')\n",
    "                else:\n",
    "                    found = False\n",
    "                    for j, word in enumerate(hl[i]):\n",
    "                        if doc[last_chunk.end - 1].text in word['text']:\n",
    "                            hl[i][j]['highlight'] = 'wrong' \n",
    "                            root_match.append(doc[last_chunk.end - 1].lemma_)\n",
    "                            found = True\n",
    "                            break\n",
    "                    if not found:\n",
    "                        root_match.append('CANNOT_DETECT')\n",
    "                        \n",
    "        assert len(root_match) == len(lst)\n",
    "        return root_match\n",
    "\n",
    "    \n",
    "    def to_bleu(self):\n",
    "        to_write = {'%s_i'%(self.ori):'',\n",
    "                    '%s_i'%(self.gen):'',\n",
    "                    '%s_d'%(self.ori):'',\n",
    "                    '%s_d'%(self.gen):''}\n",
    "        \n",
    "        for i, v in self.dic.items():\n",
    "            to_write['%s_i'%(self.ori)] += self.add_space(' $ '.join(v['%s_ingr'%(self.ori)]))+ ' $ \\n'\n",
    "            to_write['%s_i'%(self.gen)] += self.add_space(' $ '.join(v['%s_ingr'%(self.gen)])) + ' $ \\n'\n",
    "            \n",
    "            to_write['%s_d'%(self.ori)] += self.add_space(v['%s_instr'%(self.ori)])+ '\\n'\n",
    "            to_write['%s_d'%(self.gen)] += self.add_space(v['%s_instr'%(self.gen)])+ '\\n'\n",
    "        \n",
    "        for k, v in to_write.items():\n",
    "            save('../../to_gpt2/generation_%s.txt'%(k), v ,overwrite = True)\n",
    "        !eval {\"perl multi-bleu.perl ../../to_gpt2/generation_%s_i.txt < ../../to_gpt2/generation_%s_i.txt\" %(self.ori, self.gen)}\n",
    "        !eval {\"perl multi-bleu.perl ../../to_gpt2/generation_%s_d.txt < ../../to_gpt2/generation_%s_d.txt\" %(self.ori, self.gen)}\n",
    "    \n",
    "        !eval {\"rouge -f ../../to_gpt2/generation_%s_i.txt ../../to_gpt2/generation_%s_i.txt --avg\"%(self.ori, self.gen)}\n",
    "        !eval {\"rouge -f ../../to_gpt2/generation_%s_d.txt ../../to_gpt2/generation_%s_d.txt --avg\"%(self.ori, self.gen)}\n",
    "        \n",
    "        print()\n",
    "        \n",
    "    def full_bleu(self):\n",
    "        ori, gen = '',''\n",
    "        for i, v in self.dic.items():            \n",
    "            ori += self.add_space(v['%s_instr'%(self.ori)])+ '\\n'\n",
    "            gen += self.add_space(v['%s_instr'%(self.gen)])+ '\\n'\n",
    "        ans = full_moses_multi_bleu(gen, ori)\n",
    "        \n",
    "        filehypothesis = '../../to_gpt2/generation_gen.txt'        \n",
    "        filereference = '../../to_gpt2/generation_ori.txt'\n",
    "        scores = self.filesrouge.get_scores(filehypothesis, filereference, avg = True)\n",
    "        ans.update({'R-L': scores['rouge-l']['f']})\n",
    "        return ans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table 1a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load ../../to_gpt2/recipe1M_1218/val/y/\n",
      "load ../../to_gpt2/val/generation_1220_k1_val/\n",
      "load ../../to_gpt2/val/generation_1220_k3_val/\n",
      "load ../../to_gpt2/val/generation_1220_k5_val/\n",
      "load ../../to_gpt2/val/generation_1220_k10_val/\n",
      "load ../../to_gpt2/val/generation_1220_k30_val/\n",
      "k1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4000/4000 [10:22<00:00,  6.43it/s]\n",
      "100%|██████████| 4000/4000 [24:19<00:00,  2.74it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4000/4000 [10:34<00:00,  6.30it/s]\n",
      "100%|██████████| 4000/4000 [25:21<00:00,  2.63it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 397/4000 [01:02<09:46,  6.14it/s]"
     ]
    }
   ],
   "source": [
    "data = ev('../../to_gpt2/recipe1M_1218/val/y/', 'ori')\n",
    "data.append_dic('../../to_gpt2/val/generation_1220_k1_val/', 'k1')\n",
    "data.append_dic('../../to_gpt2/val/generation_1220_k3_val/', 'k3')\n",
    "data.append_dic('../../to_gpt2/val/generation_1220_k5_val/', 'k5')\n",
    "data.append_dic('../../to_gpt2/val/generation_1220_k10_val/', 'k10')\n",
    "data.append_dic('../../to_gpt2/val/generation_1220_k30_val/', 'k30')\n",
    "results = {}\n",
    "for tag in data.gens:\n",
    "    print(tag)\n",
    "    data.gen = tag\n",
    "    ans = data.full_bleu()\n",
    "    ans.update(data.ingr_f1(root=True))\n",
    "    ans.update(data.instr_tree(stem_only = False))\n",
    "    results[tag] = ans\n",
    "display(pd.DataFrame(results).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table 1b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ev('../../to_gpt2/recipe1M_1218/test/y/', 'ori')\n",
    "data.append_dic('../../to_gpt2/generation_1220_k3_test/', '117M')\n",
    "data.append_dic('../../to_gpt2/generation_scratch_k3_test/', 'scratch')\n",
    "data.append_dic('../../to_gpt2/generation_medium_k3_test/', '345M')\n",
    "results = {}\n",
    "for tag in data.gens:\n",
    "    print(tag)\n",
    "    data.gen = tag\n",
    "    ans = data.full_bleu()\n",
    "    ans.update(data.ingr_f1(root=True))\n",
    "    ans.update(data.instr_tree(stem_only = False))\n",
    "    results[tag] = ans\n",
    "display(pd.DataFrame(results).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jaccard similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ev('../../to_gpt2/recipe1M_1218/test/y/', 'ori')\n",
    "data.append_dic('../../to_gpt2/generation_1220_k3_test/', '117M')\n",
    "results = {}\n",
    "for tag in data.gens:\n",
    "    print(tag)\n",
    "    data.gen = tag\n",
    "    ans = data.jaccard(generate = 'ingr')\n",
    "    ans.update(data.jaccard(generate = 'instr'))\n",
    "    ans.update(data.jaccard(generate = 'human'))\n",
    "    results[tag] = ans\n",
    "display(pd.DataFrame(results).T)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
