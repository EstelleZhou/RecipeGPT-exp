{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 5.72 µs\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "%load_ext autotime\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 22.8 s\n"
     ]
    }
   ],
   "source": [
    "# typically takes 30 secs\n",
    "from metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1992"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 55.9 ms\n"
     ]
    }
   ],
   "source": [
    "database = load_pickle('../big_data/database3.pickle')\n",
    "len(database)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 48.7 ms\n"
     ]
    }
   ],
   "source": [
    "class ev(evaluation):\n",
    "    def __init__(self, filename, tag):\n",
    "        self.dic = self.load_dic({}, filename, tag)\n",
    "        self.ori = tag\n",
    "        self.gens = []\n",
    "\n",
    "    def ingr_f1(self, root = True):\n",
    "        value, number = [], []\n",
    "        for i, v in tqdm.tqdm(self.dic.items()):\n",
    "            true, pred = v['%s_ingr'%(self.ori)], v['%s_ingr'%(self.gen)]\n",
    "            if root:\n",
    "                true, pred = self.ingr(true), self.ingr(pred)\n",
    "            scores = metrics(true, pred)\n",
    "            value.append(scores.f1())\n",
    "            number.append(len(set(pred)))\n",
    "        avg = sum(value)/len(value)\n",
    "        print(avg)\n",
    "        print('average ingr number', sum(number)/len(number))\n",
    "        return avg\n",
    "    \n",
    "    def ingr_precision_recall(self, generate = 'ingr'):\n",
    "        assert generate in ['ingr','instr','human']\n",
    "        precision, recall = [], []\n",
    "        for i, v in tqdm.tqdm(self.dic.items()):\n",
    "            if generate == 'ingr':\n",
    "                true, pred = v['%s_ingr'%(self.ori)], v['%s_ingr'%(self.gen)]\n",
    "                true, pred = self.ingr(true), self.ingr(pred)\n",
    "            elif generate == 'instr':\n",
    "                true, pred = v['%s_ingr'%(self.ori)], v['%s_instr'%(self.gen)]\n",
    "                true, pred = self.ingr(true), self.instr(pred)\n",
    "            elif generate == 'human':   \n",
    "                true, pred = v['%s_ingr'%(self.ori)], v['%s_instr'%(self.ori)]\n",
    "                true, pred = self.ingr(true), self.instr(pred)\n",
    "            scores = metrics(true, pred)\n",
    "            precision.append(scores.precision())\n",
    "            recall.append(scores.recall())\n",
    "    \n",
    "        print('precision', sum(precision)/len(precision))\n",
    "        print('recall', sum(recall)/len(recall))\n",
    "        \n",
    "        \n",
    "    def jaccard(self, generate = 'ingr'):\n",
    "        assert generate in ['ingr','instr','human']\n",
    "        jaccard = []\n",
    "        for i, v in tqdm.tqdm(self.dic.items()):\n",
    "            if generate == 'ingr':\n",
    "                true, pred = v['%s_ingr'%(self.ori)], v['%s_ingr'%(self.gen)]\n",
    "                true, pred = self.ingr(true), self.ingr(pred)\n",
    "            elif generate == 'instr':\n",
    "                true, pred = v['%s_ingr'%(self.ori)], v['%s_instr'%(self.gen)]\n",
    "                true, pred = self.ingr(true), self.instr(pred)\n",
    "            elif generate == 'human':   \n",
    "                true, pred = v['%s_ingr'%(self.ori)], v['%s_instr'%(self.ori)]\n",
    "                true, pred = self.ingr(true), self.instr(pred)\n",
    "            true, pred = set(true), set(pred)\n",
    "            \n",
    "            intersect = len(true & pred)\n",
    "            similarity = intersect /(len(true)+len(pred) - intersect)\n",
    "            jaccard.append(similarity)\n",
    "    \n",
    "        print('jaccard', sum(jaccard)/len(jaccard))\n",
    "    \n",
    "    def instr(self, directions):\n",
    "        instr = sp.spacy(directions)\n",
    "        root_instr = []\n",
    "        for chunk in instr.noun_chunks:\n",
    "            idx_rootnoun = chunk.end - 1\n",
    "            str_rootnoun = instr[idx_rootnoun].lemma_\n",
    "            if str_rootnoun in database:\n",
    "                root_instr.append(str_rootnoun)\n",
    "        return root_instr\n",
    "    \n",
    "    def ingr(self, lst):\n",
    "        '''\n",
    "        Args: lst: a list of ingredient names\n",
    "        used when len(lst) must equal to root_match\n",
    "        '''\n",
    "        hl = [[{'text':x, 'highlight': None} for x in i.split(' ')] for i in lst]\n",
    "        root_match = []\n",
    "        for i, ingr in enumerate(lst):\n",
    "            if ' ' not in ingr:\n",
    "                hl[i][0]['highlight'] = 'wrong'\n",
    "                doc = sp.spacy(ingr)\n",
    "                root_match.append(doc[0].lemma_)\n",
    "            else:\n",
    "                phrase = 'Mix the %s and water.'%ingr\n",
    "                doc = sp.spacy(phrase)\n",
    "                \n",
    "                last_chunk = None\n",
    "                for chunk in doc.noun_chunks:\n",
    "                    if chunk.text != 'water':\n",
    "                        last_chunk = chunk\n",
    "                if not last_chunk:\n",
    "                    root_match.append('CANNOT_DETECT')\n",
    "                else:\n",
    "                    found = False\n",
    "                    for j, word in enumerate(hl[i]):\n",
    "                        if doc[last_chunk.end - 1].text in word['text']:\n",
    "                            hl[i][j]['highlight'] = 'wrong' \n",
    "                            root_match.append(doc[last_chunk.end - 1].lemma_)\n",
    "                            found = True\n",
    "                            break\n",
    "                    if not found:\n",
    "                        root_match.append('CANNOT_DETECT')\n",
    "                        \n",
    "        assert len(root_match) == len(lst)\n",
    "        return root_match\n",
    "\n",
    "    '''\n",
    "    exporting data\n",
    "    '''\n",
    "    def to_bleu(self):\n",
    "        to_write = {'%s_i'%(self.ori):'',\n",
    "                    '%s_i'%(self.gen):'',\n",
    "                    '%s_d'%(self.ori):'',\n",
    "                    '%s_d'%(self.gen):''}\n",
    "        \n",
    "        for i, v in self.dic.items():\n",
    "            to_write['%s_i'%(self.ori)] += self.add_space(' $ '.join(v['%s_ingr'%(self.ori)]))+ ' $ \\n'\n",
    "            to_write['%s_i'%(self.gen)] += self.add_space(' $ '.join(v['%s_ingr'%(self.gen)])) + ' $ \\n'\n",
    "            \n",
    "            to_write['%s_d'%(self.ori)] += self.add_space(v['%s_instr'%(self.ori)])+ '\\n'\n",
    "            to_write['%s_d'%(self.gen)] += self.add_space(v['%s_instr'%(self.gen)])+ '\\n'\n",
    "        \n",
    "        for k, v in to_write.items():\n",
    "            save('../../to_gpt2/generation_%s.txt'%(k), v ,overwrite = True)\n",
    "        !eval {\"perl multi-bleu.perl ../../to_gpt2/generation_%s_i.txt < ../../to_gpt2/generation_%s_i.txt\" %(self.ori, self.gen)}\n",
    "        !eval {\"perl multi-bleu.perl ../../to_gpt2/generation_%s_d.txt < ../../to_gpt2/generation_%s_d.txt\" %(self.ori, self.gen)}\n",
    "    \n",
    "        !eval {\"rouge -f ../../to_gpt2/generation_%s_i.txt ../../to_gpt2/generation_%s_i.txt --avg\"%(self.ori, self.gen)}\n",
    "        !eval {\"rouge -f ../../to_gpt2/generation_%s_d.txt ../../to_gpt2/generation_%s_d.txt --avg\"%(self.ori, self.gen)}\n",
    "        \n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table 1a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load ../../to_gpt2/recipe1M_1218/val/y/\n",
      "load ../../to_gpt2/val/generation_1220_k1_val/\n",
      "load ../../to_gpt2/val/generation_1220_k3_val/\n",
      "load ../../to_gpt2/val/generation_1220_k5_val/\n",
      "load ../../to_gpt2/val/generation_1220_k10_val/\n",
      "load ../../to_gpt2/val/generation_1220_k30_val/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/4000 [00:00<11:54,  5.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4000/4000 [10:38<00:00,  7.51it/s]\n",
      "  0%|          | 1/4000 [00:00<10:04,  6.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7852302818896786\n",
      "average ingr number 7.62425\n",
      "k3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 1614/4000 [04:20<07:05,  5.61it/s]"
     ]
    }
   ],
   "source": [
    "data = ev('../../to_gpt2/recipe1M_1218/val/y/', 'ori')\n",
    "data.append_dic('../../to_gpt2/val/generation_1220_k1_val/', 'k1')\n",
    "data.append_dic('../../to_gpt2/val/generation_1220_k3_val/', 'k3')\n",
    "data.append_dic('../../to_gpt2/val/generation_1220_k5_val/', 'k5')\n",
    "data.append_dic('../../to_gpt2/val/generation_1220_k10_val/', 'k10')\n",
    "data.append_dic('../../to_gpt2/val/generation_1220_k30_val/', 'k30')\n",
    "for tag in data.gens:\n",
    "    print(tag)\n",
    "    data.gen = tag\n",
    "    data.ingr_f1(root=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tag in data.gens:\n",
    "    print(tag)\n",
    "    data.gen = tag\n",
    "    data.to_bleu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tag in data.gens:\n",
    "    print(tag)\n",
    "    data.gen = tag\n",
    "    data.instr_tree(stem_only = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table 1b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ev('../../to_gpt2/recipe1M_1218/test/y/', 'ori')\n",
    "data.append_dic('../../to_gpt2/generation_1220_k3_test/', '117M')\n",
    "data.append_dic('../../to_gpt2/generation_scratch_k3_test/', 'scratch')\n",
    "data.append_dic('../../to_gpt2/generation_medium_k3_test/', '345M')\n",
    "for tag in data.gens:\n",
    "    print(tag)\n",
    "    data.gen = tag\n",
    "    data.ingr_f1(root=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tag in data.gens:\n",
    "    print(tag)\n",
    "    data.gen = tag\n",
    "    data.to_bleu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tag in data.gens:\n",
    "    print(tag)\n",
    "    data.gen = tag\n",
    "    data.instr_tree(stem_only = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jaccard similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ev('../../to_gpt2/recipe1M_1218/test/y/', 'ori')\n",
    "data.append_dic('../../to_gpt2/generation_1220_k3_test/', '117M')\n",
    "data.jaccard(generate = 'ingr')\n",
    "data.jaccard(generate = 'instr')\n",
    "data.jaccard(generate = 'human')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
