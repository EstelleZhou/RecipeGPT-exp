{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "import os, tqdm, sys\n",
    "parent_dir = os.path.abspath(os.getcwd()+'/..')+'/'\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "def load_pickle(filename):\n",
    "    with open(filename, 'rb') as gfp:\n",
    "        r = pickle.load(gfp)\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# typically takes 30 secs\n",
    "from metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../big_data/food_taxonomy.txt', delimiter='\\t', header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "origin: length of data: 4294\n",
      "drop some fields: length of data: 2682\n",
      "drop duplicates: length of data: 2582\n"
     ]
    }
   ],
   "source": [
    "def cleaning(df):\n",
    "    '''\n",
    "    eliminate the row if it contains the following non-ingredient words\n",
    "    '''\n",
    "    print('origin: length of data: %d' % len(df))\n",
    "    eliminate = ['Snack brand', 'Preparation', 'Fast food', 'Dietary Supplement', 'Dessert']\n",
    "    for i in range(2):\n",
    "        df  = df[df.apply(lambda x: x[i] not in eliminate, axis = 1)]\n",
    "    # uncased\n",
    "    for i in range(3):\n",
    "        df[i]  = df.apply(lambda x: x[i].lower(), axis = 1)\n",
    "    print('drop some fields: length of data: %d' % len(df))    \n",
    "    \n",
    "    # drop the duplicates\n",
    "    df = df[~df[2].duplicated()]\n",
    "    df = df.reset_index(drop = True)\n",
    "    print('drop duplicates: length of data: %d' % len(df))\n",
    "        \n",
    "    return df\n",
    "df = cleaning(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before processing: length of data: 2582\n",
      "add some rows: length of data: 2685\n",
      "drop duplicates: length of data: 2684\n"
     ]
    }
   ],
   "source": [
    "# firstly, we notice salvador identified several useful ingredients that are not found in our taxnomy\n",
    "# then, we selected those words based on frequency and manually add words to our taxnomy\n",
    "additional_ingr=\\\n",
    "[\n",
    "['Condiment', 'Sweet', 'sugar'],\n",
    "['Condiment', 'Sweet', 'applesauce'],\n",
    "['Flour', 'Flour','flour'],\n",
    "['Baking powder','Baking powder','baking powder'],\n",
    "['Water','Water','water'],\n",
    "['Water','Water','iced'],\n",
    "['Water','Water','ice'],\n",
    "['Herb and spice','spices','jalapeno'],\n",
    "['Condiment','Condiment', 'oil'],\n",
    "['Beverage','Fruit juice', 'juice'],\n",
    "['Staple','Maize','enchilada'],\n",
    "['Condiment','Condiment', 'dressing mix'],\n",
    "['Condiment','Condiment', 'cheese mix'],\n",
    "['Baking powder','Baking powder','baking soda'],\n",
    "['Condiment','Condiment', 'dry mix'],\n",
    "['Condiment','Condiment','chocolate'],\n",
    "['Vegetable','Bulb and stem vegetables','tapioca'],\n",
    "['Flour', 'Flour','xanthan gum'],\n",
    "['Flour', 'Flour','starch'],\n",
    "['Egg and dairy', 'Dairy product','buttermilk'],\n",
    "['Condiment','Condiment','chili'],\n",
    "['Condiment','Condiment','chile'],\n",
    "['Condiment','Condiment','chilis'],\n",
    "['Condiment','Condiment','chiles'],\n",
    "['Condiment','Condiment','chilies'],\n",
    "['Flour', 'Flour','corn muffin mix'],\n",
    "['Beverage','Chocolate','chocolate mix'],\n",
    "['Meat','dumpling','dumpling'],\n",
    "['Meat','dumpling','wonton'],\n",
    "['Staple','Wheat','pizza dough'],\n",
    "['Staple','Wheat','dough'],\n",
    "['Condiment','Condiment', 'pizza sauce'],\n",
    "['Flour', 'Flour','yeast'],\n",
    "['Condiment','Sweet','cocoa'],\n",
    "['Staple','Maize','chip'],\n",
    "['Egg and dairy','Dairy product','ricotta'],\n",
    "['Condiment','Condiment','seasoning'],\n",
    "['Beverage','Alcohol','sherry'],\n",
    "['Staple','Rice','grain rice'], \n",
    "['Staple','Wheat','shell'],\n",
    "['Meat','Beef','fillet'],\n",
    "['Staple','Maize','cornmeal'],\n",
    "['Condiment','Condiment','seed oil'],\n",
    "['Nut and seed','Other','seed'],\n",
    "['Condiment', 'Sweet', 'sugar blend'],\n",
    "['Soup','Soup','broth'],\n",
    "['Soup','Soup','stock'],\n",
    "['Condiment', 'Sweet', 'marshmallow'],\n",
    "['Condiment', 'Dry Condiment', 'dried vegetable flakes'],\n",
    "['Condiment', 'Dry Condiment', 'dried celery flakes'],\n",
    "['Flour', 'Flour','cornstarch'],\n",
    "['Staple','Wheat','double crust'],\n",
    "['Staple','Wheat','crust'],\n",
    "['Staple','Wheat','pastry crust'],\n",
    "['Egg and dairy','Dairy product','gorgonzola'],\n",
    "['Beverage','juice','drink mix'],\n",
    "['Egg and dairy','Egg','Egg whites'],\n",
    "['Baking powder','Baking powder','baking mix'],\n",
    "['Staple','Rice','brown rice'],\n",
    "['Condiment','Condiment','five spice'],\n",
    "['Meat','Beef','tenderloin'],\n",
    "['Meat','Pork','prosciutto'],\n",
    "['Condiment', 'Sweet', 'whipped topping'],\n",
    "['Condiment', 'Sweet', 'topping'],\n",
    "['Beverage','Alcohol','cider'],\n",
    "['Meat','Shellfish','crabmeat'],\n",
    "['Condiment', 'Sweet', 'candy'],\n",
    "['Condiment', 'Sweet', 'caramel'],\n",
    "['Condiment', 'Sweet', 'molasses'],\n",
    "['Vegetable','Podded vegetables','cannellini'],\n",
    "['Vegetable','Fruits','fruit'],\n",
    "['Staple','Wheat','saltine'],\n",
    "['Condiment','Condiment', 'habanero'],\n",
    "['Beverage','Juice','jell o'],\n",
    "['Beverage','Juice','jelly'],\n",
    "['Beverage','Soft drink','carbonated beverage'],\n",
    "['Egg and dairy','Dairy product','gruyere'],\n",
    "['Vegetable','Leafy and Salad','beet'],\n",
    "['Water','Water','icing'],\n",
    "['Egg and dairy','Dairy product','parmigiano'],\n",
    "['Beverage','Alcohol','liqueur'],\n",
    "['Condiment','Condiment', 'lard'],\n",
    "['Staple','Wheat','crumb'],\n",
    "['Herb and spice','Herb','peppermint'],\n",
    "['Beverage','Alcohol','marsala'],\n",
    "['Side dish','Potatoes','hash brown'],\n",
    "['Meat','Beef','steak'],\n",
    "['Condiment','Condiment','gelatin'],\n",
    "['Meat','Beef','chuck'],\n",
    "['Egg and dairy','Dairy product','colby'],\n",
    "['Condiment', 'Sweet', 'jam'],\n",
    "['Condiment', 'Sweet', 'cool whip'],\n",
    "['Condiment', 'Sweet', 'stevia'],\n",
    "['Staple','Wheat','bran'],\n",
    "['Condiment','Condiment','pimento'],\n",
    "['Condiment','Condiment','food coloring'],\n",
    "['Meat','Meat','rib'],\n",
    "['Condiment','Condiment','shortening'],\n",
    "['Vegetable','Fruits','sweet pickles'],\n",
    "['Condiment', 'Sweet', 'white confectioner'],\n",
    "['Condiment', 'Sweet', 'confectioner'],  \n",
    "['Vegetable','Root and tuberous vegetabless','rhubarb'],\n",
    "['Condiment', 'Condiment', 'cooking spray']\n",
    "]\n",
    "\n",
    "def add_rows(df, additional_ingr):\n",
    "    add = pd.DataFrame(additional_ingr)\n",
    "    print('before processing: length of data: %d' % len(df))\n",
    "    df = pd.concat([df,add]).reset_index(drop =True)\n",
    "\n",
    "    # uncased\n",
    "    for i in range(3):\n",
    "        df[i]  = df.apply(lambda x: x[i].lower().strip(), axis = 1)\n",
    "    print('add some rows: length of data: %d' % len(df))    \n",
    "    \n",
    "    # drop the duplicates\n",
    "    df = df[~df[2].duplicated()]\n",
    "    df = df.reset_index(drop = True)\n",
    "    print('drop duplicates: length of data: %d' % len(df))\n",
    "    return df\n",
    "\n",
    "df = add_rows(df, additional_ingr)\n",
    "\n",
    "\n",
    "unwelcomed_ingr =['salt and pepper', 'muffin']\n",
    "def delete_rows(df, unwelcomed_ingr):\n",
    "    return df[df[2].apply(lambda x: x not in unwelcomed_ingr)]\n",
    "\n",
    "df = delete_rows(df, unwelcomed_ingr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ev(evaluation):\n",
    "    def __init__(self, filename, tag):\n",
    "        self.dic = self.load_dic({}, filename, tag)\n",
    "        self.ori = tag\n",
    "        self.gens = []\n",
    "    \n",
    "    def ingr(self, lst):\n",
    "        '''\n",
    "        Args: lst: a list of ingredient names\n",
    "        used when len(lst) must equal to root_match\n",
    "        '''\n",
    "        hl = [[{'text':x, 'highlight': None} for x in i.split(' ')] for i in lst]\n",
    "        root_match = []\n",
    "        for i, ingr in enumerate(lst):\n",
    "            if ' ' not in ingr:\n",
    "                hl[i][0]['highlight'] = 'wrong'\n",
    "                doc = sp.spacy(ingr)\n",
    "                root_match.append(doc[0].lemma_)\n",
    "            else:\n",
    "                phrase = 'Mix the %s and water.'%ingr\n",
    "                doc = sp.spacy(phrase)\n",
    "                \n",
    "                last_chunk = None\n",
    "                for chunk in doc.noun_chunks:\n",
    "                    if chunk.text != 'water':\n",
    "                        last_chunk = chunk\n",
    "                if not last_chunk:\n",
    "                    root_match.append('CANNOT_DETECT')\n",
    "                else:\n",
    "                    found = False\n",
    "                    for j, word in enumerate(hl[i]):\n",
    "                        if doc[last_chunk.end - 1].text in word['text']:\n",
    "                            hl[i][j]['highlight'] = 'wrong' \n",
    "                            root_match.append(doc[last_chunk.end - 1].lemma_)\n",
    "                            found = True\n",
    "                            break\n",
    "                    if not found:\n",
    "                        root_match.append('CANNOT_DETECT')\n",
    "                        \n",
    "        assert len(root_match) == len(lst)\n",
    "        return root_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load ../../to_gpt2/recipe1M_1218/test/y/\n"
     ]
    }
   ],
   "source": [
    "database = ev('../../to_gpt2/recipe1M_1218/test/y/', 'ori')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-02147e72156c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# takes 1m20s\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdatabase\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mingr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "# takes 1m20s\n",
    "database = data.ingr(df[2].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "database = list(set(database))\n",
    "len(database)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blocklist = ['-PRON-','sheet','boil','time','light','CANNOT_DETECT','cup']\n",
    "database = list(set([word for word in database if word not in blocklist and len(word)>2 ]))\n",
    "print(len(database))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_pickle(obj = database,filename= '../big_data/database.pickle',overwrite =True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
