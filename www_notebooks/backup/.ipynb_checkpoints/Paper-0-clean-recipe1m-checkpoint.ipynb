{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 12.9 Âµs\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "%load_ext autotime\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "# if cannot import the modules, add the parent directory to system path might help\n",
    "\n",
    "import os, tqdm, sys\n",
    "parent_dir = os.path.abspath(os.getcwd()+'/..')+'/'\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "from utils.save import make_dir, save_pickle, load_pickle, save\n",
    "from utils.evaluation import spacy_extension\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import json\n",
    "import tqdm\n",
    "\n",
    "layer1 = json.load(open('/data/yueliu/RecipeAnalytics_201906/raw_data/recipe1M/layer1.json','r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 49010 recipes are from allrecipes.com\n",
      "time: 456 ms\n"
     ]
    }
   ],
   "source": [
    "# data analytics\n",
    "w = [i for i, recipe in enumerate(layer1) if 'allrecipes' in recipe['url']]\n",
    "print(' %d recipes are from allrecipes.com' % len(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 44.2 ms\n"
     ]
    }
   ],
   "source": [
    "def clean_line(line):\n",
    "    '''\n",
    "    Args:\n",
    "        line: a string, such as food name, sentences...\n",
    "    '''\n",
    "    assert type(line) == str\n",
    "    \n",
    "    # all lowercase\n",
    "    line = line.lower()\n",
    "    \n",
    "    # only reserve number and alphabets\n",
    "    line = re.sub(r'[^a-z0-9+()/?!.,]', ' ', line)\n",
    "    \n",
    "    # replace things in brace\n",
    "    line = re.sub(r'\\([^)]*\\)', '', line)\n",
    "    \n",
    "    # remove extra spaces\n",
    "    line = re.sub(' +',' ',line).strip()\n",
    "    return line\n",
    "\n",
    "def preprocessing(layer1):\n",
    "    data = []\n",
    "    for i, recipe in tqdm.tqdm(enumerate(layer1)):\n",
    "        processed_recipe = {'title':clean_line(recipe['title']), \n",
    "                            'id': recipe['id'],\n",
    "                            'ingredients':[],\n",
    "                            'instructions':[]}\n",
    "\n",
    "        field = 'ingredients'\n",
    "        for line in recipe[field]:\n",
    "            cleaned = clean_line(line['text'])\n",
    "            if cleaned:\n",
    "                processed_recipe[field].append(cleaned)  \n",
    "        \n",
    "        field = 'instructions'\n",
    "        cleaned = clean_line(' '.join([line['text'] for line in recipe[field]]))\n",
    "        cleaned = ['%s. '% sent for sent in cleaned.split('. ')] \n",
    "        processed_recipe[field] = cleaned\n",
    "        data.append(processed_recipe)\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1029720it [03:10, 5410.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3min 23s\n"
     ]
    }
   ],
   "source": [
    "data = preprocessing(layer1)\n",
    "save_pickle('../big_data/recipe1M_cleaned.pickle', data, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 54.2 ms\n"
     ]
    }
   ],
   "source": [
    "### STEP3 sent to the NYtimes\n",
    "### assign indices to each ingredient <---> NYtimes\n",
    "class ny_ingredients:\n",
    "    def __init__(self, fields):\n",
    "        # this function will take the global variable ls and dic\n",
    "        # static & reuseable\n",
    "        self.ny_ingred = '../../NYtime-parser2/ingred.txt'\n",
    "        self.ny_result = '../../NYtime-parser2/result.json'\n",
    "        \n",
    "        # spacy\n",
    "        self.fields = fields #['ingredients', 'generated_ingred']\n",
    "        self.sp = spacy_extension()\n",
    "\n",
    "    def to_ny(self):\n",
    "        '''\n",
    "        using global variables data and ls\n",
    "        '''\n",
    "        to_write = []\n",
    "        for i, v in tqdm.tqdm(enumerate(data)):\n",
    "            # assing index\n",
    "            for field in self.fields:\n",
    "                line_ids = []\n",
    "                for line in v[field]:\n",
    "                    if line in to_write:\n",
    "                        ny_id = to_write.index(line)\n",
    "                    else:\n",
    "                        ny_id = len(to_write)\n",
    "                        to_write.append(line)\n",
    "                    line_ids.append(ny_id)\n",
    "                data[i]['ny_%s'%(field)] = line_ids\n",
    "\n",
    "        # save the file to the folder under NYtime-parser2\n",
    "        save(filename = self.ny_ingred, \n",
    "             to_write = '\\n'.join(to_write),\n",
    "             overwrite = True, \n",
    "             print_=True)\n",
    "\n",
    "        self.to_write = to_write\n",
    "\n",
    "    def extract(self, ny_ingred):\n",
    "        '''\n",
    "        Args: ny_ingred: a list of ingredient names\n",
    "        '''\n",
    "        return self.sp.ny_ingred(ny_ingred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1029720it [53:30:52,  2.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved ../../NYtime-parser2/ingred.txt\n",
      "time: 2d 5h 31min 2s\n"
     ]
    }
   ],
   "source": [
    "### start                    \n",
    "ny_ingr = ny_ingredients(fields = ['ingredients'])\n",
    "### step 3-1 save it as ingred.txt\n",
    "ny_ingr.to_ny()\n",
    "### step 3-2 go to python2 and run NLG_notebooks/Control Nytimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1029720it [7:13:44, 39.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 7h 13min 59s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "ny_result = pd.read_json(ny_ingr.ny_result)\n",
    "to_write = []\n",
    "for i, v in tqdm.tqdm(enumerate(data)):\n",
    "    for field in ny_ingr.fields:\n",
    "        temp = [ny_result.loc[ny_id]['name'] for ny_id in v['ny_%s'%(field)]]\n",
    "        exact, root = ny_ingr.extract(temp)\n",
    "        data[i]['ny_full_%s'%(field)] = [ny_result.loc[ny_id].to_dict() for ny_id in v['ny_%s'%(field)]]\n",
    "        data[i]['ny__%s'%(field)] = {'ny':temp, 'exact':exact, 'root':root}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 58.1 s\n"
     ]
    }
   ],
   "source": [
    "save_pickle('../big_data/recipe1M_ny.pickle', data, overwrite=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
