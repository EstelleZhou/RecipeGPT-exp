{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 6.91 µs\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "%load_ext autotime\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 20.6 s\n"
     ]
    }
   ],
   "source": [
    "# typically takes 30 secs\n",
    "from nlp_metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2006\n",
      "1992\n",
      "time: 29.8 ms\n"
     ]
    }
   ],
   "source": [
    "database = load_pickle('../big_data/database2.pickle')\n",
    "print(len(database))\n",
    "\n",
    "blocklist = ['-PRON-','sheet','boil','time','light','CANNOT_DETECT','cup']\n",
    "database = list(set([word for word in database if word not in blocklist and len(word)>2 ]))\n",
    "print(len(database))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 24.7 ms\n"
     ]
    }
   ],
   "source": [
    "save_pickle(obj = database,filename= '../big_data/database3.pickle',overwrite =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 51.2 ms\n"
     ]
    }
   ],
   "source": [
    "class ev(evaluation):\n",
    "    def __init__(self, filename, tag):\n",
    "        self.dic = self.load_dic({}, filename, tag)\n",
    "        self.ori = tag\n",
    "        self.gens = []\n",
    "\n",
    "    def ingr_f1(self, root = True):\n",
    "        value, number = [], []\n",
    "        for i, v in tqdm.tqdm(self.dic.items()):\n",
    "            true, pred = v['%s_ingr'%(self.ori)], v['%s_ingr'%(self.gen)]\n",
    "            if root:\n",
    "                true, pred = self.ingr(true), self.ingr(pred)\n",
    "            scores = metrics(true, pred)\n",
    "            value.append(scores.f1())\n",
    "            number.append(len(set(pred)))\n",
    "        avg = sum(value)/len(value)\n",
    "        print(avg)\n",
    "        print('average ingr number', sum(number)/len(number))\n",
    "        return avg\n",
    "    \n",
    "    def ingr_precision_recall(self, generate = 'ingr'):\n",
    "        assert generate in ['ingr','instr','human']\n",
    "        precision, recall = [], []\n",
    "        for i, v in tqdm.tqdm(self.dic.items()):\n",
    "            if generate == 'ingr':\n",
    "                true, pred = v['%s_ingr'%(self.ori)], v['%s_ingr'%(self.gen)]\n",
    "                true, pred = self.ingr(true), self.ingr(pred)\n",
    "            elif generate == 'instr':\n",
    "                true, pred = v['%s_ingr'%(self.ori)], v['%s_instr'%(self.gen)]\n",
    "                true, pred = self.ingr(true), self.instr(pred)\n",
    "            elif generate == 'human':   \n",
    "                true, pred = v['%s_ingr'%(self.ori)], v['%s_instr'%(self.ori)]\n",
    "                true, pred = self.ingr(true), self.instr(pred)\n",
    "            scores = metrics(true, pred)\n",
    "            precision.append(scores.precision())\n",
    "            recall.append(scores.recall())\n",
    "    \n",
    "        print('precision', sum(precision)/len(precision))\n",
    "        print('recall', sum(recall)/len(recall))\n",
    "        \n",
    "        \n",
    "    def jaccard(self, generate = 'ingr'):\n",
    "        assert generate in ['ingr','instr','human']\n",
    "        jaccard = []\n",
    "        for i, v in tqdm.tqdm(self.dic.items()):\n",
    "            if generate == 'ingr':\n",
    "                true, pred = v['%s_ingr'%(self.ori)], v['%s_ingr'%(self.gen)]\n",
    "                true, pred = self.ingr(true), self.ingr(pred)\n",
    "            elif generate == 'instr':\n",
    "                true, pred = v['%s_ingr'%(self.ori)], v['%s_instr'%(self.gen)]\n",
    "                true, pred = self.ingr(true), self.instr(pred)\n",
    "            elif generate == 'human':   \n",
    "                true, pred = v['%s_ingr'%(self.ori)], v['%s_instr'%(self.ori)]\n",
    "                true, pred = self.ingr(true), self.instr(pred)\n",
    "            true, pred = set(true), set(pred)\n",
    "            \n",
    "            intersect = len(true & pred)\n",
    "            similarity = intersect /(len(true)+len(pred) - intersect)\n",
    "            jaccard.append(similarity)\n",
    "    \n",
    "        print('jaccard', sum(jaccard)/len(jaccard))\n",
    "    \n",
    "    def instr(self, directions):\n",
    "        instr = sp.spacy(directions)\n",
    "        root_instr = []\n",
    "        for chunk in instr.noun_chunks:\n",
    "            idx_rootnoun = chunk.end - 1\n",
    "            str_rootnoun = instr[idx_rootnoun].lemma_\n",
    "            if str_rootnoun in database:\n",
    "                root_instr.append(str_rootnoun)\n",
    "        return root_instr\n",
    "    \n",
    "    def ingr(self, lst):\n",
    "        '''\n",
    "        Args: lst: a list of ingredient names\n",
    "        used when len(lst) must equal to root_match\n",
    "        '''\n",
    "        hl = [[{'text':x, 'highlight': None} for x in i.split(' ')] for i in lst]\n",
    "        root_match = []\n",
    "        for i, ingr in enumerate(lst):\n",
    "            if ' ' not in ingr:\n",
    "                hl[i][0]['highlight'] = 'wrong'\n",
    "                doc = sp.spacy(ingr)\n",
    "                root_match.append(doc[0].lemma_)\n",
    "            else:\n",
    "                phrase = 'Mix the %s and water.'%ingr\n",
    "                doc = sp.spacy(phrase)\n",
    "                \n",
    "                last_chunk = None\n",
    "                for chunk in doc.noun_chunks:\n",
    "                    if chunk.text != 'water':\n",
    "                        last_chunk = chunk\n",
    "                if not last_chunk:\n",
    "                    root_match.append('CANNOT_DETECT')\n",
    "                else:\n",
    "                    found = False\n",
    "                    for j, word in enumerate(hl[i]):\n",
    "                        if doc[last_chunk.end - 1].text in word['text']:\n",
    "                            hl[i][j]['highlight'] = 'wrong' \n",
    "                            root_match.append(doc[last_chunk.end - 1].lemma_)\n",
    "                            found = True\n",
    "                            break\n",
    "                    if not found:\n",
    "                        root_match.append('CANNOT_DETECT')\n",
    "                        \n",
    "        assert len(root_match) == len(lst)\n",
    "        return root_match\n",
    "\n",
    "    '''\n",
    "    exporting data\n",
    "    '''\n",
    "    def to_bleu(self):\n",
    "        to_write = {'%s_i'%(self.ori):'',\n",
    "                    '%s_i'%(self.gen):'',\n",
    "                    '%s_d'%(self.ori):'',\n",
    "                    '%s_d'%(self.gen):''}\n",
    "        \n",
    "        for i, v in self.dic.items():\n",
    "            to_write['%s_i'%(self.ori)] += self.add_space(' $ '.join(v['%s_ingr'%(self.ori)]))+ ' $ \\n'\n",
    "            to_write['%s_i'%(self.gen)] += self.add_space(' $ '.join(v['%s_ingr'%(self.gen)])) + ' $ \\n'\n",
    "            \n",
    "            to_write['%s_d'%(self.ori)] += self.add_space(v['%s_instr'%(self.ori)])+ '\\n'\n",
    "            to_write['%s_d'%(self.gen)] += self.add_space(v['%s_instr'%(self.gen)])+ '\\n'\n",
    "        \n",
    "        for k, v in to_write.items():\n",
    "            save('../../to_gpt2/generation_%s.txt'%(k), v ,overwrite = True)\n",
    "        !eval {\"perl multi-bleu.perl ../../to_gpt2/generation_%s_i.txt < ../../to_gpt2/generation_%s_i.txt\" %(self.ori, self.gen)}\n",
    "        !eval {\"perl multi-bleu.perl ../../to_gpt2/generation_%s_d.txt < ../../to_gpt2/generation_%s_d.txt\" %(self.ori, self.gen)}\n",
    "    \n",
    "        !eval {\"rouge -f ../../to_gpt2/generation_%s_i.txt ../../to_gpt2/generation_%s_i.txt --avg\"%(self.ori, self.gen)}\n",
    "        !eval {\"rouge -f ../../to_gpt2/generation_%s_d.txt ../../to_gpt2/generation_%s_d.txt --avg\"%(self.ori, self.gen)}\n",
    "        \n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = ev('../../to_gpt2/recipe1M_1218/test/y/', 'ori')\n",
    "data.append_dic('../../to_gpt2/generation_1220_k3_test/', '117M')\n",
    "data.jaccard(generate = 'ingr')\n",
    "data.jaccard(generate = 'instr')\n",
    "data.jaccard(generate = 'human')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load ../../to_gpt2/recipe1M_1218/test/y/\n",
      "load ../../to_gpt2/generation_1220_k3_test/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4000/4000 [10:35<00:00,  7.82it/s]\n",
      "  0%|          | 1/4000 [00:00<07:15,  9.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision 0.7921950610642381\n",
      "recall 0.7384655795811356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4000/4000 [07:15<00:00,  9.18it/s]\n",
      "  0%|          | 1/4000 [00:00<06:44,  9.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision 0.6782249261365156\n",
      "recall 0.6687259421666247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4000/4000 [07:41<00:00,  8.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision 0.630349290952402\n",
      "recall 0.6623509140305002\n",
      "time: 25min 34s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data = ev('../../to_gpt2/recipe1M_1218/test/y/', 'ori')\n",
    "data.append_dic('../../to_gpt2/generation_1220_k3_test/', '117M')\n",
    "data.ingr_precision_recall(generate = 'ingr')\n",
    "data.ingr_precision_recall(generate = 'instr')\n",
    "data.ingr_precision_recall(generate = 'human')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load ../../to_gpt2/recipe1M_1218/val/y/\n",
      "load ../../to_gpt2/val/generation_1220_k1_val/\n",
      "load ../../to_gpt2/val/generation_1220_k3_val/\n",
      "load ../../to_gpt2/val/generation_1220_k5_val/\n",
      "load ../../to_gpt2/val/generation_1220_k10_val/\n",
      "load ../../to_gpt2/val/generation_1220_k30_val/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/4000 [00:00<10:58,  6.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4000/4000 [10:35<00:00,  7.62it/s]\n",
      "  0%|          | 1/4000 [00:00<10:11,  6.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7852302818896786\n",
      "average ingr number 7.62425\n",
      "k3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4000/4000 [11:02<00:00,  7.62it/s]\n",
      "  0%|          | 1/4000 [00:00<10:51,  6.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7576264358968974\n",
      "average ingr number 7.87625\n",
      "k5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4000/4000 [10:56<00:00,  7.67it/s]\n",
      "  0%|          | 1/4000 [00:00<11:08,  5.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7518758592242816\n",
      "average ingr number 8.04175\n",
      "k10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4000/4000 [11:10<00:00,  7.32it/s]\n",
      "  0%|          | 1/4000 [00:00<12:40,  5.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7359340162056293\n",
      "average ingr number 8.28425\n",
      "k30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4000/4000 [11:36<00:00,  7.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7115262449145586\n",
      "average ingr number 8.675\n",
      "time: 55min 26s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data = ev('../../to_gpt2/recipe1M_1218/val/y/', 'ori')\n",
    "data.append_dic('../../to_gpt2/val/generation_1220_k1_val/', 'k1')\n",
    "data.append_dic('../../to_gpt2/val/generation_1220_k3_val/', 'k3')\n",
    "data.append_dic('../../to_gpt2/val/generation_1220_k5_val/', 'k5')\n",
    "data.append_dic('../../to_gpt2/val/generation_1220_k10_val/', 'k10')\n",
    "data.append_dic('../../to_gpt2/val/generation_1220_k30_val/', 'k30')\n",
    "for tag in data.gens:\n",
    "    print(tag)\n",
    "    data.gen = tag\n",
    "    data.ingr_f1(root=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
