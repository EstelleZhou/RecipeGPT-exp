{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 12.6 Âµs\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "%load_ext autotime\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# add path\n",
    "import os \n",
    "import sys \n",
    "parent_dir = os.path.abspath(os.getcwd()+'/..')+'/' \n",
    "sys.path.append(parent_dir) \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from utils.save import make_dir, save_pickle, load_pickle, auto_save_csv, print_time, auto_save_pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 23.3 ms\n"
     ]
    }
   ],
   "source": [
    "def read_text(path):\n",
    "    with open(path, 'r') as fp:\n",
    "        raw_text = fp.read()\n",
    "        raw_text = raw_text.split('\\n')\n",
    "        return raw_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 39.4 ms\n"
     ]
    }
   ],
   "source": [
    "dir_dataset = '../../npn-cooking-data/cooking_dataset/'\n",
    "attr_assignments_by_verb = load_pickle(dir_dataset+'lexicon/attr_assignments_by_verb.pickle')\n",
    "state_verbs = load_pickle(dir_dataset+'/lexicon/state_change_by_verb_ncl.pickle')\n",
    "compostion_verbs = {k: {'composition': 'change'} for k, v in attr_assignments_by_verb.items() if 'composition' in v}\n",
    "location = read_text(dir_dataset+'vocabs/nyc_loc_states_5.vocab')\n",
    "\n",
    "# update compostion info\n",
    "for k, v in compostion_verbs.items():\n",
    "    if k not in state_verbs.keys():\n",
    "        state_verbs.update({k:v})\n",
    "    else:\n",
    "        value = state_verbs[k]\n",
    "        value.update(v)\n",
    "        state_verbs.update({k:value})\n",
    "\n",
    "# update location info\n",
    "for loc in location:\n",
    "    if loc not in state_verbs.keys():\n",
    "        state_verbs.update({loc:{'location':loc}})\n",
    "    else:\n",
    "        value = state_verbs[k]\n",
    "        value.update({'location':loc})\n",
    "        state_verbs.update({loc:value})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 29.6 ms\n"
     ]
    }
   ],
   "source": [
    "save_pickle(obj=state_verbs, filename='../big_data/state_verbs.pickle', overwrite= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 21.2 ms\n"
     ]
    }
   ],
   "source": [
    "x = load_pickle('../big_data/state_verbs.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "248"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 13.6 ms\n"
     ]
    }
   ],
   "source": [
    "len(set([k1+'_'+v1 for k in x.values() for k1, v1 in k.items()]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
