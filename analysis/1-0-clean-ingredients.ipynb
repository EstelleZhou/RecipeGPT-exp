{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dependency import parent_dir\n",
    "from common.basics import *\n",
    "from common.save import make_dir, save_pickle, load_pickle, save\n",
    "layer1 = json.load(open('../big_data/layer1.json','r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_line(line):\n",
    "    '''\n",
    "    Args:\n",
    "        line: a string, such as food name, sentences...\n",
    "    '''\n",
    "    assert type(line) == str\n",
    "    \n",
    "    # all lowercase\n",
    "    line = line.lower()\n",
    "    \n",
    "    # only reserve number and alphabets\n",
    "    line = re.sub(r'[^a-z0-9+()/?!.,]', ' ', line)\n",
    "    \n",
    "    # replace things in brace\n",
    "    line = re.sub(r'\\([^)]*\\)', '', line)\n",
    "    \n",
    "    # remove extra spaces\n",
    "    line = re.sub(' +',' ',line).strip()\n",
    "    return line\n",
    "\n",
    "def preprocessing(layer1):\n",
    "    data = []\n",
    "    for i, recipe in tqdm.tqdm(enumerate(layer1)):\n",
    "        processed_recipe = {'id': recipe['id'],\n",
    "                            'ingredients':[]}\n",
    "        field = 'ingredients'\n",
    "        for line in recipe[field]:\n",
    "            cleaned = clean_line(line['text'])\n",
    "            if cleaned:\n",
    "                processed_recipe[field].append(cleaned)  \n",
    "        data.append(processed_recipe)\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1029720it [03:03, 5602.32it/s]\n"
     ]
    }
   ],
   "source": [
    "data = preprocessing(layer1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ny_ingredients:\n",
    "    '''use ny-time-parser to process the ingredients'''\n",
    "    def __init__(self):\n",
    "        self.ny_ingred = '../../NYtime-parser2/ingred.txt'\n",
    "        self.ny_result = '../../NYtime-parser2/result.json'\n",
    "        self.fields = ['ingredients']\n",
    "        \n",
    "    def to_ny(self, data):\n",
    "        '''\n",
    "        Args: \n",
    "          data: A list of recipes \n",
    "        '''\n",
    "        to_write = []\n",
    "        for i, v in tqdm.tqdm(enumerate(data)):\n",
    "            # assing index\n",
    "            for field in self.fields:\n",
    "                line_ids = []\n",
    "                for line in v[field]:\n",
    "                    if line in to_write:\n",
    "                        ny_id = to_write.index(line)\n",
    "                    else:\n",
    "                        ny_id = len(to_write)\n",
    "                        to_write.append(line)\n",
    "                    line_ids.append(ny_id)\n",
    "                data[i]['ny_%s'%(field)] = line_ids\n",
    "\n",
    "        # save the file to the folder under NYtime-parser2\n",
    "        save(filename = self.ny_ingred, \n",
    "             to_write = '\\n'.join(to_write),\n",
    "             overwrite = True, \n",
    "             print_=True)\n",
    "        return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Collect all the ingredients mentioned in this dataset and save to '../../NYtime-parser2/ingred.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "631756it [25:14:54,  4.91it/s]"
     ]
    }
   ],
   "source": [
    "ny_ingr = ny_ingredients()\n",
    "data = ny_ingr.to_ny(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Execute the notebook 'Control Nytimes.ipynb' in python 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ny_result = pd.read_json(ny_ingr.ny_result)\n",
    "to_write = []\n",
    "for i, v in tqdm.tqdm(enumerate(data)):\n",
    "    for field in ny_ingr.fields:\n",
    "        temp = [ny_result.loc[ny_id]['name'] for ny_id in v['ny_%s'%(field)]]\n",
    "        data[i]['ny_full_%s'%(field)] = [ny_result.loc[ny_id].to_dict() for ny_id in v['ny_%s'%(field)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 58.1 s\n"
     ]
    }
   ],
   "source": [
    "save_pickle('../big_data/recipe1M_ny_2.pickle', data, overwrite=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
