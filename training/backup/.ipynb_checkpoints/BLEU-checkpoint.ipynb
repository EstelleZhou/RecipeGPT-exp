{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "save = importlib.import_module(\"gpt-2.src.save\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 27/32448 [00:00<02:07, 253.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "to_gpt2/recipe54k_0827/test/y/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32448/32448 [01:54<00:00, 284.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to_gpt2/recipe54k_0827/test/y_one0.txt\n",
      "saved to_gpt2/recipe54k_0827/test/y_one1.txt\n",
      "saved to_gpt2/recipe54k_0827/test/y_one2.txt\n"
     ]
    }
   ],
   "source": [
    "save.to_one_file(filename = 'to_gpt2/recipe54k_0827/test/y/', max_document=1500, overwrite = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/32448 [00:00<10:58, 49.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "to_gpt2/recipe54k_0916/test/y/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32448/32448 [07:56<00:00, 68.15it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to_gpt2/recipe54k_0916/test/y_one0.txt\n",
      "saved to_gpt2/recipe54k_0916/test/y_one1.txt\n",
      "saved to_gpt2/recipe54k_0916/test/y_one2.txt\n"
     ]
    }
   ],
   "source": [
    "save.to_one_file(filename = 'to_gpt2/recipe54k_0916/test/y/', max_document=1500, overwrite = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 16/1500 [00:00<00:09, 156.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "to_gpt2/recipe54k_0827/test/generation_308k/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1500/1500 [00:05<00:00, 296.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to_gpt2/recipe54k_0827/test/generation_308k_one0.txt\n",
      "saved to_gpt2/recipe54k_0827/test/generation_308k_one1.txt\n",
      "saved to_gpt2/recipe54k_0827/test/generation_308k_one2.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "save.to_one_file(filename = 'to_gpt2/recipe54k_0827/test/generation_308k/', max_document=1500, overwrite = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU = 2.32, 25.9/6.2/1.3/0.1 (BP=1.000, ratio=1.053, hyp_len=2169, ref_len=2059)\n",
      "It is not advisable to publish scores from multi-bleu.perl.  The scores depend on your tokenizer, which is unlikely to be reproducible from your paper or consistent across research groups.  Instead you should detokenize then use mteval-v14.pl, which has a standard tokenization.  Scores from multi-bleu.perl can still be used for internal purposes when you have a consistent tokenizer.\n"
     ]
    }
   ],
   "source": [
    "!perl gpt-2/eval/multi-bleu.perl to_gpt2/recipe54k_0827/test/y_one2.txt < to_gpt2/recipe54k_0827/test/generation_1221k_topk_one2.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Also use ROUGE to evaluate the same documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rouge\n",
      "  Downloading https://files.pythonhosted.org/packages/63/ac/b93411318529980ab7f41e59ed64ec3ffed08ead32389e29eb78585dd55d/rouge-0.3.2-py3-none-any.whl\n",
      "Installing collected packages: rouge\n",
      "Successfully installed rouge-0.3.2\n",
      "\u001b[33mYou are using pip version 18.1, however version 19.2.3 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install rouge "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"rouge-l\": {\n",
      "    \"r\": 0.49631108942092983,\n",
      "    \"p\": 0.4185911413955956,\n",
      "    \"f\": 0.4142405311926886\n",
      "  },\n",
      "  \"rouge-1\": {\n",
      "    \"r\": 0.5296482218762009,\n",
      "    \"p\": 0.44674528455827056,\n",
      "    \"f\": 0.468753249945629\n",
      "  },\n",
      "  \"rouge-2\": {\n",
      "    \"r\": 0.19839118288056753,\n",
      "    \"p\": 0.1697667529229654,\n",
      "    \"f\": 0.17450977639580392\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "!rouge -f to_gpt2/recipe54k_0827/test/y_one0.txt to_gpt2/recipe54k_0827/test/generation_1221k_topk_one0.txt --avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"rouge-l\": {\n",
      "    \"p\": 0.5022844690695616,\n",
      "    \"r\": 0.5040202190337157,\n",
      "    \"f\": 0.4858687310906024\n",
      "  },\n",
      "  \"rouge-1\": {\n",
      "    \"p\": 0.6098357232946763,\n",
      "    \"r\": 0.6127964496352052,\n",
      "    \"f\": 0.6034313035329341\n",
      "  },\n",
      "  \"rouge-2\": {\n",
      "    \"p\": 0.39442269176815553,\n",
      "    \"r\": 0.38519569314969965,\n",
      "    \"f\": 0.3847416574842294\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "!rouge -f to_gpt2/recipe54k_0827/test/y_one1.txt to_gpt2/recipe54k_0827/test/generation_1221k_topk_one1.txt --avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"rouge-2\": {\n",
      "    \"r\": 0.05816666666666665,\n",
      "    \"f\": 0.05964442957500375,\n",
      "    \"p\": 0.06872864357864357\n",
      "  },\n",
      "  \"rouge-1\": {\n",
      "    \"r\": 0.26354877344877353,\n",
      "    \"f\": 0.26253196212616037,\n",
      "    \"p\": 0.2910069264069264\n",
      "  },\n",
      "  \"rouge-l\": {\n",
      "    \"r\": 0.24977258297258306,\n",
      "    \"f\": 0.23145263452970347,\n",
      "    \"p\": 0.2765464646464646\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "!rouge -f to_gpt2/recipe54k_0827/test/y_one2.txt to_gpt2/recipe54k_0827/test/generation_1221k_topk_one2.txt --avg"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
