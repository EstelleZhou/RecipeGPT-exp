{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### separted into four fields to compare the bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def save(filename, to_write, overwrite = False):\n",
    "    make_dir(filename)\n",
    "    if os.path.isfile(filename) == True and overwrite == False:\n",
    "        print('already exists'+filename)\n",
    "    else:    \n",
    "        with open(filename,'w') as f:\n",
    "            f.write('%s' % to_write)\n",
    "        print('saved '+filename)\n",
    "        \n",
    "def make_dir(filename):\n",
    "    dir_path = os.path.dirname(filename)\n",
    "    if not os.path.exists(dir_path):\n",
    "        os.makedirs(dir_path)\n",
    "        print('make dir')\n",
    "        \n",
    "def customized_y_field(nrecipes = 4000,\n",
    "                      filename = '',\n",
    "                      overwrite = False,\n",
    "                      field=4):\n",
    "    # init\n",
    "    to_write = {k: '' for k in range(4)}\n",
    "    \n",
    "    with open(filename, 'r') as f:\n",
    "        for j, raw_text in enumerate(f):\n",
    "            if j < nrecipes or nrecipes == -1:\n",
    "                text = raw_text\n",
    "            else:\n",
    "                break\n",
    "            to_write[j%field] += text\n",
    "    for key, values in to_write.items():\n",
    "        save(filename.replace('.txt','_%d_%d.txt' %(nrecipes, key)), values, overwrite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved /workspace/gpt2_0801/to_gpt2/6600epoch/recipe54k_0724.y_test2_4000_0.txt\n",
      "saved /workspace/gpt2_0801/to_gpt2/6600epoch/recipe54k_0724.y_test2_4000_1.txt\n",
      "saved /workspace/gpt2_0801/to_gpt2/6600epoch/recipe54k_0724.y_test2_4000_2.txt\n",
      "saved /workspace/gpt2_0801/to_gpt2/6600epoch/recipe54k_0724.y_test2_4000_3.txt\n"
     ]
    }
   ],
   "source": [
    "customized_y_field(nrecipes=4000,\n",
    "                  filename='/workspace/gpt2_0801/to_gpt2/6600epoch/recipe54k_0724.y_test2.txt',\n",
    "                  overwrite = True,\n",
    "                  field=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved /workspace/gpt2_0801/to_gpt2/6600epoch/recipe54k_0724.y_pred_4000_0.txt\n",
      "saved /workspace/gpt2_0801/to_gpt2/6600epoch/recipe54k_0724.y_pred_4000_1.txt\n",
      "saved /workspace/gpt2_0801/to_gpt2/6600epoch/recipe54k_0724.y_pred_4000_2.txt\n",
      "saved /workspace/gpt2_0801/to_gpt2/6600epoch/recipe54k_0724.y_pred_4000_3.txt\n"
     ]
    }
   ],
   "source": [
    "customized_y_field(nrecipes=4000,\n",
    "                  filename='/workspace/gpt2_0801/to_gpt2/6600epoch/recipe54k_0724.y_pred.txt',\n",
    "                  overwrite = True,\n",
    "                  field=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU = 3.27, 18.7/5.5/1.6/0.7 (BP=1.000, ratio=3.007, hyp_len=195326, ref_len=64950)\n",
      "It is not advisable to publish scores from multi-bleu.perl.  The scores depend on your tokenizer, which is unlikely to be reproducible from your paper or consistent across research groups.  Instead you should detokenize then use mteval-v14.pl, which has a standard tokenization.  Scores from multi-bleu.perl can still be used for internal purposes when you have a consistent tokenizer.\n"
     ]
    }
   ],
   "source": [
    "!perl gpt-2/eval/multi-bleu.perl /workspace/gpt2_0801/to_gpt2/6600epoch/recipe54k_0724.y_test2_4000_0.txt < /workspace/gpt2_0801/to_gpt2/6600epoch/recipe54k_0724.y_pred_4000_0.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU = 2.22, 9.5/4.0/1.4/0.5 (BP=1.000, ratio=6.658, hyp_len=202230, ref_len=30372)\n",
      "It is not advisable to publish scores from multi-bleu.perl.  The scores depend on your tokenizer, which is unlikely to be reproducible from your paper or consistent across research groups.  Instead you should detokenize then use mteval-v14.pl, which has a standard tokenization.  Scores from multi-bleu.perl can still be used for internal purposes when you have a consistent tokenizer.\n"
     ]
    }
   ],
   "source": [
    "!perl gpt-2/eval/multi-bleu.perl /workspace/gpt2_0801/to_gpt2/6600epoch/recipe54k_0724.y_test2_4000_1.txt < /workspace/gpt2_0801/to_gpt2/6600epoch/recipe54k_0724.y_pred_4000_1.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU = 0.38, 4.4/0.8/0.1/0.0 (BP=1.000, ratio=11.563, hyp_len=196984, ref_len=17035)\n",
      "It is not advisable to publish scores from multi-bleu.perl.  The scores depend on your tokenizer, which is unlikely to be reproducible from your paper or consistent across research groups.  Instead you should detokenize then use mteval-v14.pl, which has a standard tokenization.  Scores from multi-bleu.perl can still be used for internal purposes when you have a consistent tokenizer.\n"
     ]
    }
   ],
   "source": [
    "!perl gpt-2/eval/multi-bleu.perl /workspace/gpt2_0801/to_gpt2/6600epoch/recipe54k_0724.y_test2_4000_2.txt < /workspace/gpt2_0801/to_gpt2/6600epoch/recipe54k_0724.y_pred_4000_2.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use of uninitialized value in division (/) at gpt-2/eval/multi-bleu.perl line 139, <STDIN> line 500.\n",
      "BLEU = 0.00, 0.4/0.0/0.0/0.0 (BP=1.000, ratio=79.586, hyp_len=203660, ref_len=2559)\n",
      "It is not advisable to publish scores from multi-bleu.perl.  The scores depend on your tokenizer, which is unlikely to be reproducible from your paper or consistent across research groups.  Instead you should detokenize then use mteval-v14.pl, which has a standard tokenization.  Scores from multi-bleu.perl can still be used for internal purposes when you have a consistent tokenizer.\n"
     ]
    }
   ],
   "source": [
    "!perl gpt-2/eval/multi-bleu.perl /workspace/gpt2_0801/to_gpt2/6600epoch/recipe54k_0724.y_test2_4000_3.txt < /workspace/gpt2_0801/to_gpt2/6600epoch/recipe54k_0724.y_pred_4000_3.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function tensorflow.contrib.framework.python.ops.sort_ops.sort(values, axis=-1, direction='ASCENDING', name=None)>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.contrib.framework.sort"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### epoch 15350-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customized_y_field(nrecipes=4000,\n",
    "                  filename='/workspace/gpt2_0801/to_gpt2/15350epoch2/recipe54k_0724.y_test2.txt',\n",
    "                  overwrite = True,\n",
    "                  field=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved /workspace/gpt2_0801/to_gpt2/15350epoch2/recipe54k_0724.y_pred_4000_0.txt\n",
      "saved /workspace/gpt2_0801/to_gpt2/15350epoch2/recipe54k_0724.y_pred_4000_1.txt\n",
      "saved /workspace/gpt2_0801/to_gpt2/15350epoch2/recipe54k_0724.y_pred_4000_2.txt\n",
      "saved /workspace/gpt2_0801/to_gpt2/15350epoch2/recipe54k_0724.y_pred_4000_3.txt\n"
     ]
    }
   ],
   "source": [
    "customized_y_field(nrecipes=4000,\n",
    "                  filename='/workspace/gpt2_0801/to_gpt2/15350epoch2/recipe54k_0724.y_pred.txt',\n",
    "                  overwrite = True,\n",
    "                  field=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU = 8.27, 42.0/13.9/5.3/2.7 (BP=0.864, ratio=0.873, hyp_len=56688, ref_len=64950)\n",
      "It is not advisable to publish scores from multi-bleu.perl.  The scores depend on your tokenizer, which is unlikely to be reproducible from your paper or consistent across research groups.  Instead you should detokenize then use mteval-v14.pl, which has a standard tokenization.  Scores from multi-bleu.perl can still be used for internal purposes when you have a consistent tokenizer.\n"
     ]
    }
   ],
   "source": [
    "!perl gpt-2/eval/multi-bleu.perl /workspace/gpt2_0801/to_gpt2/15350epoch2/recipe54k_0724.y_test2_4000_0.txt < /workspace/gpt2_0801/to_gpt2/15350epoch2/recipe54k_0724.y_pred_4000_0.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU = 14.83, 37.0/21.2/11.3/5.5 (BP=1.000, ratio=1.429, hyp_len=43400, ref_len=30372)\n",
      "It is not advisable to publish scores from multi-bleu.perl.  The scores depend on your tokenizer, which is unlikely to be reproducible from your paper or consistent across research groups.  Instead you should detokenize then use mteval-v14.pl, which has a standard tokenization.  Scores from multi-bleu.perl can still be used for internal purposes when you have a consistent tokenizer.\n"
     ]
    }
   ],
   "source": [
    "!perl gpt-2/eval/multi-bleu.perl /workspace/gpt2_0801/to_gpt2/15350epoch2/recipe54k_0724.y_test2_4000_1.txt < /workspace/gpt2_0801/to_gpt2/15350epoch2/recipe54k_0724.y_pred_4000_1.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU = 0.83, 18.8/1.9/0.3/0.1 (BP=1.000, ratio=1.213, hyp_len=20665, ref_len=17035)\n",
      "It is not advisable to publish scores from multi-bleu.perl.  The scores depend on your tokenizer, which is unlikely to be reproducible from your paper or consistent across research groups.  Instead you should detokenize then use mteval-v14.pl, which has a standard tokenization.  Scores from multi-bleu.perl can still be used for internal purposes when you have a consistent tokenizer.\n"
     ]
    }
   ],
   "source": [
    "!perl gpt-2/eval/multi-bleu.perl /workspace/gpt2_0801/to_gpt2/15350epoch2/recipe54k_0724.y_test2_4000_2.txt < /workspace/gpt2_0801/to_gpt2/15350epoch2/recipe54k_0724.y_pred_4000_2.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use of uninitialized value in division (/) at gpt-2/eval/multi-bleu.perl line 139, <STDIN> line 500.\n",
      "BLEU = 0.00, 19.9/4.6/0.7/0.0 (BP=0.805, ratio=0.822, hyp_len=2103, ref_len=2559)\n",
      "It is not advisable to publish scores from multi-bleu.perl.  The scores depend on your tokenizer, which is unlikely to be reproducible from your paper or consistent across research groups.  Instead you should detokenize then use mteval-v14.pl, which has a standard tokenization.  Scores from multi-bleu.perl can still be used for internal purposes when you have a consistent tokenizer.\n"
     ]
    }
   ],
   "source": [
    "!perl gpt-2/eval/multi-bleu.perl /workspace/gpt2_0801/to_gpt2/15350epoch2/recipe54k_0724.y_test2_4000_3.txt < /workspace/gpt2_0801/to_gpt2/15350epoch2/recipe54k_0724.y_pred_4000_3.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '/workspace/gpt2_0801/to_gpt2/recipe54k_0802.train.txt'\n",
    "\n",
    "length = []\n",
    "with open(filename, 'r') as f:\n",
    "    for j, raw_text in enumerate(f):\n",
    "        length.append(len(raw_text.split(' ')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fc27c6eada0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.Series(length).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1076"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(length).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
