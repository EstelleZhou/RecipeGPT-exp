{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 8.58 Âµs\n",
      "The autotime extension is already loaded. To reload it, use:\n",
      "  %reload_ext autotime\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "%load_ext autotime\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# if cannot import the modules, add the parent directory to system path might help\n",
    "import os, tqdm, sys\n",
    "parent_dir = os.path.abspath(os.getcwd()+'/..')+'/'\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "from utils.path import dir_HugeFiles\n",
    "from utils.save import make_dir, save_pickle, load_pickle, save\n",
    "from utils.tree import instr2tree, tree_distance, build_tree, stem\n",
    "from utils.evaluation import metrics, spacy_extension\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "treemaker = instr2tree()\n",
    "sp = spacy_extension()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class evaluation:\n",
    "    def __init__(self, filename, tag):\n",
    "        self.dic = self.load_dic({}, filename, tag)\n",
    "        self.ori = tag\n",
    "        self.gens = []\n",
    "        #from utils.evaluation import metrics\n",
    "    '''\n",
    "    loading data\n",
    "    '''\n",
    "    def append_dic(self, filename, tag):\n",
    "        if tag in self.gens:\n",
    "            print('already exist, will not load again')\n",
    "            self.gen = tag\n",
    "        else:\n",
    "            self.dic = self.load_dic(self.dic, filename, tag)\n",
    "            self.gen = tag\n",
    "            self.gens += [tag]\n",
    "        \n",
    "    def load_dic(self, dic, filename, tag):\n",
    "        if os.path.isdir(filename):\n",
    "            print('load', filename)\n",
    "            for (dirpath, _, fnames) in os.walk(filename):\n",
    "                for fname in fnames:\n",
    "                    path = os.path.join(dirpath, fname)\n",
    "                    with open(path, 'r') as fp:\n",
    "                        raw_text = fp.read()\n",
    "                        raw_text = self.remove_end(raw_text)\n",
    "\n",
    "                    name, field = int(fname[:-5]), fname[-5]\n",
    "\n",
    "                    if name not in dic.keys() and field in ['d','i']:\n",
    "                        dic.update({name: {}})\n",
    "\n",
    "                    if field == 'd':\n",
    "                        dic[name].update({'%s_instr'%(tag): raw_text})\n",
    "\n",
    "                    if field == 'i':\n",
    "                        raw_text = self.reverse_list(raw_text.split('$'))\n",
    "                        dic[name].update({'%s_ingr'%(tag): raw_text})\n",
    "        return dic\n",
    "    \n",
    "    '''\n",
    "    exporting data\n",
    "    '''\n",
    "    def to_bleu(self):\n",
    "        to_write = {'%s_i'%(self.ori):'',\n",
    "                    '%s_i'%(self.gen):'',\n",
    "                    '%s_d'%(self.ori):'',\n",
    "                    '%s_d'%(self.gen):''}\n",
    "        \n",
    "        for i, v in self.dic.items():\n",
    "            to_write['%s_i'%(self.ori)] += self.add_space(' $ '.join(v['%s_ingr'%(self.ori)]))+ ' $ \\n'\n",
    "            to_write['%s_i'%(self.gen)] += self.add_space(' $ '.join(v['%s_ingr'%(self.gen)])) + ' $ \\n'\n",
    "            \n",
    "            to_write['%s_d'%(self.ori)] += self.add_space(v['%s_instr'%(self.ori)])+ '\\n'\n",
    "            to_write['%s_d'%(self.gen)] += self.add_space(v['%s_instr'%(self.gen)])+ '\\n'\n",
    "        \n",
    "        for k, v in to_write.items():\n",
    "            save('../../to_gpt2/generation_%s.txt'%(k), v ,overwrite = True)\n",
    "        !eval {\"perl multi-bleu.perl ../../to_gpt2/generation_%s_i.txt < ../../to_gpt2/generation_%s_i.txt\" %(self.ori, self.gen)}\n",
    "        !eval {\"perl multi-bleu.perl ../../to_gpt2/generation_%s_d.txt < ../../to_gpt2/generation_%s_d.txt\" %(self.ori, self.gen)}\n",
    "    \n",
    "        !eval {\"rouge -f ../../to_gpt2/generation_%s_i.txt ../../to_gpt2/generation_%s_i.txt --avg\"%(self.ori, self.gen)}\n",
    "        !eval {\"rouge -f ../../to_gpt2/generation_%s_d.txt ../../to_gpt2/generation_%s_d.txt --avg\"%(self.ori, self.gen)}\n",
    "        \n",
    "        print()\n",
    "    \n",
    "\n",
    "    def ingr_f1_freq(self, root = False):\n",
    "        value = []\n",
    "        for i, v in tqdm.tqdm(self.dic.items()):\n",
    "            true, pred = v['%s_ingr'%(self.ori)], v['%s_ingr'%(self.gen)]\n",
    "            if root:\n",
    "                true, pred = sp.root(true), sp.root(pred)\n",
    "            scores = metrics(true, pred)\n",
    "            value.append(scores.f1_freq())\n",
    "        avg = sum(value)/len(value)\n",
    "        print(avg)\n",
    "        return avg\n",
    "    '''\n",
    "    instruction evaluation\n",
    "    '''\n",
    "    def instr_tree(self, stem_only = False):\n",
    "        value = []\n",
    "        for i, v in tqdm.tqdm(self.dic.items()):\n",
    "            ori_instr, gen_instr = v['%s_instr'%(self.ori)], v['%s_instr'%(self.gen)]\n",
    "            score = self.norm_dist(ori_instr, gen_instr, stem_only = stem_only)\n",
    "            value.append(score)\n",
    "        avg = sum(value)/len(value)\n",
    "        print(avg)\n",
    "        return avg\n",
    "    \n",
    "    '''\n",
    "    cleaning data\n",
    "    '''\n",
    "    def remove_end(self, text):\n",
    "        return text.replace('\\n','').split('<')[0]\n",
    "    \n",
    "    def reverse(self, text):\n",
    "        '''\n",
    "        Important data cleaning before NY times parser\n",
    "        '''\n",
    "        # replace things in brace\n",
    "        text = re.sub(r'\\([^)]*\\)', '', text)\n",
    "\n",
    "        # remove space before punct\n",
    "        text = re.sub(r'\\s([?.!,\"](?:\\s|$))', r'\\1', text)\n",
    "\n",
    "        # remove consecutive spaces\n",
    "        text = re.sub(' +',' ',text).strip()\n",
    "        return text\n",
    "    \n",
    "    def reverse_list(self, listoftext):\n",
    "        output = []\n",
    "        for text in listoftext:\n",
    "            rev = self.reverse(text)\n",
    "            if rev:\n",
    "                output.append(rev)\n",
    "        return output\n",
    "    \n",
    "    def add_space(self, line):\n",
    "        # add space before punct\n",
    "        line = re.sub('([.,!?()])', r' \\1 ', line)\n",
    "        line = re.sub('\\s{2,}', ' ', line)\n",
    "        return line\n",
    "    \n",
    "    '''\n",
    "    tree edit distance\n",
    "    '''\n",
    "\n",
    "    def str2tree(self, instr, stem_only):\n",
    "        instr = [x for x in instr.split('. ') if x]\n",
    "        instr = treemaker.sents2tree(instr)\n",
    "        if stem_only:\n",
    "            instr = stem(instr)\n",
    "        n_nodes = sum([len(line['ingredient']) +1 for line in instr])\n",
    "        return build_tree(instr), n_nodes\n",
    "\n",
    "    def norm_dist(self, ori_instr, gen_instr, stem_only):\n",
    "        '''\n",
    "        Args: ori_instr: str\n",
    "        Args: gen_instr: str\n",
    "        '''\n",
    "        ori_tree, ori_nodes = self.str2tree(ori_instr, stem_only = stem_only)\n",
    "        gen_tree, gen_nodes = self.str2tree(gen_instr, stem_only = stem_only)\n",
    "        tree_dist = tree_distance(ori_tree, gen_tree)\n",
    "        normed = tree_dist/(ori_nodes+gen_nodes)\n",
    "        return normed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load ../../to_gpt2/recipe1M_1118/val/y/\n",
      "load ../../to_gpt2/generation_201911118_k1_val/\n",
      "saved ../../to_gpt2/generation_ori_i.txt\n",
      "saved ../../to_gpt2/generation_k1_i.txt\n",
      "saved ../../to_gpt2/generation_ori_d.txt\n",
      "saved ../../to_gpt2/generation_k1_d.txt\n",
      "BLEU = 25.27, 54.9/40.4/21.5/8.6 (BP=1.000, ratio=1.067, hyp_len=108507, ref_len=101657)\n",
      "It is not advisable to publish scores from multi-bleu.perl.  The scores depend on your tokenizer, which is unlikely to be reproducible from your paper or consistent across research groups.  Instead you should detokenize then use mteval-v14.pl, which has a standard tokenization.  Scores from multi-bleu.perl can still be used for internal purposes when you have a consistent tokenizer.\n",
      "BLEU = 10.34, 54.1/21.4/9.4/4.7 (BP=0.689, ratio=0.728, hyp_len=380434, ref_len=522308)\n",
      "It is not advisable to publish scores from multi-bleu.perl.  The scores depend on your tokenizer, which is unlikely to be reproducible from your paper or consistent across research groups.  Instead you should detokenize then use mteval-v14.pl, which has a standard tokenization.  Scores from multi-bleu.perl can still be used for internal purposes when you have a consistent tokenizer.\n",
      "{\n",
      "  \"rouge-1\": {\n",
      "    \"f\": 0.6078115961485572,\n",
      "    \"p\": 0.5425412481741663,\n",
      "    \"r\": 0.7552048899097942\n",
      "  },\n",
      "  \"rouge-2\": {\n",
      "    \"f\": 0.49202009769196187,\n",
      "    \"p\": 0.4464398115165317,\n",
      "    \"r\": 0.6034232722223248\n",
      "  },\n",
      "  \"rouge-l\": {\n",
      "    \"f\": 0.3368956480524842,\n",
      "    \"p\": 0.325564702489678,\n",
      "    \"r\": 0.4660845499376354\n",
      "  }\n",
      "}\n",
      "{\n",
      "  \"rouge-1\": {\n",
      "    \"f\": 0.45293076283983635,\n",
      "    \"p\": 0.40334441072840577,\n",
      "    \"r\": 0.569240653003932\n",
      "  },\n",
      "  \"rouge-2\": {\n",
      "    \"f\": 0.16081417641160342,\n",
      "    \"p\": 0.14383330970975558,\n",
      "    \"r\": 0.20751599922384092\n",
      "  },\n",
      "  \"rouge-l\": {\n",
      "    \"f\": 0.3872429247767316,\n",
      "    \"p\": 0.3760648232400634,\n",
      "    \"r\": 0.5318113753182915\n",
      "  }\n",
      "}\n",
      "\n",
      "load ../../to_gpt2/generation_201911118_k3_val/\n",
      "saved ../../to_gpt2/generation_ori_i.txt\n",
      "saved ../../to_gpt2/generation_k3_i.txt\n",
      "saved ../../to_gpt2/generation_ori_d.txt\n",
      "saved ../../to_gpt2/generation_k3_d.txt\n",
      "BLEU = 27.46, 70.4/51.1/26.8/10.6 (BP=0.864, ratio=0.872, hyp_len=88655, ref_len=101657)\n",
      "It is not advisable to publish scores from multi-bleu.perl.  The scores depend on your tokenizer, which is unlikely to be reproducible from your paper or consistent across research groups.  Instead you should detokenize then use mteval-v14.pl, which has a standard tokenization.  Scores from multi-bleu.perl can still be used for internal purposes when you have a consistent tokenizer.\n",
      "BLEU = 8.65, 52.0/17.9/6.7/2.9 (BP=0.745, ratio=0.773, hyp_len=403590, ref_len=522308)\n",
      "It is not advisable to publish scores from multi-bleu.perl.  The scores depend on your tokenizer, which is unlikely to be reproducible from your paper or consistent across research groups.  Instead you should detokenize then use mteval-v14.pl, which has a standard tokenization.  Scores from multi-bleu.perl can still be used for internal purposes when you have a consistent tokenizer.\n",
      "{\n",
      "  \"rouge-1\": {\n",
      "    \"f\": 0.6049622019038874,\n",
      "    \"p\": 0.5616159146025417,\n",
      "    \"r\": 0.7066381107596577\n",
      "  },\n",
      "  \"rouge-2\": {\n",
      "    \"f\": 0.48209751400467715,\n",
      "    \"p\": 0.454231473589454,\n",
      "    \"r\": 0.5549578370860601\n",
      "  },\n",
      "  \"rouge-l\": {\n",
      "    \"f\": 0.337133035221062,\n",
      "    \"p\": 0.33406057504671044,\n",
      "    \"r\": 0.4270661651494921\n",
      "  }\n",
      "}\n",
      "{\n",
      "  \"rouge-1\": {\n",
      "    \"f\": 0.4321452432369874,\n",
      "    \"p\": 0.40554070356752486,\n",
      "    \"r\": 0.5121492497128495\n",
      "  },\n",
      "  \"rouge-2\": {\n",
      "    \"f\": 0.12973454657568448,\n",
      "    \"p\": 0.1238594403416379,\n",
      "    \"r\": 0.15638370887135006\n",
      "  },\n",
      "  \"rouge-l\": {\n",
      "    \"f\": 0.3707518742704336,\n",
      "    \"p\": 0.3754240957546078,\n",
      "    \"r\": 0.4751393267393666\n",
      "  }\n",
      "}\n",
      "\n",
      "load ../../to_gpt2/generation_201911118_k10_val/\n",
      "saved ../../to_gpt2/generation_ori_i.txt\n",
      "saved ../../to_gpt2/generation_k10_i.txt\n",
      "saved ../../to_gpt2/generation_ori_d.txt\n",
      "saved ../../to_gpt2/generation_k10_d.txt\n",
      "BLEU = 27.43, 69.1/49.0/25.1/9.6 (BP=0.914, ratio=0.917, hyp_len=93253, ref_len=101657)\n",
      "It is not advisable to publish scores from multi-bleu.perl.  The scores depend on your tokenizer, which is unlikely to be reproducible from your paper or consistent across research groups.  Instead you should detokenize then use mteval-v14.pl, which has a standard tokenization.  Scores from multi-bleu.perl can still be used for internal purposes when you have a consistent tokenizer.\n",
      "BLEU = 7.74, 46.9/14.6/4.9/1.9 (BP=0.867, ratio=0.875, hyp_len=457191, ref_len=522308)\n",
      "It is not advisable to publish scores from multi-bleu.perl.  The scores depend on your tokenizer, which is unlikely to be reproducible from your paper or consistent across research groups.  Instead you should detokenize then use mteval-v14.pl, which has a standard tokenization.  Scores from multi-bleu.perl can still be used for internal purposes when you have a consistent tokenizer.\n",
      "{\n",
      "  \"rouge-1\": {\n",
      "    \"f\": 0.592563505322009,\n",
      "    \"p\": 0.5731734515902066,\n",
      "    \"r\": 0.6611950481219133\n",
      "  },\n",
      "  \"rouge-2\": {\n",
      "    \"f\": 0.4655588367473421,\n",
      "    \"p\": 0.45623698484674485,\n",
      "    \"r\": 0.5143586306273291\n",
      "  },\n",
      "  \"rouge-l\": {\n",
      "    \"f\": 0.3292333978499195,\n",
      "    \"p\": 0.3372039771022687,\n",
      "    \"r\": 0.39504082070810487\n",
      "  }\n",
      "}\n",
      "{\n",
      "  \"rouge-1\": {\n",
      "    \"f\": 0.40746295595164134,\n",
      "    \"p\": 0.40417305015977006,\n",
      "    \"r\": 0.45661810563361505\n",
      "  },\n",
      "  \"rouge-2\": {\n",
      "    \"f\": 0.11028158265980506,\n",
      "    \"p\": 0.11250807375942867,\n",
      "    \"r\": 0.12446890276592248\n",
      "  },\n",
      "  \"rouge-l\": {\n",
      "    \"f\": 0.3510015677739845,\n",
      "    \"p\": 0.37380211169016353,\n",
      "    \"r\": 0.42261406864882456\n",
      "  }\n",
      "}\n",
      "\n",
      "load ../../to_gpt2/generation_201911118_k30_val/\n",
      "saved ../../to_gpt2/generation_ori_i.txt\n",
      "saved ../../to_gpt2/generation_k30_i.txt\n",
      "saved ../../to_gpt2/generation_ori_d.txt\n",
      "saved ../../to_gpt2/generation_k30_d.txt\n",
      "BLEU = 26.30, 63.8/43.7/21.7/7.9 (BP=1.000, ratio=1.010, hyp_len=102649, ref_len=101657)\n",
      "It is not advisable to publish scores from multi-bleu.perl.  The scores depend on your tokenizer, which is unlikely to be reproducible from your paper or consistent across research groups.  Instead you should detokenize then use mteval-v14.pl, which has a standard tokenization.  Scores from multi-bleu.perl can still be used for internal purposes when you have a consistent tokenizer.\n",
      "BLEU = 7.29, 43.2/12.6/4.0/1.5 (BP=0.971, ratio=0.972, hyp_len=507469, ref_len=522308)\n",
      "It is not advisable to publish scores from multi-bleu.perl.  The scores depend on your tokenizer, which is unlikely to be reproducible from your paper or consistent across research groups.  Instead you should detokenize then use mteval-v14.pl, which has a standard tokenization.  Scores from multi-bleu.perl can still be used for internal purposes when you have a consistent tokenizer.\n",
      "{\n",
      "  \"rouge-1\": {\n",
      "    \"f\": 0.5660780068224838,\n",
      "    \"p\": 0.5725362104465712,\n",
      "    \"r\": 0.6024353289788477\n",
      "  },\n",
      "  \"rouge-2\": {\n",
      "    \"f\": 0.4390475205076069,\n",
      "    \"p\": 0.4489618922454053,\n",
      "    \"r\": 0.46293394637779034\n",
      "  },\n",
      "  \"rouge-l\": {\n",
      "    \"f\": 0.3181376948360201,\n",
      "    \"p\": 0.3402702416410297,\n",
      "    \"r\": 0.3611108295590807\n",
      "  }\n",
      "}\n",
      "{\n",
      "  \"rouge-1\": {\n",
      "    \"f\": 0.39162862893477496,\n",
      "    \"p\": 0.4070098771980424,\n",
      "    \"r\": 0.4184683726604411\n",
      "  },\n",
      "  \"rouge-2\": {\n",
      "    \"f\": 0.09961800606737278,\n",
      "    \"p\": 0.10664807873408651,\n",
      "    \"r\": 0.10733092387074827\n",
      "  },\n",
      "  \"rouge-l\": {\n",
      "    \"f\": 0.33733747049361634,\n",
      "    \"p\": 0.37559926369716196,\n",
      "    \"r\": 0.3865656876208457\n",
      "  }\n",
      "}\n",
      "\n",
      "time: 5min 50s\n"
     ]
    }
   ],
   "source": [
    "data = evaluation('../../to_gpt2/recipe1M_1118/val/y/', 'ori')\n",
    "\n",
    "data.append_dic('../../to_gpt2/generation_201911118_k1_val/', 'k1')\n",
    "data.to_bleu()\n",
    "\n",
    "data.append_dic('../../to_gpt2/generation_201911118_k3_val/', 'k3')\n",
    "data.to_bleu()\n",
    "\n",
    "data.append_dic('../../to_gpt2/generation_201911118_k3_val/', 'k5')\n",
    "data.to_bleu()\n",
    "\n",
    "data.append_dic('../../to_gpt2/generation_201911118_k10_val/', 'k10')\n",
    "data.to_bleu()\n",
    "\n",
    "data.append_dic('../../to_gpt2/generation_201911118_k30_val/', 'k30')\n",
    "data.to_bleu()\n",
    "\n",
    "data.append_dic('../../to_gpt2/generation_201911118_p99_val/', 'p99')\n",
    "data.to_bleu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load ../../to_gpt2/recipe1M_1118/val/y/\n",
      "load ../../to_gpt2/generation_201911118_k1_val/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4000 [00:00<?, ?it/s]/data/yueliu/RecipeAnalytics_201906/AA6/utils/evaluation.py:34: UndefinedMetricWarning: input/inputs may be empty\n",
      "  self.warn()\n",
      "100%|ââââââââââ| 4000/4000 [00:00<00:00, 8812.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4162089278961664\n",
      "load ../../to_gpt2/generation_201911118_k3_val/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|ââââââââââ| 4000/4000 [00:00<00:00, 10025.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.39568148253596147\n",
      "load ../../to_gpt2/generation_201911118_k5_val/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|ââââââââââ| 4000/4000 [00:00<00:00, 10040.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3923144156092605\n",
      "load ../../to_gpt2/generation_201911118_k10_val/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|ââââââââââ| 4000/4000 [00:00<00:00, 8910.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.37357185692462935\n",
      "load ../../to_gpt2/generation_201911118_k30_val/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|ââââââââââ| 4000/4000 [00:00<00:00, 8993.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3433319541036354\n",
      "load ../../to_gpt2/generation_201911118_p99_val/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|ââââââââââ| 4000/4000 [00:00<00:00, 9114.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.32027630918170885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.32027630918170885"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 12.6 s\n"
     ]
    }
   ],
   "source": [
    "data = evaluation('../../to_gpt2/recipe1M_1118/val/y/', 'ori')\n",
    "\n",
    "data.append_dic('../../to_gpt2/generation_201911118_k1_val/', 'k1')\n",
    "data.ingr_f1_freq(root=False)\n",
    "\n",
    "data.append_dic('../../to_gpt2/generation_201911118_k3_val/', 'k3')\n",
    "data.ingr_f1_freq(root=False)\n",
    "\n",
    "data.append_dic('../../to_gpt2/generation_201911118_k5_val/', 'k5')\n",
    "data.ingr_f1_freq(root=False)\n",
    "\n",
    "data.append_dic('../../to_gpt2/generation_201911118_k10_val/', 'k10')\n",
    "data.ingr_f1_freq(root=False)\n",
    "\n",
    "data.append_dic('../../to_gpt2/generation_201911118_k30_val/', 'k30')\n",
    "data.ingr_f1_freq(root=False)\n",
    "\n",
    "data.append_dic('../../to_gpt2/generation_201911118_p99_val/', 'p99')\n",
    "data.ingr_f1_freq(root=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load ../../to_gpt2/recipe1M_1118/val/y/\n",
      "load ../../to_gpt2/generation_201911118_k1_val/\n",
      "load ../../to_gpt2/generation_201911118_k3_val/\n",
      "load ../../to_gpt2/generation_201911118_k5_val/\n",
      "load ../../to_gpt2/generation_201911118_k10_val/\n",
      "load ../../to_gpt2/generation_201911118_k30_val/\n",
      "load ../../to_gpt2/generation_201911118_p99_val/\n",
      "time: 9.73 s\n"
     ]
    }
   ],
   "source": [
    "data = evaluation('../../to_gpt2/recipe1M_1118/val/y/', 'ori')\n",
    "data.append_dic('../../to_gpt2/generation_201911118_k1_val/', 'k1')\n",
    "data.append_dic('../../to_gpt2/generation_201911118_k3_val/', 'k3')\n",
    "data.append_dic('../../to_gpt2/generation_201911118_k5_val/', 'k5')\n",
    "data.append_dic('../../to_gpt2/generation_201911118_k10_val/', 'k10')\n",
    "data.append_dic('../../to_gpt2/generation_201911118_k30_val/', 'k30')\n",
    "data.append_dic('../../to_gpt2/generation_201911118_p99_val/', 'p99')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k1\n",
      "saved ../../to_gpt2/generation_ori_i.txt\n",
      "saved ../../to_gpt2/generation_k1_i.txt\n",
      "saved ../../to_gpt2/generation_ori_d.txt\n",
      "saved ../../to_gpt2/generation_k1_d.txt\n",
      "BLEU = 25.27, 54.9/40.4/21.5/8.6 (BP=1.000, ratio=1.067, hyp_len=108507, ref_len=101657)\n",
      "It is not advisable to publish scores from multi-bleu.perl.  The scores depend on your tokenizer, which is unlikely to be reproducible from your paper or consistent across research groups.  Instead you should detokenize then use mteval-v14.pl, which has a standard tokenization.  Scores from multi-bleu.perl can still be used for internal purposes when you have a consistent tokenizer.\n",
      "BLEU = 10.34, 54.1/21.4/9.4/4.7 (BP=0.689, ratio=0.728, hyp_len=380434, ref_len=522308)\n",
      "It is not advisable to publish scores from multi-bleu.perl.  The scores depend on your tokenizer, which is unlikely to be reproducible from your paper or consistent across research groups.  Instead you should detokenize then use mteval-v14.pl, which has a standard tokenization.  Scores from multi-bleu.perl can still be used for internal purposes when you have a consistent tokenizer.\n",
      "{\n",
      "  \"rouge-1\": {\n",
      "    \"f\": 0.6078115961485572,\n",
      "    \"p\": 0.5425412481741663,\n",
      "    \"r\": 0.7552048899097942\n",
      "  },\n",
      "  \"rouge-2\": {\n",
      "    \"f\": 0.49202009769196187,\n",
      "    \"p\": 0.4464398115165317,\n",
      "    \"r\": 0.6034232722223248\n",
      "  },\n",
      "  \"rouge-l\": {\n",
      "    \"f\": 0.3368956480524842,\n",
      "    \"p\": 0.325564702489678,\n",
      "    \"r\": 0.4660845499376354\n",
      "  }\n",
      "}\n",
      "{\n",
      "  \"rouge-1\": {\n",
      "    \"f\": 0.45293076283983635,\n",
      "    \"p\": 0.40334441072840577,\n",
      "    \"r\": 0.569240653003932\n",
      "  },\n",
      "  \"rouge-2\": {\n",
      "    \"f\": 0.16081417641160342,\n",
      "    \"p\": 0.14383330970975558,\n",
      "    \"r\": 0.20751599922384092\n",
      "  },\n",
      "  \"rouge-l\": {\n",
      "    \"f\": 0.3872429247767316,\n",
      "    \"p\": 0.3760648232400634,\n",
      "    \"r\": 0.5318113753182915\n",
      "  }\n",
      "}\n",
      "\n",
      "k3\n",
      "saved ../../to_gpt2/generation_ori_i.txt\n",
      "saved ../../to_gpt2/generation_k3_i.txt\n",
      "saved ../../to_gpt2/generation_ori_d.txt\n",
      "saved ../../to_gpt2/generation_k3_d.txt\n",
      "BLEU = 27.46, 70.4/51.1/26.8/10.6 (BP=0.864, ratio=0.872, hyp_len=88655, ref_len=101657)\n",
      "It is not advisable to publish scores from multi-bleu.perl.  The scores depend on your tokenizer, which is unlikely to be reproducible from your paper or consistent across research groups.  Instead you should detokenize then use mteval-v14.pl, which has a standard tokenization.  Scores from multi-bleu.perl can still be used for internal purposes when you have a consistent tokenizer.\n",
      "BLEU = 8.65, 52.0/17.9/6.7/2.9 (BP=0.745, ratio=0.773, hyp_len=403590, ref_len=522308)\n",
      "It is not advisable to publish scores from multi-bleu.perl.  The scores depend on your tokenizer, which is unlikely to be reproducible from your paper or consistent across research groups.  Instead you should detokenize then use mteval-v14.pl, which has a standard tokenization.  Scores from multi-bleu.perl can still be used for internal purposes when you have a consistent tokenizer.\n",
      "{\n",
      "  \"rouge-1\": {\n",
      "    \"f\": 0.6049622019038874,\n",
      "    \"p\": 0.5616159146025417,\n",
      "    \"r\": 0.7066381107596577\n",
      "  },\n",
      "  \"rouge-2\": {\n",
      "    \"f\": 0.48209751400467715,\n",
      "    \"p\": 0.454231473589454,\n",
      "    \"r\": 0.5549578370860601\n",
      "  },\n",
      "  \"rouge-l\": {\n",
      "    \"f\": 0.337133035221062,\n",
      "    \"p\": 0.33406057504671044,\n",
      "    \"r\": 0.4270661651494921\n",
      "  }\n",
      "}\n",
      "{\n",
      "  \"rouge-1\": {\n",
      "    \"f\": 0.4321452432369874,\n",
      "    \"p\": 0.40554070356752486,\n",
      "    \"r\": 0.5121492497128495\n",
      "  },\n",
      "  \"rouge-2\": {\n",
      "    \"f\": 0.12973454657568448,\n",
      "    \"p\": 0.1238594403416379,\n",
      "    \"r\": 0.15638370887135006\n",
      "  },\n",
      "  \"rouge-l\": {\n",
      "    \"f\": 0.3707518742704336,\n",
      "    \"p\": 0.3754240957546078,\n",
      "    \"r\": 0.4751393267393666\n",
      "  }\n",
      "}\n",
      "\n",
      "k5\n",
      "saved ../../to_gpt2/generation_ori_i.txt\n",
      "saved ../../to_gpt2/generation_k5_i.txt\n",
      "saved ../../to_gpt2/generation_ori_d.txt\n",
      "saved ../../to_gpt2/generation_k5_d.txt\n",
      "BLEU = 27.73, 70.9/51.2/26.8/10.6 (BP=0.870, ratio=0.878, hyp_len=89249, ref_len=101657)\n",
      "It is not advisable to publish scores from multi-bleu.perl.  The scores depend on your tokenizer, which is unlikely to be reproducible from your paper or consistent across research groups.  Instead you should detokenize then use mteval-v14.pl, which has a standard tokenization.  Scores from multi-bleu.perl can still be used for internal purposes when you have a consistent tokenizer.\n",
      "BLEU = 8.17, 49.9/16.4/5.8/2.3 (BP=0.796, ratio=0.814, hyp_len=425065, ref_len=522308)\n",
      "It is not advisable to publish scores from multi-bleu.perl.  The scores depend on your tokenizer, which is unlikely to be reproducible from your paper or consistent across research groups.  Instead you should detokenize then use mteval-v14.pl, which has a standard tokenization.  Scores from multi-bleu.perl can still be used for internal purposes when you have a consistent tokenizer.\n",
      "{\n",
      "  \"rouge-1\": {\n",
      "    \"f\": 0.6038661510025992,\n",
      "    \"p\": 0.5686878629896001,\n",
      "    \"r\": 0.694097089837656\n",
      "  },\n",
      "  \"rouge-2\": {\n",
      "    \"f\": 0.4795655268981533,\n",
      "    \"p\": 0.4582550924639056,\n",
      "    \"r\": 0.5434373857006771\n",
      "  },\n",
      "  \"rouge-l\": {\n",
      "    \"f\": 0.3352041649777611,\n",
      "    \"p\": 0.33586808927298295,\n",
      "    \"r\": 0.41606269993436723\n",
      "  }\n",
      "}\n",
      "{\n",
      "  \"rouge-1\": {\n",
      "    \"f\": 0.42085278257601927,\n",
      "    \"p\": 0.4038761498110132,\n",
      "    \"r\": 0.4868177082884032\n",
      "  },\n",
      "  \"rouge-2\": {\n",
      "    \"f\": 0.12063683827343027,\n",
      "    \"p\": 0.11796532978667465,\n",
      "    \"r\": 0.14132459116171703\n",
      "  },\n",
      "  \"rouge-l\": {\n",
      "    \"f\": 0.3623998227107736,\n",
      "    \"p\": 0.37402187883402294,\n",
      "    \"r\": 0.45107927405471415\n",
      "  }\n",
      "}\n",
      "\n",
      "k10\n",
      "saved ../../to_gpt2/generation_ori_i.txt\n",
      "saved ../../to_gpt2/generation_k10_i.txt\n",
      "saved ../../to_gpt2/generation_ori_d.txt\n",
      "saved ../../to_gpt2/generation_k10_d.txt\n",
      "BLEU = 27.43, 69.1/49.0/25.1/9.6 (BP=0.914, ratio=0.917, hyp_len=93253, ref_len=101657)\n",
      "It is not advisable to publish scores from multi-bleu.perl.  The scores depend on your tokenizer, which is unlikely to be reproducible from your paper or consistent across research groups.  Instead you should detokenize then use mteval-v14.pl, which has a standard tokenization.  Scores from multi-bleu.perl can still be used for internal purposes when you have a consistent tokenizer.\n",
      "BLEU = 7.74, 46.9/14.6/4.9/1.9 (BP=0.867, ratio=0.875, hyp_len=457191, ref_len=522308)\n",
      "It is not advisable to publish scores from multi-bleu.perl.  The scores depend on your tokenizer, which is unlikely to be reproducible from your paper or consistent across research groups.  Instead you should detokenize then use mteval-v14.pl, which has a standard tokenization.  Scores from multi-bleu.perl can still be used for internal purposes when you have a consistent tokenizer.\n",
      "{\n",
      "  \"rouge-1\": {\n",
      "    \"f\": 0.592563505322009,\n",
      "    \"p\": 0.5731734515902066,\n",
      "    \"r\": 0.6611950481219133\n",
      "  },\n",
      "  \"rouge-2\": {\n",
      "    \"f\": 0.4655588367473421,\n",
      "    \"p\": 0.45623698484674485,\n",
      "    \"r\": 0.5143586306273291\n",
      "  },\n",
      "  \"rouge-l\": {\n",
      "    \"f\": 0.3292333978499195,\n",
      "    \"p\": 0.3372039771022687,\n",
      "    \"r\": 0.39504082070810487\n",
      "  }\n",
      "}\n",
      "{\n",
      "  \"rouge-1\": {\n",
      "    \"f\": 0.40746295595164134,\n",
      "    \"p\": 0.40417305015977006,\n",
      "    \"r\": 0.45661810563361505\n",
      "  },\n",
      "  \"rouge-2\": {\n",
      "    \"f\": 0.11028158265980506,\n",
      "    \"p\": 0.11250807375942867,\n",
      "    \"r\": 0.12446890276592248\n",
      "  },\n",
      "  \"rouge-l\": {\n",
      "    \"f\": 0.3510015677739845,\n",
      "    \"p\": 0.37380211169016353,\n",
      "    \"r\": 0.42261406864882456\n",
      "  }\n",
      "}\n",
      "\n",
      "k30\n",
      "saved ../../to_gpt2/generation_ori_i.txt\n",
      "saved ../../to_gpt2/generation_k30_i.txt\n",
      "saved ../../to_gpt2/generation_ori_d.txt\n",
      "saved ../../to_gpt2/generation_k30_d.txt\n",
      "BLEU = 26.30, 63.8/43.7/21.7/7.9 (BP=1.000, ratio=1.010, hyp_len=102649, ref_len=101657)\n",
      "It is not advisable to publish scores from multi-bleu.perl.  The scores depend on your tokenizer, which is unlikely to be reproducible from your paper or consistent across research groups.  Instead you should detokenize then use mteval-v14.pl, which has a standard tokenization.  Scores from multi-bleu.perl can still be used for internal purposes when you have a consistent tokenizer.\n",
      "BLEU = 7.29, 43.2/12.6/4.0/1.5 (BP=0.971, ratio=0.972, hyp_len=507469, ref_len=522308)\n",
      "It is not advisable to publish scores from multi-bleu.perl.  The scores depend on your tokenizer, which is unlikely to be reproducible from your paper or consistent across research groups.  Instead you should detokenize then use mteval-v14.pl, which has a standard tokenization.  Scores from multi-bleu.perl can still be used for internal purposes when you have a consistent tokenizer.\n",
      "{\n",
      "  \"rouge-1\": {\n",
      "    \"f\": 0.5660780068224838,\n",
      "    \"p\": 0.5725362104465712,\n",
      "    \"r\": 0.6024353289788477\n",
      "  },\n",
      "  \"rouge-2\": {\n",
      "    \"f\": 0.4390475205076069,\n",
      "    \"p\": 0.4489618922454053,\n",
      "    \"r\": 0.46293394637779034\n",
      "  },\n",
      "  \"rouge-l\": {\n",
      "    \"f\": 0.3181376948360201,\n",
      "    \"p\": 0.3402702416410297,\n",
      "    \"r\": 0.3611108295590807\n",
      "  }\n",
      "}\n",
      "{\n",
      "  \"rouge-1\": {\n",
      "    \"f\": 0.39162862893477496,\n",
      "    \"p\": 0.4070098771980424,\n",
      "    \"r\": 0.4184683726604411\n",
      "  },\n",
      "  \"rouge-2\": {\n",
      "    \"f\": 0.09961800606737278,\n",
      "    \"p\": 0.10664807873408651,\n",
      "    \"r\": 0.10733092387074827\n",
      "  },\n",
      "  \"rouge-l\": {\n",
      "    \"f\": 0.33733747049361634,\n",
      "    \"p\": 0.37559926369716196,\n",
      "    \"r\": 0.3865656876208457\n",
      "  }\n",
      "}\n",
      "\n",
      "p99\n",
      "saved ../../to_gpt2/generation_ori_i.txt\n",
      "saved ../../to_gpt2/generation_p99_i.txt\n",
      "saved ../../to_gpt2/generation_ori_d.txt\n",
      "saved ../../to_gpt2/generation_p99_d.txt\n",
      "BLEU = 23.59, 59.6/39.6/19.3/6.8 (BP=1.000, ratio=1.072, hyp_len=109004, ref_len=101657)\n",
      "It is not advisable to publish scores from multi-bleu.perl.  The scores depend on your tokenizer, which is unlikely to be reproducible from your paper or consistent across research groups.  Instead you should detokenize then use mteval-v14.pl, which has a standard tokenization.  Scores from multi-bleu.perl can still be used for internal purposes when you have a consistent tokenizer.\n",
      "BLEU = 6.37, 39.2/10.8/3.3/1.2 (BP=1.000, ratio=1.085, hyp_len=566532, ref_len=522308)\n",
      "It is not advisable to publish scores from multi-bleu.perl.  The scores depend on your tokenizer, which is unlikely to be reproducible from your paper or consistent across research groups.  Instead you should detokenize then use mteval-v14.pl, which has a standard tokenization.  Scores from multi-bleu.perl can still be used for internal purposes when you have a consistent tokenizer.\n",
      "{\n",
      "  \"rouge-1\": {\n",
      "    \"f\": 0.5372224774896351,\n",
      "    \"p\": 0.5646150621876528,\n",
      "    \"r\": 0.5525906910415981\n",
      "  },\n",
      "  \"rouge-2\": {\n",
      "    \"f\": 0.41352747440265814,\n",
      "    \"p\": 0.4375024524738855,\n",
      "    \"r\": 0.42300594731987107\n",
      "  },\n",
      "  \"rouge-l\": {\n",
      "    \"f\": 0.300144881616305,\n",
      "    \"p\": 0.3352649650654293,\n",
      "    \"r\": 0.329765575595062\n",
      "  }\n",
      "}\n",
      "{\n",
      "  \"rouge-1\": {\n",
      "    \"f\": 0.3714793877701419,\n",
      "    \"p\": 0.40785461327552336,\n",
      "    \"r\": 0.3813116646344861\n",
      "  },\n",
      "  \"rouge-2\": {\n",
      "    \"f\": 0.09062676594718024,\n",
      "    \"p\": 0.10183461480449157,\n",
      "    \"r\": 0.0942037567841985\n",
      "  },\n",
      "  \"rouge-l\": {\n",
      "    \"f\": 0.3175385112119669,\n",
      "    \"p\": 0.37624055623728486,\n",
      "    \"r\": 0.3515817970225986\n",
      "  }\n",
      "}\n",
      "\n",
      "time: 16min 13s\n"
     ]
    }
   ],
   "source": [
    "for tag in data.gens:\n",
    "    print(tag)\n",
    "    data.gen = tag\n",
    "    data.to_bleu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = evaluation('../../to_gpt2/recipe1M_1118/val/y/', 'ori')\n",
    "\n",
    "data.append_dic('../../to_gpt2/generation_201911118_k1_val/', 'k1')\n",
    "data.ingr_f1_freq(root=True)\n",
    "\n",
    "data.append_dic('../../to_gpt2/generation_201911118_k3_val/', 'k3')\n",
    "data.ingr_f1_freq(root=True)\n",
    "\n",
    "data.append_dic('../../to_gpt2/generation_201911118_k5_val/', 'k5')\n",
    "data.ingr_f1_freq(root=True)\n",
    "\n",
    "data.append_dic('../../to_gpt2/generation_201911118_k10_val/', 'k10')\n",
    "data.ingr_f1_freq(root=True)\n",
    "\n",
    "data.append_dic('../../to_gpt2/generation_201911118_k30_val/', 'k30')\n",
    "data.ingr_f1_freq(root=True)\n",
    "\n",
    "data.append_dic('../../to_gpt2/generation_201911118_p99_val/', 'p99')\n",
    "data.ingr_f1_freq(root=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load ../../to_gpt2/recipe1M_1118/val/y/\n",
      "load ../../to_gpt2/generation_201911118_k1_val/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|ââââââââââ| 4000/4000 [26:39<00:00,  2.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5186078582567383\n",
      "load ../../to_gpt2/generation_201911118_k3_val/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|ââââââââââ| 4000/4000 [26:54<00:00,  2.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5270206439868736\n",
      "load ../../to_gpt2/generation_201911118_k10_val/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|ââââââââââ| 4000/4000 [28:50<00:00,  1.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.53722605176261\n",
      "load ../../to_gpt2/generation_201911118_k30_val/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|ââââââââââ| 4000/4000 [30:39<00:00,  1.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5432887709524692\n",
      "load ../../to_gpt2/generation_201911118_p99_val/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|ââââââââââ| 4000/4000 [33:03<00:00,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5555177256269578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5555177256269578"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2h 26min 12s\n"
     ]
    }
   ],
   "source": [
    "data = evaluation('../../to_gpt2/recipe1M_1118/val/y/', 'ori')\n",
    "\n",
    "data.append_dic('../../to_gpt2/generation_201911118_k1_val/', 'k1')\n",
    "data.instr_tree(stem_only = False)\n",
    "\n",
    "data.append_dic('../../to_gpt2/generation_201911118_k3_val/', 'k3')\n",
    "data.instr_tree(stem_only = False)\n",
    "\n",
    "data.append_dic('../../to_gpt2/generation_201911118_k10_val/', 'k10')\n",
    "data.instr_tree(stem_only = False)\n",
    "\n",
    "data.append_dic('../../to_gpt2/generation_201911118_k30_val/', 'k30')\n",
    "data.instr_tree(stem_only = False)\n",
    "\n",
    "data.append_dic('../../to_gpt2/generation_201911118_p99_val/', 'p99')\n",
    "data.instr_tree(stem_only = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load ../../to_gpt2/recipe1M_1118/val/y/\n",
      "load ../../to_gpt2/generation_201911118_k1_val/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|ââââââââââ| 4000/4000 [16:27<00:00,  4.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.48086849711629653\n",
      "load ../../to_gpt2/generation_201911118_k3_val/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|ââââââââââ| 4000/4000 [15:56<00:00,  4.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4834859582582718\n",
      "load ../../to_gpt2/generation_201911118_k10_val/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|ââââââââââ| 4000/4000 [16:41<00:00,  3.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4921781118409965\n",
      "load ../../to_gpt2/generation_201911118_k30_val/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|ââââââââââ| 4000/4000 [17:24<00:00,  3.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.49803296322476104\n",
      "load ../../to_gpt2/generation_201911118_p99_val/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|ââââââââââ| 4000/4000 [18:11<00:00,  3.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5114497360289872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5114497360289872"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1h 24min 45s\n"
     ]
    }
   ],
   "source": [
    "data = evaluation('../../to_gpt2/recipe1M_1118/val/y/', 'ori')\n",
    "\n",
    "data.append_dic('../../to_gpt2/generation_201911118_k1_val/', 'k1')\n",
    "data.instr_tree(stem_only = True)\n",
    "\n",
    "data.append_dic('../../to_gpt2/generation_201911118_k3_val/', 'k3')\n",
    "data.instr_tree(stem_only = True)\n",
    "\n",
    "data.append_dic('../../to_gpt2/generation_201911118_k5_val/', 'k5')\n",
    "data.instr_tree(stem_only = True)\n",
    "\n",
    "data.append_dic('../../to_gpt2/generation_201911118_k10_val/', 'k10')\n",
    "data.instr_tree(stem_only = True)\n",
    "\n",
    "data.append_dic('../../to_gpt2/generation_201911118_k30_val/', 'k30')\n",
    "data.instr_tree(stem_only = True)\n",
    "\n",
    "data.append_dic('../../to_gpt2/generation_201911118_p99_val/', 'p99')\n",
    "data.instr_tree(stem_only = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['water', 'pepper', 'rice', 'butter', 'juice']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 61.4 ms\n"
     ]
    }
   ],
   "source": [
    "data.dic[786989]['ori_ingr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['butter', 'salt', 'lemon juice', 'long grain rice']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 51.3 ms\n"
     ]
    }
   ],
   "source": [
    "data.dic[786989]['k1_ingr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['put rice and water in a large pan and bring to a boil',\n",
       " 'reduce heat and simmer, covered, about 20 to 25 minutes or until rice is tender and the water is absorbed',\n",
       " 'add butter and stir until melted',\n",
       " 'add lemon juice, salt and pepper and stir to blend',\n",
       " ' ']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 52.8 ms\n"
     ]
    }
   ],
   "source": [
    "data.dic[786989]['k3_instr'].split('. ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bring the water to a boil in a saucepan and add salt and rice',\n",
       " 'when the water returns to a boil, let rice boil vigorously for exactly 17 minutes',\n",
       " 'drain in a colander run hot water over the rice',\n",
       " 'drain again',\n",
       " 'add the butter, salt and pepper',\n",
       " 'sprinkle with lemon juice and toss until the grains are coated',\n",
       " ' ']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 21.3 ms\n"
     ]
    }
   ],
   "source": [
    "data.dic[786989]['ori_instr'].split('. ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### human judgements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1029720it [00:32, 31819.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 33.9 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "layer1 = json.load(open('/data/yueliu/RecipeAnalytics_201906/raw_data/recipe1M/layer1.json','r'))\n",
    "\n",
    "recipe1M_ny = load_pickle('../big_data/recipe1M_ny.pickle')\n",
    "new_data, idx = [], []\n",
    "for i, v in tqdm.tqdm(enumerate(recipe1M_ny)):\n",
    "    ingr = []\n",
    "    for ny_full_ingredients in v['ny_full_ingredients']:\n",
    "        if 'half and half' in ny_full_ingredients['input']:\n",
    "            ingr.append('half and half')\n",
    "        elif type(ny_full_ingredients['name'])==float:\n",
    "            break\n",
    "        else:\n",
    "            ingr.append(ny_full_ingredients['name'])\n",
    "    if len(ingr)>=2 and len(v['instructions']) >=2:\n",
    "        recipe = {'ingredients':ingr, 'title':v['title'], 'instructions': v['instructions']}\n",
    "        new_data.append(recipe)\n",
    "        idx.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "908471\n",
      "[   'shallots',\n",
      "    'garlic',\n",
      "    'peanut oil',\n",
      "    'shrimps',\n",
      "    'sesame seeds',\n",
      "    'peanuts',\n",
      "    'cilantro',\n",
      "    'lime']\n",
      "[   'garlic',\n",
      "    'shallots',\n",
      "    'salt',\n",
      "    'olive oil',\n",
      "    'sour cream',\n",
      "    'salt',\n",
      "    'salt',\n",
      "    'salt',\n",
      "    'sour cream',\n",
      "    'salt',\n",
      "    'salt',\n",
      "    'garlic',\n",
      "    'sour cream',\n",
      "    'salt',\n",
      "    'salt',\n",
      "    'salt',\n",
      "    'sour cream',\n",
      "    'salt',\n",
      "    'salt',\n",
      "    'salt',\n",
      "    'sour cream',\n",
      "    'salt',\n",
      "    'salt',\n",
      "    'sour cream',\n",
      "    'salt',\n",
      "    'salt',\n",
      "    'salt',\n",
      "    'salt',\n",
      "    'salt',\n",
      "    'sour cream',\n",
      "    'salt',\n",
      "    'salt',\n",
      "    'salt',\n",
      "    'salt',\n",
      "    'sour cream',\n",
      "    'salt',\n",
      "    'salt',\n",
      "    'salt',\n",
      "    'salt',\n",
      "    'sour cream',\n",
      "    'salt',\n",
      "    'salt',\n",
      "    'salt',\n",
      "    'salt',\n",
      "    'salt',\n",
      "    'salt',\n",
      "    'sour cream',\n",
      "    'salt',\n",
      "    'salt',\n",
      "    'salt',\n",
      "    'salt',\n",
      "    'salt',\n",
      "    'salt',\n",
      "    'salt',\n",
      "    'salt',\n",
      "    'sour cream',\n",
      "    'salt',\n",
      "    'salt',\n",
      "    'salt',\n",
      "    'salt',\n",
      "    'salt',\n",
      "    'salt',\n",
      "    'salt',\n",
      "    'salt',\n",
      "    'salt',\n",
      "    'salt',\n",
      "    'salt',\n",
      "    'salt',\n",
      "    'salt',\n",
      "    'salt',\n",
      "    'salt',\n",
      "    'salt',\n",
      "    'salt',\n",
      "    'salt',\n",
      "    'salt',\n",
      "    'salt',\n",
      "    'salt',\n",
      "    'salt',\n",
      "    'salt']\n",
      "0.0379746835443038\n",
      "0.375\n",
      "0.06896551724137931\n",
      "[   'shallots',\n",
      "    'garlic',\n",
      "    'peanut oil',\n",
      "    'shrimps',\n",
      "    'sesame seeds',\n",
      "    'peanuts',\n",
      "    'cilantro',\n",
      "    'lime']\n",
      "[   'garlic clove',\n",
      "    'olive oil to fry',\n",
      "    'shallots',\n",
      "    'cayenne pepper',\n",
      "    'salt',\n",
      "    'sour cream',\n",
      "    's']\n",
      "0.2857142857142857\n",
      "0.25\n",
      "0.26666666666666666\n",
      "[   'shallots',\n",
      "    'garlic',\n",
      "    'peanut oil',\n",
      "    'shrimps',\n",
      "    'sesame seeds',\n",
      "    'peanuts',\n",
      "    'cilantro',\n",
      "    'lime']\n",
      "['garlic', 'red chile peppers', 'cayenne', 'eggplants', 'shallots']\n",
      "0.4\n",
      "0.25\n",
      "0.3076923076923077\n",
      "[   'shallots',\n",
      "    'garlic',\n",
      "    'peanut oil',\n",
      "    'shrimps',\n",
      "    'sesame seeds',\n",
      "    'peanuts',\n",
      "    'cilantro',\n",
      "    'lime']\n",
      "[   'salt',\n",
      "    'sour cream',\n",
      "    'garlic clove',\n",
      "    'whole egg whites',\n",
      "    'ichokes',\n",
      "    'small shallots',\n",
      "    'olive oil',\n",
      "    'plain yoghurt']\n",
      "0.25\n",
      "0.25\n",
      "0.25\n",
      "\n",
      "37755\n",
      "['cans cream of mushroom soup', 'milk', 'tuna']\n",
      "['potato chips', 'milk', 'tuna', 'tuna', 'milk', 'salt', 'bow macaroni']\n",
      "0.2857142857142857\n",
      "0.5\n",
      "0.36363636363636365\n",
      "['cans cream of mushroom soup', 'milk', 'tuna']\n",
      "[   'tuna',\n",
      "    'milk',\n",
      "    'potato chips',\n",
      "    'milk',\n",
      "    'tuna',\n",
      "    'salt',\n",
      "    'bow macaroni',\n",
      "    'pepper']\n",
      "0.25\n",
      "0.5\n",
      "0.3333333333333333\n",
      "['cans cream of mushroom soup', 'milk', 'tuna']\n",
      "[   'milk',\n",
      "    'tuna',\n",
      "    'potato chips',\n",
      "    'tuna',\n",
      "    'milk',\n",
      "    'macaroni noodles',\n",
      "    'cubed cheddar cheese']\n",
      "0.2857142857142857\n",
      "0.5\n",
      "0.36363636363636365\n",
      "['cans cream of mushroom soup', 'milk', 'tuna']\n",
      "[   'tuna',\n",
      "    'potato chips',\n",
      "    'lic onion soup',\n",
      "    'milk',\n",
      "    'milk',\n",
      "    'thin noodles',\n",
      "    'salt']\n",
      "0.42857142857142855\n",
      "0.75\n",
      "0.5454545454545454\n",
      "\n",
      "time: 741 ms\n"
     ]
    }
   ],
   "source": [
    "# Compare with ground truth\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "'''Usuage:\n",
    "pp.pprint(data.dic[786989]['ori_ingr'])\n",
    "'''\n",
    "\n",
    "from random import sample \n",
    "sampled_id = sample(list(data.dic.keys()),2)\n",
    "\n",
    "def show(true, pred):\n",
    "    pp.pprint(true)\n",
    "    pp.pprint(pred)\n",
    "    true, pred = sp.root(true), sp.root(pred)\n",
    "    scores = metrics(true, pred)\n",
    "    print(scores.precision_freq())\n",
    "    print(scores.recall_freq())\n",
    "    print(scores.f1_freq())\n",
    "        \n",
    "for k in sampled_id:\n",
    "    print(k)\n",
    "    true = data.dic[k]['ori_ingr']\n",
    "    pred = data.dic[k]['k1_ingr']\n",
    "    show(true, pred)\n",
    "    \n",
    "    true = data.dic[k]['ori_ingr']\n",
    "    pred = data.dic[k]['k3_ingr']\n",
    "    show(true, pred)\n",
    "    \n",
    "    true = data.dic[k]['ori_ingr']\n",
    "    pred = data.dic[k]['k10_ingr']\n",
    "    show(true, pred)\n",
    "        \n",
    "    true = data.dic[k]['ori_ingr']\n",
    "    pred = data.dic[k]['p99_ingr']\n",
    "    show(true, pred)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Make Ur Own Herbal Shampoo\n",
      "[   {'text': '14 cup of your favorite herbal tea (strongly brewed)'},\n",
      "    {'text': '8 ounces liquid castile soap'}]\n",
      "add soap to tea. stir over low heat until well blended. store in a capped bottle.  \n",
      "\n",
      "mix all ingredients together. apply to your face. rinse off with warm water.  \n",
      "pour all ingredients into a blender. blend until smooth. pour into a glass and enjoy.  \n",
      "mix all ingredients together well. apply to your face and neck. rinse with warm water and pat dry .  \n",
      "---------------\n",
      "Mojito\n",
      "[   {'text': '6 fresh mint leaves, shredded & mashed'},\n",
      "    {'text': '1 tablespoon sugar'},\n",
      "    {'text': '12 fresh lime, juice of'},\n",
      "    {'text': '2 ounces light rum'},\n",
      "    {'text': 'chilled club soda'},\n",
      "    {'text': 'ice cube'},\n",
      "    {'text': 'fresh mint sprig (for garnish)'},\n",
      "    {'text': 'lime slice (for garnish)'}]\n",
      "in a tall glass, stir mint, sugar and lime juice until sugar is dissolved and stir in rum. add ice cubes and top off drink with club soda or seltzer water. stir drink well and garnish with mint and lime.  \n",
      "\n",
      "in a cocktail shaker, muddle the mint leaves with the sugar. add the rum, lime juice and ice and shake well. strain into an ice filled collins glass and top with the club soda. garnish with the mint sprig and lime slice.  \n",
      "combine the mint, lime juice and sugar. stir until the sugar dissolves, then refrigerate. just before serving, stir the rum into the lime mixture. fill a tall glass with ice. add the club soda, then top with the mint syrup. garnish with a slice of lime.  \n",
      "combine the rum, sugar and lime zest in a small pitcher and stir until the sugar dissolves. pour over ice into 4 glasses. garnish with mint sprigs. top each glass with 1/4 cup club soda and 1/2 cup rum. garnish each serving with a slice of fresh mint leaf.  \n",
      "---------------\n",
      "Hot And Sour Chicken Soup\n",
      "[   {'text': '1 Tablespoon Cooking Oil,(Coconut Or Olive Work Great)'},\n",
      "    {'text': '2 whole Boneless, Skinless Chicken Breasts, Diced'},\n",
      "    {'text': '1/2 pounds Shiitake Mushrooms, Stems Removed And Sliced'},\n",
      "    {'text': '3 cloves Garlic, Minced'},\n",
      "    {   'text': '1 teaspoon Garlic Chili Paste Or More, Dependent On How Spicy '\n",
      "                '(Optional)'},\n",
      "    {'text': '1 Tablespoon Fresh Ginger, Grated'},\n",
      "    {'text': '1/4 cups Cornstarch'},\n",
      "    {'text': '8 cups Chicken Stock'},\n",
      "    {'text': '3 Tablespoons Soy Sauce, Or To Taste'},\n",
      "    {'text': '5 ounces, weight Bamboo Shoot Strips, Rinsed And Drained'},\n",
      "    {'text': '1 Tablespoon Plus 2 Teaspoon Honey'},\n",
      "    {'text': '4 Tablespoons Rice Vinegar, Or To Taste'},\n",
      "    {'text': '3 teaspoons Sesame Seed Oil Or To Taste'},\n",
      "    {'text': '3 whole Eggs'},\n",
      "    {'text': '1 Tablespoon Water'},\n",
      "    {'text': '10 ounces, weight Firm Tofu, Drained And Cubed'},\n",
      "    {'text': '8 ounces, weight Bean Sprouts'},\n",
      "    {'text': '3 whole Scallions, Diced'}]\n",
      "in a large stock pot over medium heat add oil, chicken, mushrooms, garlic, chili paste and ginger. saute until mushrooms soften. in a bowl combine cornstarch with chicken stock until cornstarch is totally dissolved. pour chicken stock slurry into the pot with the mushrooms and chicken, scraping any brown bits off the bottom of the pan. add soy sauce and bring mixture to a simmer and cook for about 15 minutes or until chicken is cooked through. add bamboo shoots. remove soup from heat and add honey, rice vinegar and sesame seed oil. at this point taste the soup and adjust soy, honey, rice vinegar and sesame seed oil to taste. combine eggs with 1 tablespoon of water and whisk until thoroughly combined. stir pot in a circle going in one direction. slowly pour eggs in a steady stream into the hot soup. stir until eggs solidify. add tofu and bean sprouts. ladle soup into serving bowls. garnish bowls with scallions and serve immediately.  \n",
      "\n",
      "in a large saucepan, heat oil over medium high heat. add chicken and cook, stirring, until browned, about 5 minutes. add garlic, ginger, and chili paste and cook, stirring, for 30 seconds. add stock, soy sauce, and mushrooms and bring to a boil. reduce heat to low and simmer, covered, for 10 minutes. in a small bowl, combine cornstarch and 1 tablespoon water. add to soup and cook, stirring, until soup thickens.  \n",
      "in a large saucepan, heat oil. add garlic and ginger. saute until fragrant. add chicken, stir to coat with oil. add stock, bring to boil, reduce to simmer. simmer for 10 minutes. add mushrooms, stir. add soy sauce. mix cornstarch with 2 tablespoons water. add to the soup and stir until soup boils and thickens. serve immediately.  \n",
      "combine cornstarch, chicken stock, soy sauce, chicken, mushrooms, garlic and garlic chili paste in a large pot and simmer until the mushrooms are softened, about 10 minutes. stir in the chicken, ginger and garlic, and simmer until the liquid is slightly reduced, about 2 minutes more. serve in bowls.  \n",
      "---------------\n",
      "Orange Blossom Zucchini\n",
      "[   {'text': '2 large zucchini or 3 small zucchini'},\n",
      "    {'text': '2 tablespoons butter'},\n",
      "    {'text': '14 cup Cointreau liqueur'},\n",
      "    {'text': '1 tablespoon orange marmalade'},\n",
      "    {'text': 'fresh ground pepper, to taste'}]\n",
      "julienne zucchini into 2 inch sticks. saute in butter until tende crisp, about 3 minutes. add cointreau and marmalade and heat through. sprinkle lightly with pepper and serve warm.  \n",
      "\n",
      "peel the zucchini and cut into 1/2 inch thick slices. in a large skillet, melt the butter over medium heat. add the zucchini and cook, stirring, for about 5 minutes. add the marmalade, cointreau, and pepper and cook, stirring, for about 2 minutes.  \n",
      "preheat oven to 400. cut the zucchini lengthwise, and then cut each length into 1/4 inch slices, leaving the ends attached. arrange in a single layer in a shallow baking dish, and sprinkle with the orange marmalade, butter, and cointreau. bake for 20 minutes.  \n",
      "peel and slice zucchini into rounds about 1/4 inch thick. melt butter in a large skillet. saute zucchini until golden brown, about 5 minutes. add marmalade, cointreau, salt, pepper and cook until melted and well mixed.  \n",
      "---------------\n",
      "Barbecue Chicken Hoecakes with Vinegar Slaw\n",
      "[   {'text': '1 1/2 pounds skinless boneless chicken thighs'},\n",
      "    {'text': 'Olive oil'},\n",
      "    {'text': 'Brown Sugar and Coffee Barbecue Sauce'},\n",
      "    {'text': '1 cup yellow cornmeal'},\n",
      "    {'text': '1/2 cup all purpose flour'},\n",
      "    {'text': '2 teaspoons sugar'},\n",
      "    {'text': '1 teaspoon baking powder'},\n",
      "    {'text': '3/4 teaspoon salt'},\n",
      "    {'text': '1 cup water'},\n",
      "    {   'text': '2 tablespoons (1/4 stick) butter, melted, plus additional for '\n",
      "                'griddle'},\n",
      "    {'text': '3/4 cup coarsely grated sharp cheddar cheese'},\n",
      "    {'text': 'Vinegar Slaw'},\n",
      "    {   'text': 'Special equipment: 2 cups wood chips (such as hickory, apple, '\n",
      "                'or cherry), soaked in 2 cups water for 1 hour, then drained; '\n",
      "                '13x9x1-inch disposable aluminum foil baking pan'}]\n",
      "prepare barbecue . spread drained wood chips in disposable foil pan. remove grill racks from barbecue. place foil pan with wood chips directly atop hot coals or over flames . return grill rack to barbecue. brush chicken with oil sprinkle with salt and pepper. when wood chips begin to smoke, place chicken on grill rack above pan with wood chips. cover grill and smoke chicken until cooked through, turning occasionally, about 18 minutes. transfer to large bowl and cool slightly. shred chicken into bite size strips place in same bowl. mix 2 1/2 cups barbecue sauce into chicken. do ahead can be made 1 day ahead. cover and chill. rewarm chicken in barbecue sauce over medium low heat before using, adding more barbecue sauce to moisten mixture, if needed. preheat oven to 300f. mix first 5 ingredients in medium bowl. add 1 cup water and melted butter and whisk until well blended. heat griddle or large nonstick skillet over medium high heat. brush with additional melted butter. working in batches, pour batter by 1/4 cupfuls onto griddle. using back of spoon, immediately spread batter for each cake into oval shape about 4x21/2 inches cook until bottom is golden brown, about 2 minutes. turn cakes over and cook until bottoms are golden brown, 1 to 2 minutes longer. place hoecakes on baking sheet and transfer to oven to keep warm while making remaining cakes. place 2 hoecakes on each of 6 plates sprinkle 1 tablespoon cheddar cheese over each cake. top each with warm chicken in barbecue sauce. spoon vinegar slaw atop chicken and serve.  \n",
      "\n",
      "for the hoecakes preheat the oven to 350 degrees f. in a large bowl, combine the flour, cornmeal, sugar, baking powder and salt. add the butter and mix until the mixture resembles coarse crumbs. add the cheese and mix until just incorporated. add the water and mix until the dough comes together. turn the dough out onto a lightly floured surface and knead until smooth. roll out the dough to 1/2 inch thickness. cut the dough into 2 inch rounds using a biscuit cutter or a glass. place the hoecakes on a baking sheet and bake until golden brown, about 20 minutes. for the slaw in a large bowl, combine the cabbage, carrots, green onions, vinegar, sugar and coffee barbecue sauce. mix well. season with salt and pepper. cover and refrigerate for at least 1 hour before serving. for the hoecakes in a large skillet, heat the oil over medium high heat. add the chicken and cook until browned on all sides, about 5 minutes. add the barbecue sauce and cook until the chicken is cooked through, about 5 minutes more. serve the hoecakes with the slaw.  \n",
      "make barbecue chicken preheat oven to 450 degrees f. remove and discard giblets and neck from chicken. pat chicken dry and sprinkle with salt. heat 1 tablespoon oil in a 12 inch cast iron skillet or ovenproof skillet over moderately high heat until hot but not smoking, then brown the chicken, skin sides down, in 2 batches, turning over once, about 4 minutes total. transfer chicken to a plate and cool. add 1 tablespoon oil to pan and saute onion, celery, bell pepper, and garlic, scraping up brown bits, until softened, about 5 minutes. add barbecue sauce and barbecue sauce can be made 1 day ahead and chilled, covered. bring barbecue chicken to room temperature before proceeding. heat oven to 450 degrees. stir together cornmeal, flour, sugar, baking powder, and salt in a bowl. whisk together milk and egg in a small bowl. whisk milk mixture into cornmeal mixture until combined well, then whisk in butter until just combined. pour batter into skillet, smoothing top. arrange chicken, skin sides down, in skillet and bake in middle of oven until golden and a wooden skewer inserted into center of cornmeal cake comes out clean, 25 to 35 minutes. transfer skillet to a rack and let cornmeal cake stand about 10 minutes. make slaw while barbecue chicken bakes cut cabbage into 2 inch long pieces. cook cabbage in a large nonaluminum saucepan with 2 tablespoons oil over moderately high heat, stirring, until just beginning to soften, about 2 minutes. stir in sugar, vinegar, salt, and pepper. cook, stirring, until cabbage is tender, about 2 minutes. remove from heat and stir in cilantro. cool slaw 10 minutes and stir in jalapeno. serve barbecue chicken with slaw.  \n",
      "make the chicken preheat a grill to medium high heat, or preheat a broiler. brush the chicken with oil and season with salt. grill or broil the chicken skin side down until the skin browns and forms a nice crust, about 10 minutes. flip the chicken and continue to grill or broil, about 4 more minutes. remove the chicken to a plate and let it rest for 5 minutes. meanwhile, make the slaw in a large bowl combine the sugar and coffee and set aside. in a small bowl, whisk together the flour, cornmeal, baking powder and salt. pour in the water, then the butter and continue stirring with a whisk until the dough comes together. turn out the dough onto plastic wrap. press and form into a disk, wrap and chill until firm, about 1 hour. preheat the oven to 350 degrees f. on a lightly floured surface, roll out the dough to 1/2 inch thick. use cookie cutters to cut out shapes and transfer to parchment lined baking sheets. brush the hoecakes with olive oil and grill or broil on the grill, or broil, for 2 to 3 minutes per side, until browned and crisp. serve with the coleslaw. in a medium bowl, whisk together all of the slaw ingredients. season with salt, if needed.  \n",
      "---------------\n",
      "Raspberry Ribbon Pie\n",
      "[   {'text': '2 (3 ounce) packages cream cheese, softened'},\n",
      "    {'text': \"12 cup confectioners' sugar\"},\n",
      "    {'text': '1 dash salt'},\n",
      "    {'text': '1 cup whipping cream, whipped'},\n",
      "    {'text': '9 inches pastry shells, with high fluted edge, baked'},\n",
      "    {'text': '1 (3 ounce) package raspberry gelatin powder'},\n",
      "    {'text': '1 14 cups boiling water'},\n",
      "    {'text': '1 tablespoon lemon juice'},\n",
      "    {'text': '1 (10 ounce) package frozen raspberries in light syrup, thawed'}]\n",
      "in a mixing bowl, beat the cream cheese, sugar and salt until light and fluffy. fold in cream. spread half into pies shell, chill 30 minutes. meanwhile, dissolve gelatin in water add lemon juice and raspberries. carefully spoon half over cream cheese layer. chill until set, about 30 minutes. set aside the remaining gelatin at room temperature. carefully spread remaing cream cheese mixture over top of pie. chill 30 minutes. top with remaining gelatin. chill until firm.  \n",
      "\n",
      "in a small saucepan, combine gelatin and salt. stir in boiling water. stir until gelatin is dissolved. remove from heat. stir in lemon juice. chill until slightly thickened. fold in whipped cream. pour into pastry shell. chill until firm. in a small saucepan, combine gelatin and salt. stir in boiling water. stir until gelatin is dissolved. cool. in a mixing bowl, beat cream cheese and confectioners sugar until smooth. add gelatin mixture beat until smooth. chill until thickened. fold in raspberries. spoon over cream cheese layer. chill until firm.  \n",
      "combine the gelatin and 1/2 cup of boiling water in a small bowl and let stand until softened, about 2 minutes. in a large bowl, beat the cream cheese until smooth. add the sugar, lemon juice, salt and gelatin mixture. mix thoroughly. fold in the whipped cream and raspberries. spoon into the pastry shell. refrigerate until set, about 3 hours.  \n",
      "dissolve gelatine in boiling water. add lemon juice. let cool. beat cream cheese and sugar until fluffy. fold in gelatine, cream and raspberries. pour into pie shell. refrigerate for 3 hours or until set. garnish with whipped cream.  \n",
      "---------------\n",
      "Sunset Dip\n",
      "[   {'text': '8 ounces cream cheese, softened'},\n",
      "    {'text': '1 cup cheddar cheese, grated (I add a bit more)'},\n",
      "    {'text': '1 cup picante sauce or 1 cup chunky salsa'}]\n",
      "spread cream cheese in a 9 microwave safe pie pan. sprinkle with cheddar cheese. microwave on high 2 3 minutes until cheddar cheese is melted. top with sauce. serve with chips.  \n",
      "\n",
      "mix all ingredients together. serve with tortilla chips.  \n",
      "combine cream cheese and picante sauce until well blended. spread on serving tray. top with shredded cheese. serve with tortilla chips, cocktail bread or assorted crackers.  \n",
      "mix all ingredients. serve with tortilla chips.  \n",
      "---------------\n",
      "Shrimp With Broccoli\n",
      "[   {'text': '2 tablespoons olive oil'},\n",
      "    {'text': '1 tablespoon mustard seeds'},\n",
      "    {'text': '4 green onions, sliced'},\n",
      "    {'text': '2 garlic cloves, chopped'},\n",
      "    {'text': '1 tablespoon Dijon mustard (or other spicy mustard)'},\n",
      "    {'text': '12 lemon, juice of, only'},\n",
      "    {'text': '1 teaspoon salt'},\n",
      "    {'text': '1 pinch cayenne pepper'},\n",
      "    {   'text': '1 lb broccoli, large stems discarded and crowns divided into '\n",
      "                'florets'},\n",
      "    {'text': '1 lb large shrimp, cleaned and peeled'}]\n",
      "in a wok or large skillet heat the olive oil over medium high heat. add mustard seeds and cook for 30 seconds or until seeds pop. add green onion and garlic to wok and stir for a few seconds. add mustard, lemon juice, salt and cayenne pepper and cook stirring until smooth and then add 2 tablespoons water, stirring to combine. add broccoli to wok and cover and cook for 3 5 minutes and then add shrimp. cover and cook an additional 3 5 minutes or until broccoli is crisp tender and shrimp is done.  \n",
      "\n",
      "in a large skillet, heat the olive oil over medium high heat. add the mustard seeds and cook until they begin to pop, about 30 seconds. add the garlic and cook, stirring, for about 30 seconds. add the broccoli and cook, stirring, until the broccoli is bright green and crisp tender, about 3 minutes. add the shrimp and cook, stirring, until the shrimp are pink and cooked through, about 3 minutes. stir in the lemon juice, cayenne, and salt. serve immediately.  \n",
      "heat olive oil and mustard seeds over medium high heat. add broccoli, garlic, and green onion and saute for about 2 minutes, stirring constantly. add shrimp and cook for 2 3 minutes, stirring constantly. add cayenne and salt, stirring to combine. reduce heat, cover and simmer for about 2 minutes. remove lid, add lemon juice and lemon zest, stir well, and serve.  \n",
      "combine broccoli, shrimp, green onion, and garlic in a large bowl. in a small bowl, mix lemon juice, olive oil, mustard, cayenne pepper, salt, and mustard seeds. pour over broccoli mixture toss to coat. cover and refrigerate at least 4 hours or up to 8 hours. serve with lemon wedges.  \n",
      "---------------\n",
      "Beef & Bean Burritos\n",
      "[   {'text': '3 tablespoons olive oil'},\n",
      "    {'text': '1 lb ground beef'},\n",
      "    {'text': '14 cup dried onion flakes'},\n",
      "    {'text': '2 tablespoons granulated garlic or 4 garlic cloves'},\n",
      "    {'text': '1 teaspoon cumin powder'},\n",
      "    {'text': '1 teaspoon red pepper flakes'},\n",
      "    {'text': '1 tablespoon white pepper'},\n",
      "    {'text': '1 teaspoon salt'},\n",
      "    {   'text': '12 teaspoon fresh ground black pepper or 1 teaspoon ground '\n",
      "                'black pepper'},\n",
      "    {'text': '1 (8 ounce) package taco seasoning'},\n",
      "    {'text': '1 (16 ounce) can refried beans'},\n",
      "    {'text': '1 (16 ounce) can chili beans'},\n",
      "    {'text': '14 cup water'},\n",
      "    {'text': '8 large tortillas'},\n",
      "    {'text': '1 cup monterey jack cheese'},\n",
      "    {'text': '2 links chorizo sausage (optional)'},\n",
      "    {'text': '1 tablespoon dried chipotle powder (optional)'}]\n",
      "brown beef in olive oil. add the onions, garlic, cumin, white pepper, red pepper flakes, black pepper, and salt. add chipotle powder if used. when the beef has browned, add thee taco seasoning and water and stir in well. now add the refried beans and chili beans and mix in well. do not drain the chili beans. . simmer for 10 minutes to allow the beans to heat and the flavors to blend. soften tortillas with steam, hot oil, or warm water. coat 8 large ramekins or a muffin pan with large cups with cooking spray . shape the tortillas into cups in the ramekins or muffin pan. if water was used to soften tortillas, lightly coat them with oil. place the shaped tortillas in an oven pre heated to 400 deg. f. bake for 7 to 10 minutes until tortillas are browned. remove shaped tortillas from oven and fill with the hot beef/bean mixture. top each with shredded cheese. return to oven for 3 to 5 minutes to melt the cheese. cool for about 3 minutes then remove them from the ramekins or muffin pan. place them on serving dishes and enjoy. this dish has a moderate zing so the faint of heart may not enjoy it. makes 8 hearty servings. may be served with pico de gallo or a lettuce tomato salad or spanish rice. also, these could be topped with a zesty red or green salsa if desired.  \n",
      "\n",
      "in a large skillet, heat olive oil over medium high heat. add ground beef and chorizo and cook until browned. drain fat. add onion, garlic, and chipotle pepper. cook until onion is tender. add taco seasoning, water, and refried beans. stir to combine. add ground beef mixture to a large skillet. add taco seasoning and chili beans. stir to combine. add salt and pepper to taste. cook until heated through. warm tortillas in microwave for about 30 seconds. spoon about 1/2 cup of the beef mixture into the center of each tortilla. sprinkle with cheese. fold tortilla over filling. serve with salsa, guacamole, and sour cream.  \n",
      "in a skillet over medium heat, saute ground beef, chorizo and onions until meat is no longer pink drain fat and set meat mixture aside. in a large pot, combine water, refried beans, taco seasoning and chipotle chili powder. bring the mixture to a boil. add the meat mixture and simmer for 10 minutes or until heated through. add the chiles, cumin, garlic, salt, black and red peppers and stir to combine. remove from heat and let cool. to assemble, place 1/4 cup of the meat mixture in the center of a warmed flour tortilla and top with a few tablespoons of the bean mixture and cheese. fold up tortilla and enjoy. repeat the process for remaining burritos.  \n",
      "start by heating a large nonstick saute or frying pan on medium high. add beef and chorizo. brown meat. add garlic, onion and peppers. cook for 2 minutes. add chili powder, cumin, salt, and pepper and cook another 2 minutes. add refried beans and water. stir. cook on medium for about 5 minutes, or until mixture thickens a bit. add taco seasoning and chipotle chili powder and stir. remove from heat and add shredded cheese. stir well to combine. to prepare the burritos, place about a tablespoon of filling on one side of a tortilla. roll tortilla around the filling. place seam side down in an 8x8 inch casserole dish. repeat with remaining tortillas. pour enchilada sauce over the burritos. sprinkle with remaining cheese and cover enchilada sauce with foil. bake for 25 minutes. serve warm with sour cream and salsa.  \n",
      "---------------\n",
      "Strawberry Preserves\n",
      "[   {'text': '6 cups strawberries, cut up'},\n",
      "    {'text': '3 cups sugar'},\n",
      "    {'text': '1 (1 3/4 ounce) box Sure-Jell'},\n",
      "    {'text': '2 (3 ounce) boxes strawberry Jell-O gelatin dessert'},\n",
      "    {'text': '12 cup water'}]\n",
      "combine strawberries sugar and water. boil for 25 30 minutes. add jello and sure jell. cook 2 minutes. scoop off foam with a metal spoon. put in sterilized jars. turn upside down to seal or put in a cool water bath.  \n",
      "\n",
      "dissolve jello in boiling water. add strawberries and sugar. stir until sugar is dissolved. add sure jell to the strawberry mixture. pour into a 9x13 inch pan. let set overnight. cut into squares.  \n",
      "dissolve jello in boiling water. add sugar and stir until dissolved. add strawberries, stir and let stand for about 1 hour. add sure jell to the fruit mixture, stir and let stand for another hour. pour into a 13x9x2 pan and refrigerate overnight. slice and serve.  \n",
      "dissolve jello in hot water and add strawberries. pour into a large bowl and stir until all berries are coated with the jello. add sugar stir to dissolve. add sure jel. place mixture in a jelly bag, and let stand for about 1 hour. when mixture has set, add strawberries with the juice. place in refrigerator and let set up. when ready to serve, add the strawberries with the juice and sugar into a punch bowl.  \n",
      "---------------\n",
      "time: 96.9 ms\n"
     ]
    }
   ],
   "source": [
    "sampled_id = sample(list(data.dic.keys()),10)\n",
    "for k in sampled_id:\n",
    "    print(layer1[idx[k]]['title'])\n",
    "    pp.pprint(layer1[idx[k]]['ingredients'])\n",
    "    print(data.dic[k]['ori_instr'])\n",
    "    print()\n",
    "    print(data.dic[k]['k1_instr'])\n",
    "    print(data.dic[k]['k3_instr'])\n",
    "    print(data.dic[k]['k5_instr'])\n",
    "    print('---'*5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'melt away peppermint wreaths'\n",
      "butter\n",
      "confectioner sugar\n",
      "all purpose flour\n",
      "peppermint extract\n",
      "drop\n",
      "red food coloring\n",
      "green food coloring\n",
      "--------------------\n",
      "'s0 buttery brioche'\n",
      "flour bread\n",
      "sugar\n",
      "yeast\n",
      "salt\n",
      "egg\n",
      "butter\n",
      "--------------------\n",
      "'brussels sprout salad with avocado pumpkin seeds'\n",
      "lemon juice\n",
      "dijon mustard\n",
      "olive oil\n",
      "salt\n",
      "pepper\n",
      "brussels\n",
      "pumpkin seed\n",
      "avocado\n",
      "--------------------\n",
      "'mint chocolate chip cookies'\n",
      "butter\n",
      "sugar\n",
      "vanilla extract\n",
      "mint extract\n",
      "green food coloring\n",
      "whole egg\n",
      "13 cup\n",
      "all purpose flour\n",
      "baking powder\n",
      "bag\n",
      "semi sweet chocolate chip\n",
      "--------------------\n",
      "'venison bites'\n",
      "small venison roast\n",
      "milk\n",
      "flour\n",
      "salt\n",
      "black pepper\n",
      "garlic powder\n",
      "--------------------\n",
      "'four cheese white broccoli pizza'\n",
      "olive oil\n",
      "pizza dough\n",
      "cheese\n",
      "provolone cheese\n",
      "broccoli floret\n",
      "ricotta cheese\n",
      "mozzarella cheese\n",
      "garlic powder\n",
      "salt\n",
      "oregano\n",
      "--------------------\n",
      "'tuna pasta with salad cream red onions'\n",
      "gram\n",
      "pasta\n",
      "gram\n",
      "tin tuna\n",
      "red onion\n",
      "--------------------\n",
      "'lahmahjoon pizza'\n",
      "olive oil\n",
      "shallot\n",
      "lamb\n",
      "plum tomato\n",
      "parsley\n",
      "pomegranate molasses\n",
      "cinnamon\n",
      "salt\n",
      "ground pepper\n",
      "cornmeal\n",
      "pizza dough\n",
      "crumble feta\n",
      "pine nut\n",
      "--------------------\n",
      "'burger stew'\n",
      "beef\n",
      "italian vegetable\n",
      "tomato\n",
      "basil\n",
      "garlic\n",
      "beef broth\n",
      "noodle\n",
      "and pepper\n",
      "--------------------\n",
      "'aeropress brewed coffee'\n",
      "gram\n",
      "whole coffee bean\n",
      "water\n",
      "--------------------\n",
      "time: 65.3 ms\n"
     ]
    }
   ],
   "source": [
    "# Retrieve prompt\n",
    "sampled_id = sample(list(data.dic.keys()),10)\n",
    "for k in sampled_id:\n",
    "    pp.pprint(recipe1M_ny[idx[k]]['title'])\n",
    "    x = recipe1M_ny[idx[k]]['ny__ingredients']['exact']\n",
    "    print('\\n'.join(x))\n",
    "    print('----'*5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   {'text': '4 boneless skinless chicken breasts'},\n",
      "    {'text': '1 teaspoon olive oil'},\n",
      "    {'text': '12 teaspoon onion powder'},\n",
      "    {'text': '1 pinch salt'},\n",
      "    {'text': '1 pinch ground black pepper'},\n",
      "    {'text': '2 avocados, peeled, pitted and sliced'},\n",
      "    {'text': '2 tomatoes, sliced'},\n",
      "    {'text': '1 (8 ounce) package monterey jack cheese, cut into 10 slices'}]\n",
      "[   '4 boneless skinless chicken breasts',\n",
      "    '1 teaspoon olive oil',\n",
      "    '12 teaspoon onion powder',\n",
      "    '1 pinch salt',\n",
      "    '1 pinch ground black pepper',\n",
      "    '2 avocados, peeled, pitted and sliced',\n",
      "    '2 tomatoes, sliced',\n",
      "    '1 package monterey jack cheese, cut into 10 slices']\n",
      "[   'chicken breasts',\n",
      "    'olive oil',\n",
      "    'onion powder',\n",
      "    'salt',\n",
      "    'black pepper',\n",
      "    'avocados',\n",
      "    'tomatoes',\n",
      "    'jack cheese']\n",
      "[   'avocado peeled',\n",
      "    'salt and pepper',\n",
      "    'tomato',\n",
      "    'onion',\n",
      "    'cheddar cheese',\n",
      "    'chicken breast halves',\n",
      "    'getable oil']\n",
      "--------------------\n",
      "[   {   'text': '2 pounds beef, round steak sliced 1/2 inch thick, and '\n",
      "                'twicetenderized by the butcher'},\n",
      "    {'text': '2 cups flour, all-purpose'},\n",
      "    {'text': '2 teaspoons baking powder'},\n",
      "    {'text': '1 teaspoon baking soda'},\n",
      "    {'text': '1 teaspoon black pepper freshly ground'},\n",
      "    {'text': '3/4 teaspoon salt'},\n",
      "    {'text': '1 1/2 cups buttermilk'},\n",
      "    {'text': '1 large eggs'},\n",
      "    {'text': '1 tablespoon red hot pepper sauce'},\n",
      "    {'text': '2 each garlic cloves minced'},\n",
      "    {'text': '1 x vegetable shortening for deep frying'},\n",
      "    {'text': '1/4 cup grease drippings from pan'},\n",
      "    {'text': '3 tablespoons flour, all-purpose'},\n",
      "    {'text': '2 cups evaporated milk'},\n",
      "    {'text': '1 cup beef stock unsalted, prefer veal stock if possible'},\n",
      "    {'text': '1/2 teaspoon black pepper freshly ground'},\n",
      "    {'text': '1 x salt to taste'},\n",
      "    {'text': '1 x mashed potatoes optional'},\n",
      "    {'text': '1 x buttermilk biscuits optional'}]\n",
      "[   '2 pounds beef, round steak sliced 1/2 inch thick, and twicetenderized by '\n",
      "    'the butcher',\n",
      "    '2 cups flour, all purpose',\n",
      "    '2 teaspoons baking powder',\n",
      "    '1 teaspoon baking soda',\n",
      "    '1 teaspoon black pepper freshly ground',\n",
      "    '3/4 teaspoon salt',\n",
      "    '1 1/2 cups buttermilk',\n",
      "    '1 large eggs',\n",
      "    '1 tablespoon red hot pepper sauce',\n",
      "    '2 each garlic cloves minced',\n",
      "    '1 x vegetable shortening for deep frying',\n",
      "    '1/4 cup grease drippings from pan',\n",
      "    '3 tablespoons flour, all purpose',\n",
      "    '2 cups evaporated milk',\n",
      "    '1 cup beef stock unsalted, prefer veal stock if possible',\n",
      "    '1/2 teaspoon black pepper freshly ground',\n",
      "    '1 x salt to taste',\n",
      "    '1 x mashed potatoes optional',\n",
      "    '1 x buttermilk biscuits optional']\n",
      "[   'beef',\n",
      "    'flour',\n",
      "    'baking powder',\n",
      "    'baking soda',\n",
      "    'black pepper',\n",
      "    'salt',\n",
      "    'buttermilk',\n",
      "    'eggs',\n",
      "    'red hot pepper sauce',\n",
      "    'garlic',\n",
      "    'x vegetable shortening',\n",
      "    'grease drippings from pan',\n",
      "    'flour',\n",
      "    'milk',\n",
      "    'beef stock unsalted',\n",
      "    'black pepper',\n",
      "    'salt',\n",
      "    'x mashed potatoes optional',\n",
      "    'x buttermilk biscuits optional']\n",
      "[   'baking powder',\n",
      "    'salt',\n",
      "    'baking soda',\n",
      "    'black pepper',\n",
      "    'all purpose flour',\n",
      "    'buttermilk',\n",
      "    'egg',\n",
      "    'milk',\n",
      "    'salt',\n",
      "    'vegetable shortening',\n",
      "    'black pepper',\n",
      "    'all purpose flour',\n",
      "    'ef']\n",
      "--------------------\n",
      "time: 58.6 ms\n"
     ]
    }
   ],
   "source": [
    "# explore the change of ingredient preprocessing\n",
    "sampled_id = sample(list(data.dic.keys()),2)\n",
    "for k in sampled_id:\n",
    "    pp.pprint(layer1[idx[k]]['ingredients'])\n",
    "    pp.pprint(recipe1M_ny[idx[k]]['ingredients'])\n",
    "    pp.pprint(data.dic[k]['ori_ingr'])\n",
    "    pp.pprint(data.dic[k]['k1_ingr'])\n",
    "    print('----'*5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
