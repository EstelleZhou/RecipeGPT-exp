{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 5.25 Âµs\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "%load_ext autotime\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "# if cannot import the modules, add the parent directory to system path might help\n",
    "\n",
    "import os, tqdm, sys\n",
    "parent_dir = os.path.abspath(os.getcwd()+'/..')+'/'\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "from utils.path import dir_HugeFiles\n",
    "from utils.preprocessing import load\n",
    "from utils.save import make_dir, save_pickle, load_pickle, save\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import spacy\n",
    "import copy\n",
    "import re\n",
    "random_seed = 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exist ../big_data/dic_20190927.pickle\n",
      "time: 3.76 s\n"
     ]
    }
   ],
   "source": [
    "dic = load(dir_save = '../big_data/dic_20190927.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 24.1 ms\n"
     ]
    }
   ],
   "source": [
    "### STEP2 load and clean the generation\n",
    "\n",
    "def reverse(text):\n",
    "    '''\n",
    "    Important data cleaning before NY times parser\n",
    "    '''\n",
    "    # replace things in brace\n",
    "    text = re.sub(r'\\([^)]*\\)', '', text)\n",
    "\n",
    "    # remove space before punct\n",
    "    text = re.sub(r'\\s([?.!,\"](?:\\s|$))', r'\\1', text)\n",
    "\n",
    "    # remove consecutive spaces\n",
    "    text = re.sub(' +',' ',text).strip()\n",
    "    return text\n",
    "\n",
    "def reverse_list(listoftext):\n",
    "    output=[]\n",
    "    for text in listoftext:\n",
    "        rev = reverse(text)\n",
    "        if rev:\n",
    "            output.append(rev)\n",
    "    return output\n",
    "\n",
    "def load_dir_data(filename):\n",
    "    ls = []\n",
    "    if os.path.isdir(filename):\n",
    "        print('load', filename)\n",
    "        # Directory\n",
    "        for (dirpath, _, fnames) in os.walk(filename):\n",
    "            for fname in fnames:\n",
    "                path = os.path.join(dirpath, fname)\n",
    "                with open(path, 'r') as fp:\n",
    "                    raw_text = fp.read()\n",
    "                    \n",
    "                # if it contains instr\n",
    "                if fname[-5] == 'd':\n",
    "                    dic[int(fname[:-5])]['generated_instr'] = reverse_list(raw_text.split('.'))\n",
    "\n",
    "                # if it contains ingred\n",
    "                if fname[-5] == 'i':\n",
    "                    dic[int(fname[:-5])]['generated_ingred'] = reverse_list(raw_text.split('$'))\n",
    "                    \n",
    "                # if it contains name\n",
    "                if fname[-5] == 't':\n",
    "                    dic[int(fname[:-5])]['generated_name'] = raw_text\n",
    "                ls.append(int(fname[:-5]))# only interested in instr\n",
    "                    \n",
    "    return sorted(list(set(ls)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load ../../to_gpt2/generation_reproduce_2e-5/\n",
      "time: 200 ms\n"
     ]
    }
   ],
   "source": [
    "filename = '../../to_gpt2/generation_reproduce_2e-5/'\n",
    "ls = load_dir_data(filename)\n",
    "#filename = '../../to_gpt2/generation_1221k_top0.95_new/'\n",
    "#ls = load_dir_data(filename)\n",
    "assert len(ls)>0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved ../../to_gpt2/generation_reproduce_2e-5_truth_t.txt\n",
      "saved ../../to_gpt2/generation_reproduce_2e-5_truth_i.txt\n",
      "saved ../../to_gpt2/generation_reproduce_2e-5_truth_d.txt\n",
      "saved ../../to_gpt2/generation_reproduce_2e-5_pred_t.txt\n",
      "saved ../../to_gpt2/generation_reproduce_2e-5_pred_i.txt\n",
      "saved ../../to_gpt2/generation_reproduce_2e-5_pred_d.txt\n",
      "time: 492 ms\n"
     ]
    }
   ],
   "source": [
    "def add_space(line):\n",
    "    # add space before punct\n",
    "    line = re.sub('([.,!?()])', r' \\1 ', line)\n",
    "    line = re.sub('\\s{2,}', ' ', line)\n",
    "    return line\n",
    "\n",
    "to_write = {'truth_t':'', 'truth_i':'', 'truth_d':'',\n",
    "            'pred_t':'', 'pred_i':'', 'pred_d':''\n",
    "           }\n",
    "for i, v in dic.items():\n",
    "    if i in ls:\n",
    "        to_write['truth_t'] += add_space(' '.join(v['name'])) + '\\n'\n",
    "        to_write['truth_i'] += add_space(' $ '.join(v['ingredients']))+ ' $ \\n'\n",
    "        to_write['truth_d'] += add_space(' '.join(v['directions'])) + ' . \\n'\n",
    "        to_write['pred_t'] += add_space(v['generated_name']) + '\\n'\n",
    "        to_write['pred_i'] += add_space(' $ '.join(v['generated_ingred'])) + ' $ \\n'\n",
    "        to_write['pred_d'] += add_space(' . '.join(v['generated_instr'])) + ' . \\n'\n",
    "        \n",
    "for k, v in to_write.items():\n",
    "    save('../../to_gpt2/generation_reproduce_2e-5_%s.txt'%(k), v ,overwrite = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU = 6.71, 34.9/11.2/3.7/1.4 (BP=1.000, ratio=1.006, hyp_len=1997, ref_len=1985)\n",
      "It is not advisable to publish scores from multi-bleu.perl.  The scores depend on your tokenizer, which is unlikely to be reproducible from your paper or consistent across research groups.  Instead you should detokenize then use mteval-v14.pl, which has a standard tokenization.  Scores from multi-bleu.perl can still be used for internal purposes when you have a consistent tokenizer.\n",
      "time: 180 ms\n"
     ]
    }
   ],
   "source": [
    "!perl multi-bleu.perl ../../to_gpt2/generation_reproduce_2e-5_truth_t.txt < ../../to_gpt2/generation_reproduce_2e-5_pred_t.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU = 29.04, 62.9/39.9/23.2/12.2 (BP=1.000, ratio=1.017, hyp_len=27476, ref_len=27015)\n",
      "It is not advisable to publish scores from multi-bleu.perl.  The scores depend on your tokenizer, which is unlikely to be reproducible from your paper or consistent across research groups.  Instead you should detokenize then use mteval-v14.pl, which has a standard tokenization.  Scores from multi-bleu.perl can still be used for internal purposes when you have a consistent tokenizer.\n",
      "time: 536 ms\n"
     ]
    }
   ],
   "source": [
    "!perl multi-bleu.perl ../../to_gpt2/generation_reproduce_2e-5_truth_i.txt < ../../to_gpt2/generation_reproduce_2e-5_pred_i.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU = 12.79, 57.5/23.8/10.7/5.5 (BP=0.761, ratio=0.786, hyp_len=47340, ref_len=60267)\n",
      "It is not advisable to publish scores from multi-bleu.perl.  The scores depend on your tokenizer, which is unlikely to be reproducible from your paper or consistent across research groups.  Instead you should detokenize then use mteval-v14.pl, which has a standard tokenization.  Scores from multi-bleu.perl can still be used for internal purposes when you have a consistent tokenizer.\n",
      "time: 946 ms\n"
     ]
    }
   ],
   "source": [
    "!perl multi-bleu.perl ../../to_gpt2/generation_reproduce_2e-5_truth_d.txt < ../../to_gpt2/generation_reproduce_2e-5_pred_d.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### part 2: with the top p sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load ../../to_gpt2/generation_reproduce_2e-5_p99/\n",
      "time: 236 ms\n"
     ]
    }
   ],
   "source": [
    "filename = '../../to_gpt2/generation_reproduce_2e-5_p99/'\n",
    "ls = load_dir_data(filename)\n",
    "assert len(ls)>0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved ../../to_gpt2/generation_reproduce_2e-5_p99_truth_t.txt\n",
      "saved ../../to_gpt2/generation_reproduce_2e-5_p99_truth_i.txt\n",
      "saved ../../to_gpt2/generation_reproduce_2e-5_p99_truth_d.txt\n",
      "saved ../../to_gpt2/generation_reproduce_2e-5_p99_pred_t.txt\n",
      "saved ../../to_gpt2/generation_reproduce_2e-5_p99_pred_i.txt\n",
      "saved ../../to_gpt2/generation_reproduce_2e-5_p99_pred_d.txt\n",
      "time: 543 ms\n"
     ]
    }
   ],
   "source": [
    "def add_space(line):\n",
    "    # add space before punct\n",
    "    line = re.sub('([.,!?()])', r' \\1 ', line)\n",
    "    line = re.sub('\\s{2,}', ' ', line)\n",
    "    return line\n",
    "\n",
    "to_write = {'truth_t':'', 'truth_i':'', 'truth_d':'',\n",
    "            'pred_t':'', 'pred_i':'', 'pred_d':''\n",
    "           }\n",
    "for i, v in dic.items():\n",
    "    if i in ls:\n",
    "        to_write['truth_t'] += add_space(' '.join(v['name'])) + '\\n'\n",
    "        to_write['truth_i'] += add_space(' $ '.join(v['ingredients']))+ ' $ \\n'\n",
    "        to_write['truth_d'] += add_space(' '.join(v['directions'])) + ' . \\n'\n",
    "        to_write['pred_t'] += add_space(v['generated_name']) + '\\n'\n",
    "        to_write['pred_i'] += add_space(' $ '.join(v['generated_ingred'])) + ' $ \\n'\n",
    "        to_write['pred_d'] += add_space(' . '.join(v['generated_instr'])) + ' . \\n'\n",
    "        \n",
    "for k, v in to_write.items():\n",
    "    save('../../to_gpt2/generation_reproduce_2e-5_p99_%s.txt'%(k), v ,overwrite = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU = 2.44, 22.9/6.1/1.7/0.2 (BP=1.000, ratio=1.044, hyp_len=2072, ref_len=1985)\n",
      "It is not advisable to publish scores from multi-bleu.perl.  The scores depend on your tokenizer, which is unlikely to be reproducible from your paper or consistent across research groups.  Instead you should detokenize then use mteval-v14.pl, which has a standard tokenization.  Scores from multi-bleu.perl can still be used for internal purposes when you have a consistent tokenizer.\n",
      "time: 182 ms\n"
     ]
    }
   ],
   "source": [
    "!perl multi-bleu.perl ../../to_gpt2/generation_reproduce_2e-5_p99_truth_t.txt < ../../to_gpt2/generation_reproduce_2e-5_p99_pred_t.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU = 24.35, 58.2/34.7/18.9/9.2 (BP=1.000, ratio=1.068, hyp_len=28854, ref_len=27015)\n",
      "It is not advisable to publish scores from multi-bleu.perl.  The scores depend on your tokenizer, which is unlikely to be reproducible from your paper or consistent across research groups.  Instead you should detokenize then use mteval-v14.pl, which has a standard tokenization.  Scores from multi-bleu.perl can still be used for internal purposes when you have a consistent tokenizer.\n",
      "time: 542 ms\n"
     ]
    }
   ],
   "source": [
    "!perl multi-bleu.perl ../../to_gpt2/generation_reproduce_2e-5_p99_truth_i.txt < ../../to_gpt2/generation_reproduce_2e-5_p99_pred_i.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU = 10.16, 47.1/16.0/6.1/2.7 (BP=0.963, ratio=0.963, hyp_len=58049, ref_len=60267)\n",
      "It is not advisable to publish scores from multi-bleu.perl.  The scores depend on your tokenizer, which is unlikely to be reproducible from your paper or consistent across research groups.  Instead you should detokenize then use mteval-v14.pl, which has a standard tokenization.  Scores from multi-bleu.perl can still be used for internal purposes when you have a consistent tokenizer.\n",
      "time: 968 ms\n"
     ]
    }
   ],
   "source": [
    "!perl multi-bleu.perl ../../to_gpt2/generation_reproduce_2e-5_p99_truth_d.txt < ../../to_gpt2/generation_reproduce_2e-5_p99_pred_d.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 21.9 s\n"
     ]
    }
   ],
   "source": [
    "from utils.tree import instr2tree, tree_distance, build_tree\n",
    "from utils.evaluation import spacy_extension\n",
    "treemaker = instr2tree()\n",
    "sp = spacy_extension()\n",
    "def stem(x):\n",
    "    return [{'word':d['word'], 'ingredient':[]} for d in x]\n",
    "\n",
    "def allinone(v_directions, v_generated_instr, tag = ''):\n",
    "    true = treemaker.sents2tree(v_directions)\n",
    "    pred = treemaker.sents2tree(v_generated_instr)\n",
    "    tree_dist = tree_distance(build_tree(true), build_tree(pred))\n",
    "    \n",
    "    true_nodes = sum([len(line['ingredient']) +1 for line in true])\n",
    "    pred_nodes = sum([len(line['ingredient']) +1 for line in pred])\n",
    "    \n",
    "    true, pred = stem(true), stem(pred)\n",
    "    stem_dist = tree_distance(build_tree(true), build_tree(pred))\n",
    "    true_stem = sum([len(line['ingredient']) +1 for line in true])\n",
    "    pred_stem = sum([len(line['ingredient']) +1 for line in pred])\n",
    "    \n",
    "    return {'tree_dist_%s'%tag:  tree_dist,\n",
    "            'true_nodes_%s'%tag: true_nodes,\n",
    "            'pred_nodes_%s'%tag: pred_nodes,\n",
    "            'stem_dist_%s'%tag:  stem_dist,\n",
    "            'true_stem_%s'%tag:  true_stem,\n",
    "            'pred_stem_%s'%tag:  pred_stem}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/55102 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load ../../to_gpt2/generation_reproduce_2e-5_p99/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|ââ        | 11647/55102 [02:42<1:49:20,  6.62it/s]"
     ]
    }
   ],
   "source": [
    "filename = '../../to_gpt2/generation_reproduce_2e-5_p99/'\n",
    "ls = load_dir_data(filename)\n",
    "assert len(ls)>0\n",
    "\n",
    "for i, v in tqdm.tqdm(dic.items()):\n",
    "    if i in ls:\n",
    "        dic[i].update(allinone(v['directions'], v['generated_instr'], tag = '@'))\n",
    "        \n",
    "df2 = pd.DataFrame.from_dict(dic, orient = 'index')\n",
    "temp = df2[[col for col in df2.columns if '@' in col]].iloc[ls]\n",
    "print(str(temp.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp.apply(lambda x: x['tree_dist_@']*x['pred_nodes_@']/x['true_nodes_@'], axis=1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp.apply(lambda x: x['stem_dist_@']*x['pred_stem_@']/x['true_stem_@'], axis=1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/55102 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load ../../to_gpt2/generation_reproduce_2e-5/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|ââââââââââ| 55102/55102 [02:56<00:00, 311.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tree_dist_@     39.659661\n",
      "true_nodes_@    44.066000\n",
      "pred_nodes_@    33.846000\n",
      "stem_dist_@     14.835638\n",
      "true_stem_@     17.712000\n",
      "pred_stem_@     13.356000\n",
      "dtype: float64\n",
      "time: 3min\n"
     ]
    }
   ],
   "source": [
    "filename = '../../to_gpt2/generation_reproduce_2e-5/'\n",
    "ls = load_dir_data(filename)\n",
    "assert len(ls)>0\n",
    "\n",
    "for i, v in tqdm.tqdm(dic.items()):\n",
    "    if i in ls:\n",
    "        dic[i].update(allinone(v['directions'], v['generated_instr'], tag = '@'))\n",
    "        \n",
    "df2 = pd.DataFrame.from_dict(dic, orient = 'index')\n",
    "temp = df2[[col for col in df2.columns if '@' in col]].iloc[ls]\n",
    "print(str(temp.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33.09303491872026"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 58.7 ms\n"
     ]
    }
   ],
   "source": [
    "temp.apply(lambda x: x['tree_dist_@']*x['pred_nodes_@']/x['true_nodes_@'], axis=1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.269946640455773"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 52 ms\n"
     ]
    }
   ],
   "source": [
    "temp.apply(lambda x: x['pred_stem_@']*x['pred_stem_@']/x['true_stem_@'], axis=1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9366594160625229"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 61.3 ms\n"
     ]
    }
   ],
   "source": [
    "temp.apply(lambda x: x['tree_dist_@']/x['true_nodes_@'], axis=1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.943933540672245"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 44.9 ms\n"
     ]
    }
   ],
   "source": [
    "temp.apply(lambda x: x['pred_stem_@']/x['true_stem_@'], axis=1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
