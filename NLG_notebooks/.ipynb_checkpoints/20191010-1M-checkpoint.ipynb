{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 7.63 Âµs\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "%load_ext autotime\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "# if cannot import the modules, add the parent directory to system path might help\n",
    "\n",
    "import os, tqdm, sys\n",
    "parent_dir = os.path.abspath(os.getcwd()+'/..')+'/'\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "from utils.path import dir_HugeFiles\n",
    "from utils.preprocessing import load\n",
    "from utils.save import make_dir, save_pickle, load_pickle, save\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import spacy\n",
    "import copy\n",
    "import re\n",
    "random_seed = 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 11 s\n"
     ]
    }
   ],
   "source": [
    "dic = load_pickle('../big_data/recipe1M_cleaned.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 23.7 ms\n"
     ]
    }
   ],
   "source": [
    "def reverse(text):\n",
    "    '''\n",
    "    Important data cleaning before NY times parser\n",
    "    '''\n",
    "    # replace things in brace\n",
    "    text = re.sub(r'\\([^)]*\\)', '', text)\n",
    "\n",
    "    # remove space before punct\n",
    "    text = re.sub(r'\\s([?.!,\"](?:\\s|$))', r'\\1', text)\n",
    "\n",
    "    # remove consecutive spaces\n",
    "    text = re.sub(' +',' ',text).strip()\n",
    "    return text\n",
    "\n",
    "def reverse_list(listoftext):\n",
    "    output=[]\n",
    "    for text in listoftext:\n",
    "        rev = reverse(text)\n",
    "        if rev:\n",
    "            output.append(rev)\n",
    "    return output\n",
    "\n",
    "def load_dir_data(filename):\n",
    "    ls = []\n",
    "    if os.path.isdir(filename):\n",
    "        print('load', filename)\n",
    "        # Directory\n",
    "        for (dirpath, _, fnames) in os.walk(filename):\n",
    "            for fname in fnames:\n",
    "                path = os.path.join(dirpath, fname)\n",
    "                with open(path, 'r') as fp:\n",
    "                    raw_text = fp.read()\n",
    "                    \n",
    "                # if it contains instr\n",
    "                if fname[-5] == 'd':\n",
    "                    dic[int(fname[:-5])]['generated_instr'] = reverse_list(raw_text.split('.'))\n",
    "\n",
    "                # if it contains ingred\n",
    "                if fname[-5] == 'i':\n",
    "                    dic[int(fname[:-5])]['generated_ingred'] = reverse_list(raw_text.split('$'))\n",
    "                    \n",
    "                # if it contains name\n",
    "                if fname[-5] == 't':\n",
    "                    dic[int(fname[:-5])]['generated_name'] = raw_text\n",
    "                ls.append(int(fname[:-5]))# only interested in instr\n",
    "                    \n",
    "    return sorted(list(set(ls)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load ../../to_gpt2/generation_20191010-1M_test/\n",
      "time: 265 ms\n"
     ]
    }
   ],
   "source": [
    "filename = '../../to_gpt2/generation_20191010-1M_test/'\n",
    "ls = load_dir_data(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 41.7 ms\n"
     ]
    }
   ],
   "source": [
    "def add_space(line):\n",
    "    # add space before punct\n",
    "    line = re.sub('([.,!?()])', r' \\1 ', line)\n",
    "    line = re.sub('\\s{2,}', ' ', line)\n",
    "    return line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved ../../to_gpt2/generation_overwrite_truth_t.txt\n",
      "saved ../../to_gpt2/generation_overwrite_truth_i.txt\n",
      "saved ../../to_gpt2/generation_overwrite_truth_d.txt\n",
      "saved ../../to_gpt2/generation_overwrite_pred_t.txt\n",
      "saved ../../to_gpt2/generation_overwrite_pred_i.txt\n",
      "saved ../../to_gpt2/generation_overwrite_pred_d.txt\n",
      "time: 6.71 s\n"
     ]
    }
   ],
   "source": [
    "to_write = {'truth_t':'', 'truth_i':'', 'truth_d':'',\n",
    "            'pred_t':'', 'pred_i':'', 'pred_d':''\n",
    "           }\n",
    "for i, v in enumerate(dic):\n",
    "    if i in ls:\n",
    "        to_write['truth_t'] += add_space(v['title']) + '\\n'\n",
    "        to_write['truth_i'] += add_space(' $ '.join(v['ingredients']))+ ' $ \\n'\n",
    "        to_write['truth_d'] += add_space(' '.join(v['instructions'])) + ' . \\n'\n",
    "        to_write['pred_t'] += add_space(v['generated_name']) + '\\n'\n",
    "        to_write['pred_i'] += add_space(' $ '.join(v['generated_ingred'])) + ' $ \\n'\n",
    "        to_write['pred_d'] += add_space(' . '.join(v['generated_instr'])) + ' . \\n'\n",
    "        \n",
    "for k, v in to_write.items():\n",
    "    save('../../to_gpt2/generation_overwrite_%s.txt'%(k), v ,overwrite = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU = 11.07, 44.4/16.7/7.2/3.9 (BP=0.922, ratio=0.925, hyp_len=1898, ref_len=2053)\n",
      "It is not advisable to publish scores from multi-bleu.perl.  The scores depend on your tokenizer, which is unlikely to be reproducible from your paper or consistent across research groups.  Instead you should detokenize then use mteval-v14.pl, which has a standard tokenization.  Scores from multi-bleu.perl can still be used for internal purposes when you have a consistent tokenizer.\n",
      "time: 338 ms\n"
     ]
    }
   ],
   "source": [
    "!perl multi-bleu.perl ../../to_gpt2/generation_overwrite_truth_t.txt < ../../to_gpt2/generation_overwrite_pred_t.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU = 22.32, 56.8/32.2/16.9/8.0 (BP=1.000, ratio=1.035, hyp_len=29418, ref_len=28430)\n",
      "It is not advisable to publish scores from multi-bleu.perl.  The scores depend on your tokenizer, which is unlikely to be reproducible from your paper or consistent across research groups.  Instead you should detokenize then use mteval-v14.pl, which has a standard tokenization.  Scores from multi-bleu.perl can still be used for internal purposes when you have a consistent tokenizer.\n",
      "time: 639 ms\n"
     ]
    }
   ],
   "source": [
    "!perl multi-bleu.perl ../../to_gpt2/generation_overwrite_truth_i.txt < ../../to_gpt2/generation_overwrite_pred_i.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU = 9.01, 55.9/20.3/7.8/3.3 (BP=0.690, ratio=0.729, hyp_len=48415, ref_len=66394)\n",
      "It is not advisable to publish scores from multi-bleu.perl.  The scores depend on your tokenizer, which is unlikely to be reproducible from your paper or consistent across research groups.  Instead you should detokenize then use mteval-v14.pl, which has a standard tokenization.  Scores from multi-bleu.perl can still be used for internal purposes when you have a consistent tokenizer.\n",
      "time: 1.02 s\n"
     ]
    }
   ],
   "source": [
    "!perl multi-bleu.perl ../../to_gpt2/generation_overwrite_truth_d.txt < ../../to_gpt2/generation_overwrite_pred_d.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 47.2 ms\n"
     ]
    }
   ],
   "source": [
    "### STEP3 sent to the NYtimes\n",
    "### assign indices to each ingredient <---> NYtimes\n",
    "class ny_ingredients:\n",
    "    def __init__(self, fields):\n",
    "        # this function will take the global variable ls and dic\n",
    "        # static & reuseable\n",
    "        self.ny_ingred = '../../NYtime-parser2/ingred.txt'\n",
    "        self.ny_result = '../../NYtime-parser2/result.json'\n",
    "        \n",
    "        # spacy\n",
    "        self.spacy = spacy.load('en_core_web_lg')\n",
    "        self.fields = fields #['ingredients', 'generated_ingred']\n",
    "\n",
    "    def to_ny(self):\n",
    "        '''\n",
    "        using global variables dic and ls\n",
    "        '''\n",
    "        to_write = []\n",
    "        #for i, v in dic.items():\n",
    "        for i, v in enumerate(dic):    \n",
    "            if i in ls:\n",
    "                # assing index\n",
    "                for field in self.fields:\n",
    "                    line_ids = []\n",
    "                    for line in v[field]:\n",
    "                        reversed_line = reverse(line)\n",
    "                        if line in to_write:\n",
    "                            ny_id = to_write.index(reversed_line)\n",
    "                        else:\n",
    "                            ny_id = len(to_write)\n",
    "                            to_write.append(reversed_line)\n",
    "                        line_ids.append(ny_id)\n",
    "                    dic[i]['ny_%s'%(field)] = line_ids\n",
    "\n",
    "        # save the file to the folder under NYtime-parser2\n",
    "        save(filename = self.ny_ingred, \n",
    "             to_write = '\\n'.join(to_write),\n",
    "             overwrite = True, \n",
    "             print_=True)\n",
    "\n",
    "        self.to_write = to_write\n",
    "        \n",
    "    # step 3\n",
    "    def to_ingred(self):\n",
    "        '''\n",
    "        using global variables dic and ls\n",
    "        '''\n",
    "        ny_result = pd.read_json(self.ny_result)\n",
    "        to_write = []\n",
    "        #for i, v in dic.items():\n",
    "        for i, v in enumerate(dic):    \n",
    "            if i in ls:\n",
    "                # assing index\n",
    "                for field in self.fields:\n",
    "                    temp = [ny_result.loc[ny_id]['name'] for ny_id in v['ny_%s'%(field)]]\n",
    "                    exact, root = self.extract(temp)\n",
    "                    dic[i]['ny_%s'%(field)] = {'ny':temp, 'exact':exact, 'root':root}\n",
    "                    \n",
    "    def extract(self, ny_ingred):\n",
    "        '''\n",
    "        Args: ny_ingred: a list of ingredient names\n",
    "        '''\n",
    "        phrases_to_sentences = ' '.join(['Mix the %s and water.'%ingr for ingr in ny_ingred])\n",
    "        doc = self.spacy(phrases_to_sentences)\n",
    "        exact_match, root_match = [],[]\n",
    "        for chunk in doc.noun_chunks:\n",
    "            if chunk.text != 'water':\n",
    "                root_lemma = [token.lemma_ for token in doc if token.text == chunk.root.text][0]\n",
    "                exact_match.append(chunk.lemma_.replace('the ',''))\n",
    "                root_match.append(root_lemma)\n",
    "        return exact_match, root_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved ../../NYtime-parser2/ingred.txt\n",
      "time: 22.5 s\n"
     ]
    }
   ],
   "source": [
    "ny_ingr = ny_ingredients(fields = ['generated_ingred','ingredients'])\n",
    "### step 3-1 save it as ingred.txt\n",
    "ny_ingr.to_ny()\n",
    "### step 3-2 go to python2 and run NLG_notebooks/Control Nytimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 29.6 s\n"
     ]
    }
   ],
   "source": [
    "### step 3-3 load the result.json back to dic\n",
    "ny_ingr.to_ingred()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 43.5 ms\n"
     ]
    }
   ],
   "source": [
    "from utils.evaluation import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "160567it [00:01, 137213.75it/s]/home/helena/anaconda3/envs/py36/lib/python3.6/site-packages/numpy/core/fromnumeric.py:2920: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/home/helena/anaconda3/envs/py36/lib/python3.6/site-packages/numpy/core/_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "1029720it [00:07, 139782.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision_@precision_root                0.731566\n",
      "precision_freq_@precision_root           0.678349\n",
      "precision_ngram_@precision_exact         0.632323\n",
      "precision_ngram_freq_@precision_exact    0.598198\n",
      "recall_@recall_root                      0.711097\n",
      "recall_freq_@recall_root                 0.699889\n",
      "recall_ngram_@recall_exact               0.574229\n",
      "recall_ngram_freq_@recall_exact          0.572469\n",
      "dtype: float64\n",
      "time: 11.4 s\n"
     ]
    }
   ],
   "source": [
    "#for i, v in tqdm.tqdm(dic.items()):\n",
    "for i, v in tqdm.tqdm(enumerate(dic)):    \n",
    "    if i in ls:\n",
    "        score = metrics(v['ny_ingredients']['exact'], v['ny_generated_ingred']['exact'])\n",
    "        dic[i].update(score.all_ngram_recall(name='@recall_exact'))\n",
    "        dic[i].update(score.all_ngram_precision(name='@precision_exact'))\n",
    "        score = metrics(v['ny_ingredients']['root'], v['ny_generated_ingred']['root'])\n",
    "        dic[i].update(score.all_recall(name='@recall_root'))\n",
    "        dic[i].update(score.all_precision(name='@precision_root'))       \n",
    "    \n",
    "# df2 = pd.DataFrame.from_dict(dic, orient = 'index')\n",
    "df2 = pd.DataFrame(dic)\n",
    "temp = df2[[col for col in df2.columns if '@' in col]].iloc[ls]\n",
    "print(str(temp.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 \n",
      "0.728\n",
      "f1 freq_\n",
      "0.693\n",
      "f1 ngram_\n",
      "0.582\n",
      "f1 ngram_freq_\n",
      "0.566\n",
      "time: 253 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/helena/anaconda3/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  \"\"\"\n",
      "/home/helena/anaconda3/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:11: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "for metric_name in ['','freq_']:#,'ngram','ngram_freq']:\n",
    "    print('f1',metric_name)\n",
    "    str_p = 'precision_%s@precision_root'%(metric_name)\n",
    "    str_r = 'recall_%s@recall_root'%(metric_name)\n",
    "    score = temp.apply(lambda x: 2*x[str_p]*x[str_r]/(x[str_p]+x[str_r]) , axis = 1).mean()\n",
    "    print(round(score, 3))\n",
    "for metric_name in ['ngram_','ngram_freq_']:\n",
    "    print('f1',metric_name)\n",
    "    str_p = 'precision_%s@precision_exact'%(metric_name)\n",
    "    str_r = 'recall_%s@recall_exact'%(metric_name)\n",
    "    score = temp.apply(lambda x: 2*x[str_p]*x[str_r]/(x[str_p]+x[str_r]) , axis = 1).mean()\n",
    "    print(round(score, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 20.5 s\n"
     ]
    }
   ],
   "source": [
    "from utils.tree import instr2tree, tree_distance, build_tree\n",
    "from utils.evaluation import spacy_extension\n",
    "treemaker = instr2tree()\n",
    "sp = spacy_extension()\n",
    "def stem(x):\n",
    "    return [{'word':d['word'], 'ingredient':[]} for d in x]\n",
    "\n",
    "def allinone(v_directions, v_generated_instr, tag = '', rev=False):\n",
    "    true = treemaker.sents2tree(v_directions)\n",
    "    pred = treemaker.sents2tree(v_generated_instr)\n",
    "    if rev:\n",
    "        pred = pred[::-1]\n",
    "    tree_dist = tree_distance(build_tree(true), build_tree(pred))\n",
    "    \n",
    "    true_nodes = sum([len(line['ingredient']) +1 for line in true])\n",
    "    pred_nodes = sum([len(line['ingredient']) +1 for line in pred])\n",
    "    \n",
    "    true, pred = stem(true), stem(pred)\n",
    "    stem_dist = tree_distance(build_tree(true), build_tree(pred))\n",
    "    true_stem = sum([len(line['ingredient']) +1 for line in true])\n",
    "    pred_stem = sum([len(line['ingredient']) +1 for line in pred])\n",
    "    \n",
    "    return {'tree_dist_%s'%tag:  tree_dist,\n",
    "            'true_nodes_%s'%tag: true_nodes,\n",
    "            'pred_nodes_%s'%tag: pred_nodes,\n",
    "            'stem_dist_%s'%tag:  stem_dist,\n",
    "            'true_stem_%s'%tag:  true_stem,\n",
    "            'pred_stem_%s'%tag:  pred_stem}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision_@precision_root                 0.731566\n",
      "precision_freq_@precision_root            0.678349\n",
      "precision_ngram_@precision_exact          0.632323\n",
      "precision_ngram_freq_@precision_exact     0.598198\n",
      "pred_nodes_@                             36.620000\n",
      "pred_nodes_@rev                          36.620000\n",
      "pred_stem_@                              15.484000\n",
      "pred_stem_@rev                           15.484000\n",
      "recall_@recall_root                       0.711097\n",
      "recall_freq_@recall_root                  0.699889\n",
      "recall_ngram_@recall_exact                0.574229\n",
      "recall_ngram_freq_@recall_exact           0.572469\n",
      "stem_dist_@                              17.569806\n",
      "stem_dist_@rev                           19.230115\n",
      "tree_dist_@                              44.439031\n",
      "tree_dist_@rev                           48.258554\n",
      "true_nodes_@                             48.600000\n",
      "true_nodes_@rev                          48.600000\n",
      "true_stem_@                              21.268000\n",
      "true_stem_@rev                           21.268000\n",
      "dtype: float64\n",
      "time: 6.78 s\n"
     ]
    }
   ],
   "source": [
    "# recipe1M\n",
    "for i, v in tqdm.tqdm(enumerate(dic)):  \n",
    "    if i in ls:\n",
    "        dic[i].update(allinone(v['instructions'], v['generated_instr'], tag = '@'))\n",
    "        dic[i].update(allinone(v['instructions'], v['generated_instr'], tag = '@rev', rev = True))\n",
    "        \n",
    "df2 = pd.DataFrame(dic)\n",
    "temp = df2[[col for col in df2.columns if '@' in col]].iloc[ls]\n",
    "#logger.report_text(str(temp))\n",
    "print(str(temp.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.510792893873668\n",
      "0.465785985623208\n",
      "0.561067984836763\n",
      "0.5156743513430984\n",
      "time: 191 ms\n"
     ]
    }
   ],
   "source": [
    "val = temp.apply(lambda x: x['tree_dist_@']/(x['true_nodes_@']+x['pred_nodes_@']), axis=1).mean()\n",
    "print (val)\n",
    "\n",
    "val = temp.apply(lambda x: x['stem_dist_@']/(x['true_stem_@']+x['pred_stem_@']), axis=1).mean()\n",
    "print (val)\n",
    "\n",
    "val = temp.apply(lambda x: x['tree_dist_@rev']/(x['true_nodes_@rev']+x['pred_nodes_@rev']), axis=1).mean()\n",
    "print (val)\n",
    "\n",
    "val = temp.apply(lambda x: x['stem_dist_@rev']/(x['true_stem_@rev']+x['pred_stem_@rev']), axis=1).mean()\n",
    "print (val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load ../../to_gpt2/generation_20191010-s/\n",
      "time: 985 ms\n"
     ]
    }
   ],
   "source": [
    "filename = '../../to_gpt2/generation_20191010-s/'\n",
    "ls = load_dir_data(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1029720it [06:46, 2532.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision_@precision_root                 0.731566\n",
      "precision_freq_@precision_root            0.678349\n",
      "precision_ngram_@precision_exact          0.632323\n",
      "precision_ngram_freq_@precision_exact     0.598198\n",
      "pred_nodes_@                             35.510000\n",
      "pred_nodes_@rev                          35.510000\n",
      "pred_stem_@                              15.378000\n",
      "pred_stem_@rev                           15.378000\n",
      "recall_@recall_root                       0.711097\n",
      "recall_freq_@recall_root                  0.699889\n",
      "recall_ngram_@recall_exact                0.574229\n",
      "recall_ngram_freq_@recall_exact           0.572469\n",
      "stem_dist_@                              19.339024\n",
      "stem_dist_@rev                           20.251536\n",
      "tree_dist_@                              48.110847\n",
      "tree_dist_@rev                           50.140224\n",
      "true_nodes_@                             48.600000\n",
      "true_nodes_@rev                          48.600000\n",
      "true_stem_@                              21.268000\n",
      "true_stem_@rev                           21.268000\n",
      "dtype: float64\n",
      "time: 6min 53s\n"
     ]
    }
   ],
   "source": [
    "# recipe1M subset\n",
    "for i, v in tqdm.tqdm(enumerate(dic)):  \n",
    "    if i in ls:\n",
    "        dic[i].update(allinone(v['instructions'], v['generated_instr'], tag = '@'))\n",
    "        dic[i].update(allinone(v['instructions'], v['generated_instr'], tag = '@rev', rev = True))\n",
    "        \n",
    "df2 = pd.DataFrame(dic)\n",
    "temp = df2[[col for col in df2.columns if '@' in col]].iloc[ls]\n",
    "#logger.report_text(str(temp))\n",
    "print(str(temp.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.569779852598404\n",
      "0.5226003813029513\n",
      "0.5968378247543937\n",
      "0.5520942707757207\n",
      "time: 128 ms\n"
     ]
    }
   ],
   "source": [
    "val = temp.apply(lambda x: x['tree_dist_@']/(x['true_nodes_@']+x['pred_nodes_@']), axis=1).mean()\n",
    "print (val)\n",
    "\n",
    "val = temp.apply(lambda x: x['stem_dist_@']/(x['true_stem_@']+x['pred_stem_@']), axis=1).mean()\n",
    "print (val)\n",
    "\n",
    "val = temp.apply(lambda x: x['tree_dist_@rev']/(x['true_nodes_@rev']+x['pred_nodes_@rev']), axis=1).mean()\n",
    "print (val)\n",
    "\n",
    "val = temp.apply(lambda x: x['stem_dist_@rev']/(x['true_stem_@rev']+x['pred_stem_@rev']), axis=1).mean()\n",
    "print (val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
