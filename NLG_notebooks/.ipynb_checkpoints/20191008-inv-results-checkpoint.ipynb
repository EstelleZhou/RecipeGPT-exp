{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 ms, sys: 0 ns, total: 4 ms\n",
      "Wall time: 5.72 Âµs\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "%load_ext autotime\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "# if cannot import the modules, add the parent directory to system path might help\n",
    "\n",
    "import os, tqdm, sys\n",
    "parent_dir = os.path.abspath(os.getcwd()+'/..')+'/'\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "from utils.path import dir_HugeFiles\n",
    "from utils.preprocessing import load\n",
    "from utils.save import make_dir, save_pickle, load_pickle, save\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import spacy\n",
    "import copy\n",
    "import re\n",
    "random_seed = 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exist ../big_data/data55_inv.pickle\n",
      "time: 2.98 s\n"
     ]
    }
   ],
   "source": [
    "dic = load(dir_save = '../big_data/data55_inv.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 24.8 ms\n"
     ]
    }
   ],
   "source": [
    "### STEP2 load and clean the generation\n",
    "\n",
    "def reverse(text):\n",
    "    '''\n",
    "    Important data cleaning before NY times parser\n",
    "    '''\n",
    "    # replace things in brace\n",
    "    text = re.sub(r'\\([^)]*\\)', '', text)\n",
    "\n",
    "    # remove space before punct\n",
    "    text = re.sub(r'\\s([?.!,\"](?:\\s|$))', r'\\1', text)\n",
    "\n",
    "    # remove consecutive spaces\n",
    "    text = re.sub(' +',' ',text).strip()\n",
    "    return text\n",
    "\n",
    "def reverse_list(listoftext):\n",
    "    output=[]\n",
    "    for text in listoftext:\n",
    "        rev = reverse(text)\n",
    "        if rev:\n",
    "            output.append(rev)\n",
    "    return output\n",
    "\n",
    "def load_dir_data(filename):\n",
    "    ls = []\n",
    "    if os.path.isdir(filename):\n",
    "        print('load', filename)\n",
    "        # Directory\n",
    "        for (dirpath, _, fnames) in os.walk(filename):\n",
    "            for fname in fnames:\n",
    "                path = os.path.join(dirpath, fname)\n",
    "                with open(path, 'r') as fp:\n",
    "                    raw_text = fp.read()\n",
    "                    \n",
    "                # if it contains instr\n",
    "                if fname[-5] == 'd':\n",
    "                    dic[int(fname[:-5])]['generated_instr'] = reverse_list(raw_text.split('.'))\n",
    "\n",
    "                # if it contains ingred\n",
    "                if fname[-5] == 'i':\n",
    "                    dic[int(fname[:-5])]['generated_ingred'] = reverse_list(raw_text.split('$'))\n",
    "                    \n",
    "                # if it contains name\n",
    "                if fname[-5] == 't':\n",
    "                    dic[int(fname[:-5])]['generated_name'] = raw_text\n",
    "                ls.append(int(fname[:-5]))# only interested in instr\n",
    "                    \n",
    "    return sorted(list(set(ls)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load ../../to_gpt2/generation_20191008-inv/\n",
      "time: 207 ms\n"
     ]
    }
   ],
   "source": [
    "filename = '../../to_gpt2/generation_20191008-inv/'\n",
    "ls = load_dir_data(filename)\n",
    "#filename = '../../to_gpt2/generation_1221k_top0.95_new/'\n",
    "#ls = load_dir_data(filename)\n",
    "assert len(ls)>0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved ../../to_gpt2/generation_20191008_inv_truth_t.txt\n",
      "saved ../../to_gpt2/generation_20191008_inv_truth_i.txt\n",
      "saved ../../to_gpt2/generation_20191008_inv_truth_d.txt\n",
      "saved ../../to_gpt2/generation_20191008_inv_pred_t.txt\n",
      "saved ../../to_gpt2/generation_20191008_inv_pred_i.txt\n",
      "saved ../../to_gpt2/generation_20191008_inv_pred_d.txt\n",
      "time: 537 ms\n"
     ]
    }
   ],
   "source": [
    "def add_space(line):\n",
    "    # add space before punct\n",
    "    line = re.sub('([.,!?()])', r' \\1 ', line)\n",
    "    line = re.sub('\\s{2,}', ' ', line)\n",
    "    return line\n",
    "\n",
    "to_write = {'truth_t':'', 'truth_i':'', 'truth_d':'',\n",
    "            'pred_t':'', 'pred_i':'', 'pred_d':''\n",
    "           }\n",
    "for i, v in enumerate(dic):\n",
    "    if i in ls:\n",
    "        to_write['truth_t'] += add_space(' '.join(v['name'])) + '\\n'\n",
    "        to_write['truth_i'] += add_space(' $ '.join(v['inv_ingredients']))+ ' $ \\n'\n",
    "        to_write['truth_d'] += add_space(' '.join(v['directions'])) + ' . \\n'\n",
    "        to_write['pred_t'] += add_space(v['generated_name']) + '\\n'\n",
    "        to_write['pred_i'] += add_space(' $ '.join(v['generated_ingred'])) + ' $ \\n'\n",
    "        to_write['pred_d'] += add_space(' . '.join(v['generated_instr'])) + ' . \\n'\n",
    "        \n",
    "for k, v in to_write.items():\n",
    "    save('../../to_gpt2/generation_20191008_inv_%s.txt'%(k), v ,overwrite = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use of uninitialized value in division (/) at multi-bleu.perl line 139, <STDIN> line 500.\n",
      "BLEU = 0.00, 33.0/8.4/1.8/0.0 (BP=0.965, ratio=0.965, hyp_len=1900, ref_len=1968)\n",
      "It is not advisable to publish scores from multi-bleu.perl.  The scores depend on your tokenizer, which is unlikely to be reproducible from your paper or consistent across research groups.  Instead you should detokenize then use mteval-v14.pl, which has a standard tokenization.  Scores from multi-bleu.perl can still be used for internal purposes when you have a consistent tokenizer.\n",
      "time: 187 ms\n"
     ]
    }
   ],
   "source": [
    "!perl multi-bleu.perl ../../to_gpt2/generation_20191008_inv_truth_t.txt < ../../to_gpt2/generation_20191008_inv_pred_t.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU = 32.28, 74.9/51.2/28.9/14.4 (BP=0.907, ratio=0.911, hyp_len=20637, ref_len=22642)\n",
      "It is not advisable to publish scores from multi-bleu.perl.  The scores depend on your tokenizer, which is unlikely to be reproducible from your paper or consistent across research groups.  Instead you should detokenize then use mteval-v14.pl, which has a standard tokenization.  Scores from multi-bleu.perl can still be used for internal purposes when you have a consistent tokenizer.\n",
      "time: 462 ms\n"
     ]
    }
   ],
   "source": [
    "!perl multi-bleu.perl ../../to_gpt2/generation_20191008_inv_truth_i.txt < ../../to_gpt2/generation_20191008_inv_pred_i.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU = 13.05, 54.8/22.0/9.6/4.8 (BP=0.851, ratio=0.861, hyp_len=55527, ref_len=64517)\n",
      "It is not advisable to publish scores from multi-bleu.perl.  The scores depend on your tokenizer, which is unlikely to be reproducible from your paper or consistent across research groups.  Instead you should detokenize then use mteval-v14.pl, which has a standard tokenization.  Scores from multi-bleu.perl can still be used for internal purposes when you have a consistent tokenizer.\n",
      "time: 940 ms\n"
     ]
    }
   ],
   "source": [
    "!perl multi-bleu.perl ../../to_gpt2/generation_20191008_inv_truth_d.txt < ../../to_gpt2/generation_20191008_inv_pred_d.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load ../../to_gpt2/generation_20191008-inv/\n",
      "time: 205 ms\n"
     ]
    }
   ],
   "source": [
    "filename = '../../to_gpt2/generation_20191008-inv/'\n",
    "ls_1 = load_dir_data(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"rouge-1\": {\n",
      "    \"f\": 0.2732767114237679,\n",
      "    \"p\": 0.26726111111111117,\n",
      "    \"r\": 0.3065904761904763\n",
      "  },\n",
      "  \"rouge-2\": {\n",
      "    \"f\": 0.06952258211750184,\n",
      "    \"p\": 0.06746746031746029,\n",
      "    \"r\": 0.08087460317460317\n",
      "  },\n",
      "  \"rouge-l\": {\n",
      "    \"f\": 0.24821538640897314,\n",
      "    \"p\": 0.2590142857142858,\n",
      "    \"r\": 0.2982214285714287\n",
      "  }\n",
      "}\n",
      "time: 249 ms\n"
     ]
    }
   ],
   "source": [
    "!rouge -f ../../to_gpt2/generation_20191008_inv_truth_t.txt ../../to_gpt2/generation_20191008_inv_pred_t.txt --avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"rouge-1\": {\n",
      "    \"f\": 0.5746180176847999,\n",
      "    \"p\": 0.5369220630768636,\n",
      "    \"r\": 0.6360451844613361\n",
      "  },\n",
      "  \"rouge-2\": {\n",
      "    \"f\": 0.36442329313513966,\n",
      "    \"p\": 0.3502125384174111,\n",
      "    \"r\": 0.39031712311744227\n",
      "  },\n",
      "  \"rouge-l\": {\n",
      "    \"f\": 0.3486173341883424,\n",
      "    \"p\": 0.3373768325514306,\n",
      "    \"r\": 0.40077752736135697\n",
      "  }\n",
      "}\n",
      "time: 2.03 s\n"
     ]
    }
   ],
   "source": [
    "!rouge -f ../../to_gpt2/generation_20191008_inv_truth_i.txt ../../to_gpt2/generation_20191008_inv_pred_i.txt --avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"rouge-1\": {\n",
      "    \"f\": 0.4737956727648326,\n",
      "    \"p\": 0.44520916221376655,\n",
      "    \"r\": 0.5372016429141295\n",
      "  },\n",
      "  \"rouge-2\": {\n",
      "    \"f\": 0.17764214014010618,\n",
      "    \"p\": 0.16987047228058327,\n",
      "    \"r\": 0.2017127007919821\n",
      "  },\n",
      "  \"rouge-l\": {\n",
      "    \"f\": 0.41543684993165514,\n",
      "    \"p\": 0.41189795397583334,\n",
      "    \"r\": 0.4970520018154333\n",
      "  }\n",
      "}\n",
      "time: 7.58 s\n"
     ]
    }
   ],
   "source": [
    "!rouge -f ../../to_gpt2/generation_20191008_inv_truth_d.txt ../../to_gpt2/generation_20191008_inv_pred_d.txt --avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
