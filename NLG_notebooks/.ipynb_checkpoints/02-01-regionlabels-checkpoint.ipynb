{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 7.87 Âµs\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "%load_ext autotime\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "# if cannot import the modules, add the parent directory to system path might help\n",
    "\n",
    "import os\n",
    "import sys\n",
    "parent_dir = os.path.abspath(os.getcwd()+'/..')+'/'\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "\n",
    "import os\n",
    "from utils.path import dir_HugeFiles\n",
    "from utils.preprocessing import load\n",
    "from utils.words import make_corpus_0, get_wordcount_list\n",
    "from utils.save import make_dir, save_pickle, load_pickle, auto_save_csv, print_time\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#dir_save = os.path.normpath(dir_HugeFiles+'dph/dic_20190607.pickle')\n",
    "#dic = load(dir_save)\n",
    "random_seed = 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exist\n",
      "drop 46 recipes with less than 2 ingredients\n",
      "furthur drop 1026 recipes with less than 2 instructions\n",
      "drop 0 recipes with no description\n",
      "now we are using recipe54k 54076\n",
      "time: 43.3 s\n"
     ]
    }
   ],
   "source": [
    "dic = load(dir_save = '../big_data/dic_20190830.pickle')\n",
    "\n",
    "ls = [i for i,v in dic.items() if len(v['ingredients'])>1]\n",
    "print('drop %d recipes with less than 2 ingredients' %(len(dic)-len(ls)))\n",
    "ls = [i for i in ls if len(dic[i]['directions'])>1]\n",
    "print('furthur drop %d recipes with less than 2 instructions' %(len(dic)-len(ls)))\n",
    "desc = [i for i in ls if len(dic[i]['description'])<1]\n",
    "print('drop %d recipes with no description' %(len(desc)))\n",
    "print('now we are using recipe54k %d' % len(ls))\n",
    "\n",
    "corpus_llist, corpus_list, corpus = make_corpus_0(dic, ['name','ingredients','directions'], ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1min 34s\n"
     ]
    }
   ],
   "source": [
    "X, knowns = get_wordcount_list(corpus_list, drop = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1min 15s\n"
     ]
    }
   ],
   "source": [
    "def add_UNK(string, key):\n",
    "    listt = string.split(' ')\n",
    "    listt = [l if l in knowns else 'UNK' for l in listt]\n",
    "    return listt\n",
    "def rm_UNK(string, key):\n",
    "    listt = string.split(' ')\n",
    "    listt = [l for l in listt if l in knowns]\n",
    "    return listt\n",
    "\n",
    "for i, v in dic.items():\n",
    "    if i in ls:\n",
    "        for key in ['name','ingredients','directions']:\n",
    "            dic[i][key+'_UNK'] = [rm_UNK(string, key) for string in v[key]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 21.6 s\n"
     ]
    }
   ],
   "source": [
    "stats = []\n",
    "# find world cuisine\n",
    "world = set(['all world cuisine', 'world cuisine'])\n",
    "# check the region tag\n",
    "region = set(['latin american','european', 'asian', 'u . s .', 'african', 'australian and new zealander'])\n",
    "for i, v in dic.items():\n",
    "    if i in ls:\n",
    "        # filter out the ' recipe'\n",
    "        recipe = set([t[:-8] if t[-8:]==' recipes' else t for t in v['tags']])\n",
    "\n",
    "        # if not world cusine\n",
    "        if len( recipe & world ) == 0:\n",
    "            regional_tag = 'unknown'\n",
    "        else:\n",
    "            check_region = recipe & region\n",
    "            # if region not in the list\n",
    "            if len(check_region) == 0:\n",
    "                if 'italian' in recipe:\n",
    "                    regional_tag = 'european'\n",
    "                elif 'mexican' in recipe:\n",
    "                    regional_tag = 'latin american'\n",
    "                elif 'canadian' in recipe:\n",
    "                    regional_tag = 'north american'\n",
    "                elif 'middle eastern' in recipe:\n",
    "                    regional_tag = 'asian'\n",
    "                elif 'indian' in recipe:\n",
    "                    regional_tag = 'asian'\n",
    "                else:\n",
    "                    regional_tag = 'unknown_region'\n",
    "            # exact match\n",
    "            elif len(check_region) == 1: \n",
    "                regional_tag = list(check_region)[0]\n",
    "                if regional_tag == 'u . s .':\n",
    "                    regional_tag = 'north american'\n",
    "            # dual region\n",
    "            else:\n",
    "                regional_tag = 'dual_region'\n",
    "        \n",
    "        dic[i]['regional_tag'] = regional_tag\n",
    "        stats.append(regional_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'unknown': 38098,\n",
       "         'european': 5059,\n",
       "         'latin american': 2590,\n",
       "         'dual_region': 447,\n",
       "         'north american': 3795,\n",
       "         'asian': 3299,\n",
       "         'australian and new zealander': 328,\n",
       "         'african': 205,\n",
       "         'unknown_region': 255})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 28.3 ms\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 41.3 ms\n"
     ]
    }
   ],
   "source": [
    "ls_region = [i for i in ls if dic[i]['regional_tag'] not in ['unknown','dual_region']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 13.2 s\n"
     ]
    }
   ],
   "source": [
    "stats = []\n",
    "\n",
    "# check the region tag\n",
    "regional_tag2 = {'asian':set(['chinese', 'japanese', 'korean','indian','pakistani','bangladeshi',\n",
    "                            'persian','filipino','indonesian','vietnamese','thai', 'korean', \n",
    "                            'middle eastern','indian']),\n",
    "                 'european':set(['italian', 'german', 'uk and ireland','french']),\n",
    "                 'north american':set(['canadian','southern','u . s .']),\n",
    "                 'latin american': set(['mexican','south american','caribbean']),\n",
    "                 'african': set(['african'])\n",
    "              }\n",
    "\n",
    "for i, v in dic.items():\n",
    "    if i in ls_region:\n",
    "        # filter out the ' recipe'\n",
    "        recipe = set([t[:-8] if t[-8:]==' recipes' else t for t in v['tags']])\n",
    "        if v['regional_tag'] in regional_tag2.keys():\n",
    "            compare = regional_tag2[v['regional_tag']] & recipe\n",
    "            if len(compare) == 1:\n",
    "                dic[i]['regional_tag2'] = compare.pop()\n",
    "            elif len(compare) > 1:\n",
    "                dic[i]['regional_tag2'] = 'dual_region'\n",
    "            else:\n",
    "                dic[i]['regional_tag2'] = 'unknown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3.36 s\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame.from_dict(dic, orient = 'index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 78.3 ms\n"
     ]
    }
   ],
   "source": [
    "df = df.loc[ls_region]\n",
    "df = df[df['regional_tag2']!='unknown']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "regional_tag    regional_tag2 \n",
       "african         african            205\n",
       "asian           bangladeshi          3\n",
       "                chinese            454\n",
       "                dual_region         79\n",
       "                filipino            95\n",
       "                indian             637\n",
       "                indonesian          21\n",
       "                japanese           188\n",
       "                korean             136\n",
       "                middle eastern     281\n",
       "                pakistani           17\n",
       "                thai               203\n",
       "                vietnamese          28\n",
       "european        dual_region         10\n",
       "                french             309\n",
       "                german             117\n",
       "                italian           2838\n",
       "                uk and ireland     181\n",
       "latin american  caribbean          146\n",
       "                dual_region          2\n",
       "                mexican           2024\n",
       "                south american     107\n",
       "north american  canadian           770\n",
       "                dual_region        819\n",
       "                u . s .           2206\n",
       "Name: regional_tag2, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 26 ms\n"
     ]
    }
   ],
   "source": [
    "df.groupby(['regional_tag','regional_tag2'])['regional_tag2'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### further merge several labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 14 s\n"
     ]
    }
   ],
   "source": [
    "regional_tag3 = []\n",
    "for i, row in df.iterrows():\n",
    "    if row.regional_tag in ['latin american','african']:\n",
    "        regional_tag3.append(row.regional_tag)\n",
    "    elif row.regional_tag2 in ['bangladeshi','filipino','indonesian','pakistani','vietnamese']:\n",
    "        regional_tag3.append('other asian')\n",
    "    elif row.regional_tag == 'asian' and row.regional_tag2 =='dual_region' :\n",
    "        regional_tag3.append(np.nan)\n",
    "    elif row.regional_tag == 'asian' :\n",
    "        regional_tag3.append(row.regional_tag2)\n",
    "    elif row.regional_tag2 == 'italian' :\n",
    "        regional_tag3.append(row.regional_tag2)\n",
    "    elif row.regional_tag in ['european','north american','australian and new zealander']:\n",
    "        regional_tag3.append('general western')\n",
    "    else:\n",
    "        regional_tag3.append(np.nan)\n",
    "df['regional_tag3'] = regional_tag3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.12 s\n"
     ]
    }
   ],
   "source": [
    "dic = df.to_dict(orient = 'index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 42.3 ms\n"
     ]
    }
   ],
   "source": [
    "df = df[~df.regional_tag3.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "regional_tag                  regional_tag3  \n",
       "african                       african             205\n",
       "asian                         chinese             454\n",
       "                              indian              637\n",
       "                              japanese            188\n",
       "                              korean              136\n",
       "                              middle eastern      281\n",
       "                              other asian         164\n",
       "                              thai                203\n",
       "australian and new zealander  general western     328\n",
       "european                      general western     617\n",
       "                              italian            2838\n",
       "latin american                latin american     2279\n",
       "north american                general western    3795\n",
       "Name: regional_tag3, dtype: int64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 35 ms\n"
     ]
    }
   ],
   "source": [
    "df.groupby(['regional_tag','regional_tag3'])['regional_tag3'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "regional_tag                  regional_tag3  \n",
       "african                       african            [[[rice, with, chicken, and, fried, plantains]...\n",
       "asian                         chinese            [[[chinese, chicken, salad, iii]], [[chinese, ...\n",
       "                              indian             [[[easy, peasy, pea, salad]], [[besan]], [[ind...\n",
       "                              japanese           [[[traditional, beef, sukiyaki]], [[japanese, ...\n",
       "                              korean             [[[quick, and, easy, kimchi, salad]], [[kimchi...\n",
       "                              middle eastern     [[[eggplants, in, red, sauce]], [[tahini, dres...\n",
       "                              other asian        [[[(, chicken, cooked, in, coconut, milk, )]],...\n",
       "                              thai               [[[thai, green, mango, salad]], [[shrimp, and,...\n",
       "australian and new zealander  general western    [[[garbanzos, with, fennel]], [[pecan, dijon, ...\n",
       "european                      general western    [[[german, lasagna]], [[german, rhubarb, streu...\n",
       "                              italian            [[[italian, sausage, tuscan, style]], [[easy, ...\n",
       "latin american                latin american     [[[cream, cheese, jalapeno, dip]], [[karen, s,...\n",
       "north american                general western    [[[s, maid, sandwiches]], [[memphis, rub]], [[...\n",
       "Name: name_UNK, dtype: object"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 320 ms\n"
     ]
    }
   ],
   "source": [
    "gb = df.groupby(['regional_tag','regional_tag3'])['name_UNK'].apply(list)\n",
    "gb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 27.6 ms\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, precision_score\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 6.2 s\n"
     ]
    }
   ],
   "source": [
    "datasets = []\n",
    "labels = []\n",
    "for (tag, tag2), row in gb.iteritems():\n",
    "    datasets += row\n",
    "    labels += [tag2]*len(row)\n",
    "X, fn = get_wordcount_list([recipe[0] for recipe in datasets])\n",
    "y = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/helena/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/helena/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/helena/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/helena/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/helena/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/helena/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/helena/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/helena/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/helena/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/helena/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/helena/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/helena/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/helena/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/helena/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/helena/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/helena/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/helena/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/helena/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/helena/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/helena/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "        african       0.95      0.49      0.65        41\n",
      "        chinese       0.90      0.66      0.76        91\n",
      "general western       0.75      0.91      0.82       948\n",
      "         indian       0.81      0.68      0.74       127\n",
      "        italian       0.88      0.83      0.85       567\n",
      "       japanese       0.96      0.66      0.78        38\n",
      "         korean       0.96      0.89      0.92        27\n",
      " latin american       0.88      0.80      0.84       456\n",
      " middle eastern       0.78      0.32      0.46        56\n",
      "    other asian       1.00      0.48      0.65        33\n",
      "           thai       0.88      0.73      0.80        41\n",
      "\n",
      "      micro avg       0.82      0.82      0.82      2425\n",
      "      macro avg       0.89      0.68      0.75      2425\n",
      "   weighted avg       0.83      0.82      0.81      2425\n",
      "\n",
      "time: 3min 40s\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify = y, test_size = 0.2)\n",
    "p2_lr = {'solver': 'lbfgs','penalty':'l2','class_weight':None, 'multi_class': 'auto', 'max_iter': 300}\n",
    "model2 = LogisticRegression(**p2_lr)\n",
    "parameters = {'C': [0.1, 0.5, 1, 3, 10, 100, 500]}\n",
    "clf = GridSearchCV(model2, parameters, cv = 5, scoring = 'precision_weighted')\n",
    "clf.fit(X_train, y_train)\n",
    "print(classification_report(y_test, clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''alternative: LGBM\n",
    "from lightgbm import LGBMClassifier\n",
    "p2_lgbm = {'class_weight':'balanced','boosting':'gbrt'} \n",
    "model2 = LGBMClassifier(**p2_lgbm)\n",
    "parameters = {'num_leaves': [31, 50, 75], 'learning_rate':[0.1, 0.05, 0.01]}\n",
    "clf = GridSearchCV(model2, parameters, cv = 5)\n",
    "clf.fit(X_train, y_train)\n",
    "print(classification_report(y_test, clf.predict(X_test)))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 23.8 ms\n"
     ]
    }
   ],
   "source": [
    "# drop some keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 789 ms\n"
     ]
    }
   ],
   "source": [
    "style = ['chinese', 'japanese', 'korean','indian','pakistani','bangladeshi','persian','filipino',\n",
    "         'indonesian','vietnamese','thai', 'korean','italian', 'german',\n",
    "         'english','irish ','french','canadian','southern''african','caribbean','mexican']\n",
    "new_fn = [f for f in fn if f not in style]\n",
    "new_idx = [i for i, f in enumerate(fn) if f not in style]\n",
    "X = X[:,new_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/helena/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/helena/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/helena/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/helena/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/helena/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/helena/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/helena/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/helena/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/helena/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/helena/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/helena/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/helena/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/helena/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/helena/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/helena/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/helena/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/helena/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/helena/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/helena/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/helena/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/helena/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "        african       0.88      0.56      0.69        41\n",
      "        chinese       0.56      0.36      0.44        91\n",
      "general western       0.67      0.88      0.76       948\n",
      "         indian       0.78      0.63      0.70       127\n",
      "        italian       0.82      0.72      0.77       567\n",
      "       japanese       0.83      0.26      0.40        38\n",
      "         korean       0.86      0.22      0.35        27\n",
      " latin american       0.81      0.74      0.77       456\n",
      " middle eastern       0.76      0.34      0.47        56\n",
      "    other asian       0.83      0.15      0.26        33\n",
      "           thai       0.65      0.27      0.38        41\n",
      "\n",
      "      micro avg       0.73      0.73      0.73      2425\n",
      "      macro avg       0.77      0.47      0.54      2425\n",
      "   weighted avg       0.74      0.73      0.72      2425\n",
      "\n",
      "time: 3min 15s\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify = y, test_size = 0.2)\n",
    "p2_lr = {'solver': 'lbfgs','penalty':'l2','class_weight':None, 'multi_class': 'auto', 'max_iter': 300}\n",
    "model2 = LogisticRegression(**p2_lr)\n",
    "parameters = {'C': [0.1, 0.5, 1, 3, 10, 100, 500]}\n",
    "clf = GridSearchCV(model2, parameters, cv = 5, scoring = 'precision_weighted')\n",
    "clf.fit(X_train, y_train)\n",
    "print(classification_report(y_test, clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use all labelled data and train another model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/helena/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/helena/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/helena/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/helena/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/helena/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/helena/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/helena/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/helena/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/helena/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/helena/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/helena/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/helena/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/helena/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/helena/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=300, multi_class='auto',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='lbfgs',\n",
       "          tol=0.0001, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'C': [0.1, 0.5, 1, 3, 10, 100, 500]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='precision_weighted', verbose=0)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 4min 37s\n"
     ]
    }
   ],
   "source": [
    "datasets = []\n",
    "labels = []\n",
    "for (tag, tag2), row in gb.iteritems():\n",
    "    datasets += row\n",
    "    labels += [tag2]*len(row)\n",
    "X, fn = get_wordcount_list([recipe[0] for recipe in datasets])\n",
    "y = np.array(labels)\n",
    "\n",
    "p2_lr = {'solver': 'lbfgs','penalty':'l2','class_weight':None, 'multi_class': 'auto', 'max_iter': 300}\n",
    "model2 = LogisticRegression(**p2_lr)\n",
    "parameters = {'C': [0.1, 0.5, 1, 3, 10, 100, 500]}\n",
    "clf = GridSearchCV(model2, parameters, cv = 5, scoring = 'precision_weighted')\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 21 s\n"
     ]
    }
   ],
   "source": [
    "ls_unlabeled = [i for i, v in dic.items() if i in ls and float == type(v['regional_tag3']) and v['regional_tag'] != 'dual_region']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 18.6 s\n"
     ]
    }
   ],
   "source": [
    "corpus_list = [v['name_UNK'][0] for i,v in dic.items() if i in ls_unlabeled]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 26.9 ms\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "def wordcount_matrix(corpus_list, fn):\n",
    "    row, col, data = [], [], []\n",
    "\n",
    "    for i, recipe in enumerate(corpus_list):\n",
    "        for w, times in dict(Counter(recipe)).items():\n",
    "            if w in fn:\n",
    "                row.append(i)\n",
    "                col.append(fn.index(w))\n",
    "                data.append(times)\n",
    "\n",
    "    X = csr_matrix((data,(row,col)), shape=(len(corpus_list),len(fn)))\n",
    "    return X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 11.2 s\n"
     ]
    }
   ],
   "source": [
    "X_unlabeled = wordcount_matrix(corpus_list, fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 9.06 s\n"
     ]
    }
   ],
   "source": [
    "prediction = clf.predict(X_unlabeled).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 20.9 s\n"
     ]
    }
   ],
   "source": [
    "for i, prediction in zip(ls_unlabeled, prediction):\n",
    "    dic[i]['regional_predict'] = prediction\n",
    "ls_labeled = ls_unlabeled\n",
    "for i, v in dic.items():\n",
    "    if i in ls:\n",
    "        if dic[i]['regional_tag'] != 'dual_region' and type(v['regional_tag3']) != float:\n",
    "            dic[i]['regional_predict'] = v['regional_tag3']\n",
    "            ls_labeled.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 13.5 s\n"
     ]
    }
   ],
   "source": [
    "save_pickle(obj = dic, filename='../big_data/dic_regional_20190920.pickle',overwrite = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### filter the main dish and desserts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'main dishes'\n",
    "'desserts'\n",
    "'Soups Stew'\n",
    "'salad'\n",
    "'appetizers',\n",
    "'side dishes\n",
    "'Pasta Recipes'\n",
    "'Bread Recipes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 20.9 s\n"
     ]
    }
   ],
   "source": [
    "for i, v in dic.items():\n",
    "    if i in ls_labeled:\n",
    "        # filter out the ' recipe'\n",
    "        recipe = set([t[:-8] if t[-8:]==' recipes' else t for t in v['tags']])\n",
    "        if 'main dish' in recipe and 'desserts' in recipe:\n",
    "            dic[i]['meal_type'] = 'dual_type'\n",
    "        elif 'main dish' in recipe:\n",
    "            dic[i]['meal_type'] = 'main'\n",
    "        elif 'main dishes' in recipe:\n",
    "            dic[i]['meal_type'] = 'main'\n",
    "        elif 'desserts' in recipe:\n",
    "            dic[i]['meal_type'] = 'desserts'\n",
    "        else:\n",
    "            dic[i]['meal_type'] = 'others'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "meal_type  regional_predict\n",
       "desserts   african                21\n",
       "           chinese                27\n",
       "           general western     12269\n",
       "           indian                 63\n",
       "           italian               450\n",
       "           japanese               31\n",
       "           korean                  1\n",
       "           latin american        306\n",
       "           middle eastern         40\n",
       "           other asian            39\n",
       "           thai                   29\n",
       "           unknown                45\n",
       "dual_type  general western         3\n",
       "main       african                82\n",
       "           chinese               541\n",
       "           general western      9641\n",
       "           indian                434\n",
       "           italian              3265\n",
       "           japanese               92\n",
       "           korean                 87\n",
       "           latin american       1704\n",
       "           middle eastern        114\n",
       "           other asian           133\n",
       "           thai                  139\n",
       "           unknown               500\n",
       "others     african               129\n",
       "           chinese               201\n",
       "           general western     17054\n",
       "           indian                462\n",
       "           italian              2313\n",
       "           japanese              119\n",
       "           korean                 71\n",
       "           latin american       2193\n",
       "           middle eastern        304\n",
       "           other asian            17\n",
       "           thai                   98\n",
       "           unknown               612\n",
       "Name: meal_type, dtype: int64"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 55 ms\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame.from_dict(dic, orient = 'index')\n",
    "df.groupby(['meal_type','regional_predict'])['meal_type'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "decide to study the main dish in chinese, general western, italian, latin american style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
