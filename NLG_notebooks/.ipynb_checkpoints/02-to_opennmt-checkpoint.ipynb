{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 9.3 Âµs\n",
      "The autotime extension is already loaded. To reload it, use:\n",
      "  %reload_ext autotime\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "exist\n",
      "time: 12.4 s\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "%load_ext autotime\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "'''\n",
    "# if cannot import the modules, add the parent directory to system path might help\n",
    "\n",
    "import os\n",
    "import sys\n",
    "parent_dir = os.path.abspath(os.getcwd()+'/..')+'/'\n",
    "sys.path.append(parent_dir)\n",
    "'''\n",
    "\n",
    "import os\n",
    "from utils.path import dir_HugeFiles\n",
    "from utils.words import make_corpus_0, clean_wordcount, get_wordcount, replace_UNK, parse_section\n",
    "from utils.preprocessing import load, preprocessing, clean_ny\n",
    "from utils.save import make_dir, save_pickle, load_pickle, auto_save_csv, print_time\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "dir_save = os.path.normpath(dir_HugeFiles+'dph/dic_20190607.pickle')\n",
    "dic = load(dir_save)\n",
    "random_seed = 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drop 46 recipes with less than 2 ingredients\n",
      "time: 139 ms\n"
     ]
    }
   ],
   "source": [
    "ls = [i for i,v in dic.items() if len(v['ingredients'])>1]\n",
    "print('drop %d recipes with less than 2 ingredients' %(len(dic)-len(ls)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "furthur drop 1026 recipes with less than 2 instructions\n",
      "time: 88.7 ms\n"
     ]
    }
   ],
   "source": [
    "ls = [i for i in ls if len(dic[i]['directions'])>1]\n",
    "print('furthur drop %d recipes with less than 2 instructions' %(len(dic)-len(ls)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 82.2 ms\n"
     ]
    }
   ],
   "source": [
    "train_ls, test_ls = train_test_split(ls, test_size = 0.2, shuffle = True, random_state = random_seed)\n",
    "train_ls, val_ls = train_test_split(train_ls, test_size = 0.25, shuffle = True, random_state = random_seed + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/2 cup ketchup $ 1/4 cup prepared yellow mustard $ 1 cup cornflake crumbs $ 1 ( 16 ounce ) package all beef hot dogs\n",
      "\n",
      "preheat oven to 350 degrees f ( 175 degrees c ) . line a baking sheet with a sheet of aluminum foil . stir together ketchup and mustard on a plate until mixed . place the cornflake crumbs in a shallow bowl . roll each hot dog in the ketchup mixture , then roll in the cornflake crumbs to coat . place onto prepared baking sheet . bake in preheated oven until the hot dogs are hot on the inside , and crispy on the outside , 15 to 20 minutes .\n",
      "\n",
      "time: 25.6 ms\n"
     ]
    }
   ],
   "source": [
    "ingredients_list = dic[0]['ingredients_list']\n",
    "to_write = ' $ '.join([' '.join(ele) for ele in ingredients_list])\n",
    "print(to_write)\n",
    "print()\n",
    "directions_list = dic[0]['directions_list']\n",
    "to_write = ' '.join([' '.join(ele) for ele in directions_list])\n",
    "print(to_write)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 32.1 ms\n"
     ]
    }
   ],
   "source": [
    "def to_opennmt(key, ls, filename, delimiter = ' $ ', overwrite = False):\n",
    "    '''\n",
    "    params: key: string, the key of data, e.g. dic[0]['ingredients_list']\n",
    "    params: ls: list, he index of recipe, from train_test_split\n",
    "    params: filename, string, the filename of txt file\n",
    "    '''\n",
    "    make_dir(filename)\n",
    "    if os.path.isfile(filename) == True and overwrite == False:\n",
    "        print('already exists'+filename)\n",
    "    else:    \n",
    "        with open(filename,'w') as f:\n",
    "            for i, v in dic.items():\n",
    "                if i in ls:\n",
    "                    to_write = delimiter.join([' '.join(ele) for ele in v[key]])\n",
    "                    f.write(\"%s\\n\" % to_write)\n",
    "        print('saved '+filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size after train test split\n",
      "[32445, 10815, 10816]\n",
      "time: 34.2 ms\n"
     ]
    }
   ],
   "source": [
    "print('size after train test split')\n",
    "print([len(ls) for ls in [train_ls, val_ls, test_ls]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2min 14s\n"
     ]
    }
   ],
   "source": [
    "# takes about 3 min\n",
    "to_opennmt(key = 'ingredients_list', \n",
    "           ls = train_ls, \n",
    "           filename = dir_HugeFiles+'to_opennmt/train.ingred.atok'\n",
    "          )\n",
    "to_opennmt(key = 'ingredients_list', \n",
    "           ls = val_ls, \n",
    "           filename = dir_HugeFiles+'to_opennmt/val.ingred.atok'\n",
    "          )\n",
    "to_opennmt(key = 'ingredients_list', \n",
    "           ls = test_ls, \n",
    "           filename = dir_HugeFiles+'to_opennmt/test.ingred.atok'\n",
    "          )\n",
    "to_opennmt(key = 'directions_list', \n",
    "           ls = train_ls, \n",
    "           filename = dir_HugeFiles+'to_opennmt/train.instr.atok',\n",
    "           delimiter = ' '\n",
    "          )\n",
    "to_opennmt(key = 'directions_list', \n",
    "           ls = val_ls, \n",
    "           filename = dir_HugeFiles+'to_opennmt/val.instr.atok'\n",
    "          )\n",
    "to_opennmt(key = 'directions_list', \n",
    "           ls = test_ls, \n",
    "           filename = dir_HugeFiles+'to_opennmt/test.instr.atok'\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
