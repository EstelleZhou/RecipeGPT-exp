{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 7.15 Âµs\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "%load_ext autotime\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "# if cannot import the modules, add the parent directory to system path might help\n",
    "\n",
    "import os\n",
    "import sys\n",
    "parent_dir = os.path.abspath(os.getcwd()+'/..')+'/'\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "\n",
    "import os\n",
    "from utils.path import dir_HugeFiles\n",
    "from utils.preprocessing import load\n",
    "from utils.words import make_corpus_0, get_wordcount_list\n",
    "from utils.save import make_dir, save_pickle, load_pickle, auto_save_csv, print_time\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import inflect\n",
    "from collections import Counter\n",
    "\n",
    "#dir_save = os.path.normpath(dir_HugeFiles+'dph/dic_20190607.pickle')\n",
    "#dic = load(dir_save)\n",
    "random_seed = 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exist\n",
      "drop 46 recipes with less than 2 ingredients\n",
      "furthur drop 1026 recipes with less than 2 instructions\n",
      "drop 0 recipes with no description\n",
      "now we are using recipe54k 54076\n",
      "time: 1.51 s\n"
     ]
    }
   ],
   "source": [
    "dic = load(dir_save = '../big_data/dic_20190830.pickle')\n",
    "ls = [i for i,v in dic.items() if len(v['ingredients'])>1]\n",
    "print('drop %d recipes with less than 2 ingredients' %(len(dic)-len(ls)))\n",
    "ls = [i for i in ls if len(dic[i]['directions'])>1]\n",
    "print('furthur drop %d recipes with less than 2 instructions' %(len(dic)-len(ls)))\n",
    "desc = [i for i in ls if len(dic[i]['description'])<1]\n",
    "print('drop %d recipes with no description' %(len(desc)))\n",
    "print('now we are using recipe54k %d' % len(ls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 52.2 ms\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(dir_HugeFiles+'raw_data/food_taxonomy.txt',delimiter='\\t', header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "origin: length of data: 4294\n",
      "drop some fields: length of data: 2682\n",
      "drop duplicates: length of data: 2582\n",
      "time: 1.34 s\n"
     ]
    }
   ],
   "source": [
    "def cleaning(df):\n",
    "    '''\n",
    "    eliminate the row if it contains the following non-ingredient words\n",
    "    '''\n",
    "    print('origin: length of data: %d' % len(df))\n",
    "    eliminate = ['Snack brand', 'Preparation', 'Fast food', 'Dietary Supplement', 'Dessert']\n",
    "    for i in range(2):\n",
    "        df  = df[df.apply(lambda x: x[i] not in eliminate, axis = 1)]\n",
    "    # uncased\n",
    "    for i in range(3):\n",
    "        df[i]  = df.apply(lambda x: x[i].lower(), axis = 1)\n",
    "    print('drop some fields: length of data: %d' % len(df))    \n",
    "    \n",
    "    # drop the duplicates\n",
    "    df = df[~df[2].duplicated()]\n",
    "    df = df.reset_index(drop = True)\n",
    "    print('drop duplicates: length of data: %d' % len(df))\n",
    "        \n",
    "    return df\n",
    "df = cleaning(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bean and legume' 'beverage' 'breakfast cereal' 'condiment'\n",
      " 'egg and dairy' 'fruit' 'herb and spice' 'meat' 'mushroom' 'nut and seed'\n",
      " 'side dish' 'snack' 'staple' 'vegetable']\n",
      "['legume' 'soy product' 'alcohol' 'chocolate' 'coffee' 'energy drink'\n",
      " 'fruit juice' 'hot beverage' 'lemon beverage' 'milk substitutes'\n",
      " 'rice beverage' 'soft drink' 'breakfast cereal' 'condiment'\n",
      " 'dairy product' 'egg' 'berry' 'mediterranean' 'temperate' 'tropical'\n",
      " 'herbs' 'mixtures' 'peppers' 'spices' 'beef' 'fish' 'game' 'lamb' 'meat'\n",
      " 'meatball' 'pork' 'poultry' 'sausage' 'seafood' 'shellfish' 'mushroom'\n",
      " 'gymnosperm seed' 'nut' 'other' 'pseudocereal' 'antipasto' 'fries'\n",
      " 'legumes' 'maize' 'pasta' 'potatoes' 'salad' 'soup' 'snack' 'banana'\n",
      " 'other cereal' 'rice' 'root and tuber' 'wheat' 'bulb and stem vegetables'\n",
      " 'flowers and flower buds' 'fruits' 'leafy and salad' 'podded vegetables'\n",
      " 'root and tuberous vegetables' 'sea vegetables' 'vegetables']\n",
      "['bean' 'chickpea' 'cowpea' ... 'vegetables' 'vegetarian' 'veggie']\n",
      "time: 27.1 ms\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    print(df[i].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 24.7 ms\n"
     ]
    }
   ],
   "source": [
    "p = inflect.engine()\n",
    "class closest:\n",
    "    def __init__(self, series):\n",
    "        find_ngram = series.apply(lambda x: ' ' in x)\n",
    "        self.unigram_ingredients, self.ngram_ingredients = series[~find_ngram], series[find_ngram]\n",
    "        self.unigram_ingredients_pluraled = [p.plural(ingr) for ingr in self.unigram_ingredients]\n",
    "    \n",
    "    def ngram(self, listofline, pluraled_listofline):\n",
    "        answer = []\n",
    "        for ngram in self.ngram_ingredients.values:\n",
    "            n_list= ngram.split(' ')\n",
    "            intersection = set(listofline) & set(n_list)\n",
    "            if len(intersection) >= 2 and len(intersection) == len(n_list):\n",
    "                answer.append(ngram)\n",
    "            else:\n",
    "                # repeat\n",
    "                intersection = (set(pluraled_listofline) | set(intersection)) & set(n_list)\n",
    "                if len(intersection) >= 2 and len(intersection) == len(n_list):\n",
    "                    answer.append(ngram)\n",
    "        return set(answer)\n",
    "    \n",
    "    def unigram(self, listofline, pluraled_listofline):\n",
    "        first =  set(listofline) & set(self.unigram_ingredients)\n",
    "        if first:\n",
    "            return first\n",
    "        second = set(pluraled_listofline) & set(self.unigram_ingredients)\n",
    "        if second:\n",
    "            return second\n",
    "        \n",
    "    def check(self, listofline):\n",
    "        pluraled_listofline = [p.plural(word) for word in listofline]\n",
    "        ngram = self.ngram(listofline, pluraled_listofline)\n",
    "        if ngram:\n",
    "            return ngram\n",
    "        unigram = self.unigram(listofline, pluraled_listofline)\n",
    "        if unigram:\n",
    "            return unigram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "stage1: matching ingredients with food-taxonomy (from Aek) and known_ingr from Salvador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 210 ms\n"
     ]
    }
   ],
   "source": [
    "salvador = load_pickle(dir_HugeFiles+'raw_data/recipe1M/ingr_vocab.pkl')\n",
    "known_ingr = pd.concat([df[2], pd.Series([ingr.replace('_',' ') for ingr in salvador if '<' not in ingr])], ignore_index=True)\n",
    "known_ingr = known_ingr[~known_ingr.duplicated()]\n",
    "model = closest(known_ingr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "37000\n",
      "38000\n",
      "39000\n",
      "40000\n",
      "41000\n",
      "42000\n",
      "43000\n",
      "44000\n",
      "45000\n",
      "46000\n",
      "47000\n",
      "48000\n",
      "49000\n",
      "50000\n",
      "51000\n",
      "52000\n",
      "53000\n",
      "54000\n",
      "55000\n",
      "time: 1h 48s\n"
     ]
    }
   ],
   "source": [
    "# may takes ~100 minutes\n",
    "transformeds = []\n",
    "for i, v in dic.items():\n",
    "    if i in ls:\n",
    "        ingredients = [sent.split(' ') for sent in v['ingredients']]\n",
    "        transformed = [model.check(ingred) for ingred in ingredients]\n",
    "        dic[i]['ingred_level2'] = transformed\n",
    "        transformeds += transformed\n",
    "    if not i % 1000:\n",
    "        print(i)\n",
    "\n",
    "save_pickle(obj=dic, filename='../big_data/dic_20190831.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the popular ingredients (ocurrence > 100) in salvador's list. <br>\n",
    "Maunally add them to the food-taxonomy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 42.4 s\n"
     ]
    }
   ],
   "source": [
    "# take 1 min\n",
    "dic = load_pickle(filename='../big_data/dic_20190831.pickle')\n",
    "transformeds = []\n",
    "for i, v in dic.items():\n",
    "    if i in ls:\n",
    "        transformed = [ing for ingr in v['ingred_level2'] if ingr for ing in ingr]\n",
    "        transformeds += transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 228 ms\n"
     ]
    }
   ],
   "source": [
    "# count the occurrences of ingr indentified by salvador\n",
    "count =  dict(Counter(transformeds))\n",
    "common_sal = [k for k, v in count.items() if v>100 and k not in df[2].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before processing: length of data: 2582\n",
      "add some rows: length of data: 2685\n",
      "drop duplicates: length of data: 2684\n",
      "time: 848 ms\n"
     ]
    }
   ],
   "source": [
    "additional_ingr=\\\n",
    "[\n",
    "['Condiment', 'Sweet', 'sugar'],\n",
    "['Condiment', 'Sweet', 'applesauce'],\n",
    "['Flour', 'Flour','flour'],\n",
    "['Baking powder','Baking powder','baking powder'],\n",
    "['Water','Water','water'],\n",
    "['Water','Water','iced'],\n",
    "['Water','Water','ice'],\n",
    "['Herb and spice','spices','jalapeno'],\n",
    "['Condiment','Condiment', 'oil'],\n",
    "['Beverage','Fruit juice', 'juice'],\n",
    "['Staple','Maize','enchilada'],\n",
    "['Condiment','Condiment', 'dressing mix'],\n",
    "['Condiment','Condiment', 'cheese mix'],\n",
    "['Baking powder','Baking powder','baking soda'],\n",
    "['Condiment','Condiment', 'dry mix'],\n",
    "['Condiment','Condiment','chocolate'],\n",
    "['Vegetable','Bulb and stem vegetables','tapioca'],\n",
    "['Flour', 'Flour','xanthan gum'],\n",
    "['Flour', 'Flour','starch'],\n",
    "['Egg and dairy', 'Dairy product','buttermilk'],\n",
    "['Condiment','Condiment','chili'],\n",
    "['Condiment','Condiment','chile'],\n",
    "['Condiment','Condiment','chilis'],\n",
    "['Condiment','Condiment','chiles'],\n",
    "['Condiment','Condiment','chilies'],\n",
    "['Flour', 'Flour','corn muffin mix'],\n",
    "['Beverage','Chocolate','chocolate mix'],\n",
    "['Meat','dumpling','dumpling'],\n",
    "['Meat','dumpling','wonton'],\n",
    "['Staple','Wheat','pizza dough'],\n",
    "['Staple','Wheat','dough'],\n",
    "['Condiment','Condiment', 'pizza sauce'],\n",
    "['Flour', 'Flour','yeast'],\n",
    "['Condiment','Sweet','cocoa'],\n",
    "['Staple','Maize','chip'],\n",
    "['Egg and dairy','Dairy product','ricotta'],\n",
    "['Condiment','Condiment','seasoning'],\n",
    "['Beverage','Alcohol','sherry'],\n",
    "['Staple','Rice','grain rice'], \n",
    "['Staple','Wheat','shell'],\n",
    "['Meat','Beef','fillet'],\n",
    "['Staple','Maize','cornmeal'],\n",
    "['Condiment','Condiment','seed oil'],\n",
    "['Nut and seed','Other','seed'],\n",
    "['Condiment', 'Sweet', 'sugar blend'],\n",
    "['Soup','Soup','broth'],\n",
    "['Soup','Soup','stock'],\n",
    "['Condiment', 'Sweet', 'marshmallow'],\n",
    "['Condiment', 'Dry Condiment', 'dried vegetable flakes'],\n",
    "['Condiment', 'Dry Condiment', 'dried celery flakes'],\n",
    "['Flour', 'Flour','cornstarch'],\n",
    "['Staple','Wheat','double crust'],\n",
    "['Staple','Wheat','crust'],\n",
    "['Staple','Wheat','pastry crust'],\n",
    "['Egg and dairy','Dairy product','gorgonzola'],\n",
    "['Beverage','juice','drink mix'],\n",
    "['Egg and dairy','Egg','Egg whites'],\n",
    "['Baking powder','Baking powder','baking mix'],\n",
    "['Staple','Rice','brown rice'],\n",
    "['Condiment','Condiment','five spice'],\n",
    "['Meat','Beef','tenderloin'],\n",
    "['Meat','Pork','prosciutto'],\n",
    "['Condiment', 'Sweet', 'whipped topping'],\n",
    "['Condiment', 'Sweet', 'topping'],\n",
    "['Beverage','Alcohol','cider'],\n",
    "['Meat','Shellfish','crabmeat'],\n",
    "['Condiment', 'Sweet', 'candy'],\n",
    "['Condiment', 'Sweet', 'caramel'],\n",
    "['Condiment', 'Sweet', 'molasses'],\n",
    "['Vegetable','Podded vegetables','cannellini'],\n",
    "['Vegetable','Fruits','fruit'],\n",
    "['Staple','Wheat','saltine'],\n",
    "['Condiment','Condiment', 'habanero'],\n",
    "['Beverage','Juice','jell o'],\n",
    "['Beverage','Juice','jelly'],\n",
    "['Beverage','Soft drink','carbonated beverage'],\n",
    "['Egg and dairy','Dairy product','gruyere'],\n",
    "['Vegetable','Leafy and Salad','beet'],\n",
    "['Water','Water','icing'],\n",
    "['Egg and dairy','Dairy product','parmigiano'],\n",
    "['Beverage','Alcohol','liqueur'],\n",
    "['Condiment','Condiment', 'lard'],\n",
    "['Staple','Wheat','crumb'],\n",
    "['Herb and spice','Herb','peppermint'],\n",
    "['Beverage','Alcohol','marsala'],\n",
    "['Side dish','Potatoes','hash brown'],\n",
    "['Meat','Beef','steak'],\n",
    "['Condiment','Condiment','gelatin'],\n",
    "['Meat','Beef','chuck'],\n",
    "['Egg and dairy','Dairy product','colby'],\n",
    "['Condiment', 'Sweet', 'jam'],\n",
    "['Condiment', 'Sweet', 'cool whip'],\n",
    "['Condiment', 'Sweet', 'stevia'],\n",
    "['Staple','Wheat','bran'],\n",
    "['Condiment','Condiment','pimento'],\n",
    "['Condiment','Condiment','food coloring'],\n",
    "['Meat','Meat','rib'],\n",
    "['Condiment','Condiment','shortening'],\n",
    "['Vegetable','Fruits','sweet pickles'],\n",
    "['Condiment', 'Sweet', 'white confectioner'],\n",
    "['Condiment', 'Sweet', 'confectioner'],  \n",
    "['Vegetable','Root and tuberous vegetabless','rhubarb'],\n",
    "['Condiment', 'Condiment', 'cooking spray']\n",
    "]\n",
    "\n",
    "def add_rows(df, additional_ingr):\n",
    "    add = pd.DataFrame(additional_ingr)\n",
    "    print('before processing: length of data: %d' % len(df))\n",
    "    df = pd.concat([df,add]).reset_index(drop =True)\n",
    "\n",
    "    # uncased\n",
    "    for i in range(3):\n",
    "        df[i]  = df.apply(lambda x: x[i].lower().strip(), axis = 1)\n",
    "    print('add some rows: length of data: %d' % len(df))    \n",
    "    \n",
    "    # drop the duplicates\n",
    "    df = df[~df[2].duplicated()]\n",
    "    df = df.reset_index(drop = True)\n",
    "    print('drop duplicates: length of data: %d' % len(df))\n",
    "    return df\n",
    "\n",
    "df = add_rows(df, additional_ingr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "37000\n",
      "38000\n",
      "39000\n",
      "40000\n",
      "41000\n",
      "42000\n",
      "43000\n",
      "44000\n",
      "45000\n",
      "46000\n",
      "47000\n",
      "48000\n",
      "49000\n",
      "50000\n",
      "51000\n",
      "52000\n",
      "53000\n",
      "54000\n",
      "55000\n",
      "time: 42min\n"
     ]
    }
   ],
   "source": [
    "# prepare the ingredient detection algorithm\n",
    "model = closest(df[2])\n",
    "\n",
    "# may takes ~24 minutes\n",
    "transformeds = []\n",
    "for i, v in dic.items():\n",
    "    if i in ls:\n",
    "        ingredients = [sent.split(' ') for sent in v['ingredients']]\n",
    "        transformed = [model.check(ingred) for ingred in ingredients]\n",
    "        dic[i]['ingred_level2'] = transformed\n",
    "        transformeds += transformed\n",
    "    if not i % 1000:\n",
    "        print(i)\n",
    "save_pickle(obj=dic, filename='../big_data/dic_20190831_extra.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9793 recipes was almost converted\n",
      "0.8394 recipes was fully converted\n",
      "512222 lines of ingredient in total\n",
      "0.9806 lines of ingredient was transformed\n",
      "\n",
      "0.9597 recipes was almost converted\n",
      "0.7568 recipes was fully converted\n",
      "512222 lines of ingredient in total\n",
      "0.9692 lines of ingredient was transformed\n",
      "time: 1min 35s\n"
     ]
    }
   ],
   "source": [
    "def conversion_rate(dic):\n",
    "    converts, transformeds = [], []\n",
    "    for i, v in dic.items():\n",
    "        if i in ls:\n",
    "            convert = len([ingr for ingr in v['ingred_level2'] if not ingr])\n",
    "            converts.append(convert)\n",
    "            transformeds += v['ingred_level2']\n",
    "    converts = pd.Series(converts)\n",
    "    print('%.4f recipes was almost converted' % (sum(converts<=1)/len(converts)))\n",
    "    print('%.4f recipes was fully converted' % (sum(converts==0)/len(converts)))\n",
    "    \n",
    "    print('%d lines of ingredient in total' % len(transformeds))\n",
    "    print('%.4f lines of ingredient was transformed' % (len([t for t in transformeds if t])/len(transformeds)))\n",
    "    return converts, transformeds\n",
    "\n",
    "# Aek and Salvadors\n",
    "dic = load_pickle(filename='../big_data/dic_20190831.pickle') \n",
    "converts, transformeds = conversion_rate(dic)\n",
    "print()\n",
    "# Aek and Helena\n",
    "dic_extra = load_pickle(filename='../big_data/dic_20190831_extra.pickle')\n",
    "converts, transformeds = conversion_rate(dic_extra)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Then, I manually sample some recipes and reviewed the precision\n",
    "number of ingredients/ number of ingredients found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([None,\n",
       "  {'ham'},\n",
       "  {'cheese'},\n",
       "  {'cheese'},\n",
       "  {'salami'},\n",
       "  {'pepperoni', 'sausage'},\n",
       "  {'pepper'},\n",
       "  {'egg'},\n",
       "  {'parmesan cheese'},\n",
       "  {'pepper'}],\n",
       " ['2 ( 10 ounce ) cans refrigerated crescent dinner rolls',\n",
       "  '1/4 pound thinly sliced boiled ham',\n",
       "  '1/4 pound thinly sliced provolone cheese',\n",
       "  '1/4 pound thinly sliced swiss cheese',\n",
       "  '1/4 pound thinly sliced genoa salami',\n",
       "  '1/4 pound thinly sliced pepperoni sausage',\n",
       "  '1 ( 12 ounce ) jar roasted red peppers , drained , cut into thin strips',\n",
       "  '3 eggs',\n",
       "  '3 tablespoons grated parmesan cheese',\n",
       "  '1/2 teaspoon ground black pepper'])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 22.5 ms\n"
     ]
    }
   ],
   "source": [
    "sample_100 = [i for i in ls if not i%7][:100]\n",
    "i = sample_100[20]\n",
    "print(sum([len(v) for v in dic_extra[i]['ingred_level2'] if v]))\n",
    "dic_extra[i]['ingred_level2'], dic_extra[i]['ingredients']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 28.2 ms\n"
     ]
    }
   ],
   "source": [
    "# how many reasonable found; how many found\n",
    "# tp, all p, all true\n",
    "annotate = {0:[4,5],\n",
    "           1:[5,5],\n",
    "           2:[12,13],\n",
    "           3:[5,5],\n",
    "           4:[10,11],\n",
    "           5:[6,6],\n",
    "           6:[6,6],\n",
    "           7:[4,4],\n",
    "           8:[6,7],\n",
    "           9:[13,15],\n",
    "           10:[7,9],\n",
    "           11:[8,9],\n",
    "           12:[7,8],\n",
    "           13:[19,19],\n",
    "           14:[5,5],\n",
    "           15:[5,5],\n",
    "           16:[16,16],\n",
    "           17:[5,6],\n",
    "           18:[10,10],\n",
    "           19:[10,11],\n",
    "           20:[10,11]}\n",
    "\n",
    "# note: tomatoes cannot recognize\n",
    "# whole wheat --> flour\n",
    "# the later word is better\n",
    "# 'chile', 'pepper' should be one word\n",
    "# if have to pick one answer, the latter is better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count the occurrences of ingr indentified by salvador\n",
    "count =  dict(Counter([t for tr in transformeds if tr for t in tr]))\n",
    "rare = [k for k, v in count.items() if v < 5]\n",
    "rare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in count.keys() in k not in additional_ingr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 24.6 ms\n"
     ]
    }
   ],
   "source": [
    "#dic_extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54076"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 27.8 ms\n"
     ]
    }
   ],
   "source": [
    "len(ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In average, there are  9.472261261927658  lines in one recipe\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fe7bee10be0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In average, there are  9.407703972187292  keywords in one recipe\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fe7bee10be0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 24.3 s\n"
     ]
    }
   ],
   "source": [
    "def ingred_numbers(dic):\n",
    "    n_lines, n_keywords = [], []\n",
    "    for i, v in dic_extra.items():\n",
    "        if i in ls:\n",
    "            n_line = len(dic[i]['ingred_level2'])\n",
    "            try: \n",
    "                n_keyword = len(set.union(*[line for line in dic[i]['ingred_level2'] if line]))\n",
    "            except TypeError:\n",
    "                n_keyword = 0\n",
    "            n_lines.append(n_line)\n",
    "            n_keywords.append(n_keyword)\n",
    "        \n",
    "    print('In average, there are ',pd.Series(n_lines).mean(), ' lines in one recipe')\n",
    "    display(pd.Series(n_lines).hist())\n",
    "    print('In average, there are ',pd.Series(n_keywords).mean(), ' keywords in one recipe')\n",
    "    display(pd.Series(n_keywords).hist())\n",
    "ingred_numbers(dic_extra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 24.4 s\n"
     ]
    }
   ],
   "source": [
    "all_keywords = []\n",
    "for i, v in dic_extra.items():\n",
    "    if i in ls:\n",
    "        try:\n",
    "            keyword = set.union(*[line for line in dic_extra[i]['ingred_level2'] if line])\n",
    "            all_keywords.append(keyword)\n",
    "        except:\n",
    "            pass\n",
    "set_keywords = frozenset().union(*all_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1052"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 20.8 ms\n"
     ]
    }
   ],
   "source": [
    "len(set_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
