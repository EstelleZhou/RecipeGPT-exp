{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 10 Âµs\n",
      "The autotime extension is already loaded. To reload it, use:\n",
      "  %reload_ext autotime\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "time: 29 ms\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "%load_ext autotime\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "# if cannot import the modules, add the parent directory to system path might help\n",
    "\n",
    "import os\n",
    "import sys\n",
    "parent_dir = os.path.abspath(os.getcwd()+'/..')+'/'\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "\n",
    "import os\n",
    "from utils.path import dir_HugeFiles\n",
    "from utils.preprocessing_0716 import load\n",
    "from utils.words import make_corpus_0, get_wordcount_list\n",
    "from utils.save import make_dir, save_pickle, load_pickle, auto_save_csv, print_time\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import inflect\n",
    "from collections import Counter\n",
    "\n",
    "#dir_save = os.path.normpath(dir_HugeFiles+'dph/dic_20190607.pickle')\n",
    "#dic = load(dir_save)\n",
    "random_seed = 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exist\n",
      "drop 46 recipes with less than 2 ingredients\n",
      "furthur drop 1026 recipes with less than 2 instructions\n",
      "drop 0 recipes with no description\n",
      "now we are using recipe54k 54076\n",
      "time: 2.22 s\n"
     ]
    }
   ],
   "source": [
    "dic = load(dir_save = dir_HugeFiles+'nlg/dic_20190716.pickle')\n",
    "ls = [i for i,v in dic.items() if len(v['ingredients'])>1]\n",
    "print('drop %d recipes with less than 2 ingredients' %(len(dic)-len(ls)))\n",
    "ls = [i for i in ls if len(dic[i]['directions'])>1]\n",
    "print('furthur drop %d recipes with less than 2 instructions' %(len(dic)-len(ls)))\n",
    "desc = [i for i in ls if len(dic[i]['description'])<1]\n",
    "print('drop %d recipes with no description' %(len(desc)))\n",
    "print('now we are using recipe54k %d' % len(ls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 27.4 ms\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(dir_HugeFiles+'raw_data/food_taxonomy.txt',delimiter='\\t', header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 16.9 ms\n"
     ]
    }
   ],
   "source": [
    "ls = range(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "origin: length of data: 4294\n",
      "drop some fields: length of data: 2682\n",
      "drop duplicates: length of data: 2582\n",
      "time: 959 ms\n"
     ]
    }
   ],
   "source": [
    "def cleaning(df):\n",
    "    '''\n",
    "    eliminate the row if it contains the following non-ingredient words\n",
    "    '''\n",
    "    print('origin: length of data: %d' % len(df))\n",
    "    eliminate = ['Snack brand', 'Preparation', 'Fast food', 'Dietary Supplement', 'Dessert']\n",
    "    for i in range(2):\n",
    "        df  = df[df.apply(lambda x: x[i] not in eliminate, axis = 1)]\n",
    "    # uncased\n",
    "    for i in range(3):\n",
    "        df[i]  = df.apply(lambda x: x[i].lower(), axis = 1)\n",
    "    print('drop some fields: length of data: %d' % len(df))    \n",
    "    \n",
    "    # drop the duplicates\n",
    "    df = df[~df[2].duplicated()]\n",
    "    df = df.reset_index(drop = True)\n",
    "    print('drop duplicates: length of data: %d' % len(df))\n",
    "        \n",
    "    return df\n",
    "df = cleaning(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bean and legume' 'beverage' 'breakfast cereal' 'condiment'\n",
      " 'egg and dairy' 'fruit' 'herb and spice' 'meat' 'mushroom' 'nut and seed'\n",
      " 'side dish' 'snack' 'staple' 'vegetable']\n",
      "['legume' 'soy product' 'alcohol' 'chocolate' 'coffee' 'energy drink'\n",
      " 'fruit juice' 'hot beverage' 'lemon beverage' 'milk substitutes'\n",
      " 'rice beverage' 'soft drink' 'breakfast cereal' 'condiment'\n",
      " 'dairy product' 'egg' 'berry' 'mediterranean' 'temperate' 'tropical'\n",
      " 'herbs' 'mixtures' 'peppers' 'spices' 'beef' 'fish' 'game' 'lamb' 'meat'\n",
      " 'meatball' 'pork' 'poultry' 'sausage' 'seafood' 'shellfish' 'mushroom'\n",
      " 'gymnosperm seed' 'nut' 'other' 'pseudocereal' 'antipasto' 'fries'\n",
      " 'legumes' 'maize' 'pasta' 'potatoes' 'salad' 'soup' 'snack' 'banana'\n",
      " 'other cereal' 'rice' 'root and tuber' 'wheat' 'bulb and stem vegetables'\n",
      " 'flowers and flower buds' 'fruits' 'leafy and salad' 'podded vegetables'\n",
      " 'root and tuberous vegetables' 'sea vegetables' 'vegetables']\n",
      "['bean' 'chickpea' 'cowpea' ... 'vegetables' 'vegetarian' 'veggie']\n",
      "time: 21.5 ms\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    print(df[i].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 20.9 ms\n"
     ]
    }
   ],
   "source": [
    "p = inflect.engine()\n",
    "class closest:\n",
    "    def __init__(self, series):\n",
    "        find_ngram = series.apply(lambda x: ' ' in x)\n",
    "        self.unigram_ingredients, self.ngram_ingredients = series[~find_ngram], series[find_ngram]\n",
    "        self.unigram_ingredients_pluraled = [p.plural(ingr) for ingr in self.unigram_ingredients]\n",
    "    \n",
    "    def ngram(self, listofline, pluraled_listofline):\n",
    "        answer = []\n",
    "        for ngram in self.ngram_ingredients.values:\n",
    "            n_list= ngram.split(' ')\n",
    "            intersection = set(listofline) & set(n_list)\n",
    "            if len(intersection) >= 2:\n",
    "                answer.append(ngram)\n",
    "            else:\n",
    "                # repeat\n",
    "                intersection = (set(pluraled_listofline) | set(intersection)) & set(n_list)\n",
    "                if len(intersection) >= 2:\n",
    "                    answer.append(ngram)\n",
    "        return set(answer)\n",
    "    \n",
    "    def unigram(self, listofline, pluraled_listofline):\n",
    "        first =  set(listofline) & set(self.unigram_ingredients)\n",
    "        if first:\n",
    "            return first\n",
    "        second = set(pluraled_listofline) & set(self.unigram_ingredients)\n",
    "        if second:\n",
    "            return second\n",
    "    def check(self, listofline):\n",
    "        pluraled_listofline = [p.plural(word) for word in listofline]\n",
    "        ngram = self.ngram(listofline, pluraled_listofline)\n",
    "        if ngram:\n",
    "            return ngram\n",
    "        unigram = self.unigram(listofline, pluraled_listofline)\n",
    "        if unigram:\n",
    "            return unigram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "stage1: matching ingredients with food-taxonomy (from Aek) and known_ingr from Salvador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 171 ms\n"
     ]
    }
   ],
   "source": [
    "salvador = load_pickle(dir_HugeFiles+'raw_data/recipe1M/ingr_vocab.pkl')\n",
    "known_ingr = pd.concat([df[2], pd.Series([ingr.replace('_',' ') for ingr in salvador if '<' not in ingr])], ignore_index=True)\n",
    "known_ingr = known_ingr[~known_ingr.duplicated()]\n",
    "model = closest(known_ingr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# may takes ~40 minutes\n",
    "transformeds = []\n",
    "for i, v in dic.items():\n",
    "    if i in ls:\n",
    "        ingredients = [sent.split(' ') for sent in v['ingredients']]\n",
    "        transformed = [model.check(ingred) for ingred in ingredients]\n",
    "        dic[i]['ingred_level2'] = transformed\n",
    "        transformeds += transformed\n",
    "    if not i % 1000:\n",
    "        print(i)\n",
    "\n",
    "save_pickle(obj=dic, filename=dir_HugeFiles+'dic_20190721.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the popular ingredients (ocurrence > 100) in salvador's list. <br>\n",
    "Maunally add them to the food-taxonomy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 27.4 s\n"
     ]
    }
   ],
   "source": [
    "# take 1 min\n",
    "dic = load_pickle(filename=dir_HugeFiles+'dic_20190721.pickle')\n",
    "transformeds = []\n",
    "for i, v in dic.items():\n",
    "    if i in ls:\n",
    "        transformed = [ing for ingr in v['ingred_level2'] if ingr for ing in ingr]\n",
    "        transformeds += transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 160 ms\n"
     ]
    }
   ],
   "source": [
    "# count the occurrences of ingr indentified by salvador\n",
    "count =  dict(Counter(transformeds))\n",
    "common_sal = [k for k, v in count.items() if v>100 and k not in df[2].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before processing: length of data: 2684\n",
      "add some rows: length of data: 2787\n",
      "drop duplicates: length of data: 2684\n",
      "time: 549 ms\n"
     ]
    }
   ],
   "source": [
    "additional_ingr=\\\n",
    "[\n",
    "['Condiment', 'Sweet', 'sugar'],\n",
    "['Condiment', 'Sweet', 'applesauce'],\n",
    "['Flour', 'Flour','flour'],\n",
    "['Baking powder','Baking powder','baking powder'],\n",
    "['Water','Water','water'],\n",
    "['Water','Water','iced'],\n",
    "['Water','Water','ice'],\n",
    "['Herb and spice','spices','jalapeno'],\n",
    "['Condiment','Condiment', 'oil'],\n",
    "['Beverage','Fruit juice', 'juice'],\n",
    "['Staple','Maize','enchilada'],\n",
    "['Condiment','Condiment', 'dressing mix'],\n",
    "['Condiment','Condiment', 'cheese mix'],\n",
    "['Baking powder','Baking powder','baking soda'],\n",
    "['Condiment','Condiment', 'dry mix'],\n",
    "['Condiment','Condiment','chocolate'],\n",
    "['Vegetable','Bulb and stem vegetables','tapioca'],\n",
    "['Flour', 'Flour','xanthan gum'],\n",
    "['Flour', 'Flour','starch'],\n",
    "['Egg and dairy', 'Dairy product','buttermilk'],\n",
    "['Condiment','Condiment','chili'],\n",
    "['Condiment','Condiment','chile'],\n",
    "['Condiment','Condiment','chilis'],\n",
    "['Condiment','Condiment','chiles'],\n",
    "['Condiment','Condiment','chilies'],\n",
    "['Flour', 'Flour','corn muffin mix'],\n",
    "['Beverage','Chocolate','chocolate mix'],\n",
    "['Meat','dumpling','dumpling'],\n",
    "['Meat','dumpling','wonton'],\n",
    "['Staple','Wheat','pizza dough'],\n",
    "['Staple','Wheat','dough'],\n",
    "['Condiment','Condiment', 'pizza sauce'],\n",
    "['Flour', 'Flour','yeast'],\n",
    "['Condiment','Sweet','cocoa'],\n",
    "['Staple','Maize','chip'],\n",
    "['Egg and dairy','Dairy product','ricotta'],\n",
    "['Condiment','Condiment','seasoning'],\n",
    "['Beverage','Alcohol','sherry'],\n",
    "['Staple','Rice','grain rice'], \n",
    "['Staple','Wheat','shell'],\n",
    "['Meat','Beef','fillet'],\n",
    "['Staple','Maize','cornmeal'],\n",
    "['Condiment','Condiment','seed oil'],\n",
    "['Nut and seed','Other','seed'],\n",
    "['Condiment', 'Sweet', 'sugar blend'],\n",
    "['Soup','Soup','broth'],\n",
    "['Soup','Soup','stock'],\n",
    "['Condiment', 'Sweet', 'marshmallow'],\n",
    "['Condiment', 'Dry Condiment', 'dried vegetable flakes'],\n",
    "['Condiment', 'Dry Condiment', 'dried celery flakes'],\n",
    "['Flour', 'Flour','cornstarch'],\n",
    "['Staple','Wheat','double crust'],\n",
    "['Staple','Wheat','crust'],\n",
    "['Staple','Wheat','pastry crust'],\n",
    "['Egg and dairy','Dairy product','gorgonzola'],\n",
    "['Beverage','juice','drink mix'],\n",
    "['Egg and dairy','Egg','Egg whites'],\n",
    "['Baking powder','Baking powder','baking mix'],\n",
    "['Staple','Rice','brown rice'],\n",
    "['Condiment','Condiment','five spice'],\n",
    "['Meat','Beef','tenderloin'],\n",
    "['Meat','Pork','prosciutto'],\n",
    "['Condiment', 'Sweet', 'whipped topping'],\n",
    "['Condiment', 'Sweet', 'topping'],\n",
    "['Beverage','Alcohol','cider'],\n",
    "['Meat','Shellfish','crabmeat'],\n",
    "['Condiment', 'Sweet', 'candy'],\n",
    "['Condiment', 'Sweet', 'caramel'],\n",
    "['Condiment', 'Sweet', 'molasses'],\n",
    "['Vegetable','Podded vegetables','cannellini'],\n",
    "['Vegetable','Fruits','fruit'],\n",
    "['Staple','Wheat','saltine'],\n",
    "['Condiment','Condiment', 'habanero'],\n",
    "['Beverage','Juice','jell o'],\n",
    "['Beverage','Juice','jelly'],\n",
    "['Beverage','Soft drink','carbonated beverage'],\n",
    "['Egg and dairy','Dairy product','gruyere'],\n",
    "['Vegetable','Leafy and Salad','beet'],\n",
    "['Water','Water','icing'],\n",
    "['Egg and dairy','Dairy product','parmigiano'],\n",
    "['Beverage','Alcohol','liqueur'],\n",
    "['Condiment','Condiment', 'lard'],\n",
    "['Staple','Wheat','crumb'],\n",
    "['Herb and spice','Herb','peppermint'],\n",
    "['Beverage','Alcohol','marsala'],\n",
    "['Side dish','Potatoes','hash brown'],\n",
    "['Meat','Beef','steak'],\n",
    "['Condiment','Condiment','gelatin'],\n",
    "['Meat','Beef','chuck'],\n",
    "['Egg and dairy','Dairy product','colby'],\n",
    "['Condiment', 'Sweet', 'jam'],\n",
    "['Condiment', 'Sweet', 'cool whip'],\n",
    "['Condiment', 'Sweet', 'stevia'],\n",
    "['Staple','Wheat','bran'],\n",
    "['Condiment','Condiment','pimento'],\n",
    "['Condiment','Condiment','food coloring'],\n",
    "['Meat','Meat','rib'],\n",
    "['Condiment','Condiment','shortening'],\n",
    "['Vegetable','Fruits','sweet pickles'],\n",
    "['Condiment', 'Sweet', 'white confectioner'],\n",
    "['Condiment', 'Sweet', 'confectioner'],  \n",
    "['Vegetable','Root and tuberous vegetabless','rhubarb'],\n",
    "['Condiment', 'Condiment', 'cooking spray']\n",
    "]\n",
    "\n",
    "def add_rows(df, additional_ingr):\n",
    "    add = pd.DataFrame(additional_ingr)\n",
    "    print('before processing: length of data: %d' % len(df))\n",
    "    df = pd.concat([df,add]).reset_index(drop =True)\n",
    "\n",
    "    # uncased\n",
    "    for i in range(3):\n",
    "        df[i]  = df.apply(lambda x: x[i].lower().strip(), axis = 1)\n",
    "    print('add some rows: length of data: %d' % len(df))    \n",
    "    \n",
    "    # drop the duplicates\n",
    "    df = df[~df[2].duplicated()]\n",
    "    df = df.reset_index(drop = True)\n",
    "    print('drop duplicates: length of data: %d' % len(df))\n",
    "    return df\n",
    "\n",
    "df = add_rows(df, additional_ingr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "already exists/data/yueliu/RecipeAnalytics_201906/dic_20190722.pickle\n",
      "time: 25min 13s\n"
     ]
    }
   ],
   "source": [
    "# prepare the ingredient detection algorithm\n",
    "model = closest(df[2])\n",
    "\n",
    "# may takes ~24 minutes\n",
    "transformeds = []\n",
    "for i, v in dic.items():\n",
    "    if i in ls:\n",
    "        ingredients = [sent.split(' ') for sent in v['ingredients']]\n",
    "        transformed = [model.check(ingred) for ingred in ingredients]\n",
    "save_pickle(obj=dic, filename=dir_HugeFiles+'dic_20190722.pickle', overwrite = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9801 recipes was almost converted\n",
      "0.8597 recipes was fully converted\n",
      "512222 lines of ingredient in total\n",
      "0.9826 lines of ingredient was transformed\n",
      "time: 20.3 s\n"
     ]
    }
   ],
   "source": [
    "# take 1 min\n",
    "#dic = load_pickle(filename=dir_HugeFiles+'dic_20190722.pickle')\n",
    "\n",
    "def conversion_rate(dic):\n",
    "    converts, transformeds = [], []\n",
    "    for i, v in dic.items():\n",
    "        if i in ls:\n",
    "            convert = len([ingr for ingr in v['ingred_level2'] if not ingr])\n",
    "            converts.append(convert)\n",
    "            transformeds += v['ingred_level2']\n",
    "    converts = pd.Series(converts)\n",
    "    print('%.4f recipes was almost converted' % (sum(converts<=1)/len(converts)))\n",
    "    print('%.4f recipes was fully converted' % (sum(converts==0)/len(converts)))\n",
    "    \n",
    "    print('%d lines of ingredient in total' % len(transformeds))\n",
    "    print('%.4f lines of ingredient was transformed' % (len([t for t in transformeds if t])/len(transformeds)))\n",
    "    return converts, transformeds\n",
    "\n",
    "converts, transformeds = conversion_rate(dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pasta salad',\n",
       " 'cheeses',\n",
       " '7up',\n",
       " 'sub',\n",
       " 'arame',\n",
       " 'chile con queso',\n",
       " 'lovage',\n",
       " 'minute maid',\n",
       " 'brinjal',\n",
       " 'sugars',\n",
       " 'jujube',\n",
       " 'swiss miss',\n",
       " 'delmonico steak',\n",
       " 'elephant garlic',\n",
       " 'loquats',\n",
       " 'ibarra',\n",
       " 'maize',\n",
       " 'flap steak',\n",
       " 'nacho',\n",
       " 'puffed rice',\n",
       " 'gelato',\n",
       " 'ostrich',\n",
       " 'sangria',\n",
       " 'mochi',\n",
       " 'fish paste',\n",
       " 'marlin',\n",
       " 'leches',\n",
       " 'maitake mushroom',\n",
       " 'raisin',\n",
       " 'banana ketchup',\n",
       " 'celtuce',\n",
       " 'mutton',\n",
       " 'blueberry jam',\n",
       " 'jasmine tea',\n",
       " 'herbal tea',\n",
       " 'capellini',\n",
       " 'tia maria',\n",
       " 'ti',\n",
       " 'sandwiches',\n",
       " 'pomelo',\n",
       " 'shichimi',\n",
       " 'panch phoron',\n",
       " 'lotus root',\n",
       " 'lapsang souchong',\n",
       " 'pomegranates',\n",
       " 'mojito',\n",
       " 'clam sauce',\n",
       " 'poke',\n",
       " 'boysenberry',\n",
       " 'white tea',\n",
       " 'horned melon',\n",
       " 'curry leaf tree',\n",
       " 'curry leaf',\n",
       " 'chips & salsa',\n",
       " 'abalone',\n",
       " 'shark',\n",
       " 'rice bran oil',\n",
       " 'pheasants',\n",
       " 'chive',\n",
       " 'remoulade',\n",
       " 'pepsi cola',\n",
       " 'sassafras',\n",
       " 'soybean',\n",
       " 'blade steak',\n",
       " 'risotto',\n",
       " 'guavas',\n",
       " 'special k',\n",
       " 'grouse',\n",
       " 'royal crown cherry',\n",
       " 'royal crown cola',\n",
       " 'chimichurri',\n",
       " 'pollock',\n",
       " 'ouzo',\n",
       " 'nesquik',\n",
       " 'galliano',\n",
       " 'squirt',\n",
       " 'disaronno',\n",
       " 'grapefruits',\n",
       " 'kiwifruits',\n",
       " 'macchiato',\n",
       " 'mustard oil',\n",
       " 'cheese puffs',\n",
       " 'yoghurt',\n",
       " 'folgers',\n",
       " 'cocktails',\n",
       " 'mezcal',\n",
       " 'mitsuba',\n",
       " 'kinako',\n",
       " 'crunk energy drink',\n",
       " 'bomb energy drink',\n",
       " 'xs energy drink',\n",
       " 'euro shopper energy drink',\n",
       " 'rockstar energy drink',\n",
       " 'energy drink',\n",
       " 'red bull',\n",
       " 'cherry 7up',\n",
       " 'squashes',\n",
       " 'pinot noir',\n",
       " 'banana chips',\n",
       " 'mongongo nut oil',\n",
       " 'macadamia oil',\n",
       " 'lemon verbena',\n",
       " 'fruits',\n",
       " 'cantaloupes',\n",
       " 'laver',\n",
       " 'lingonberry',\n",
       " 'herbsaint',\n",
       " 'sambuca',\n",
       " 'quark',\n",
       " 'farl',\n",
       " 'porridge',\n",
       " 'diet cola',\n",
       " 'pho',\n",
       " 'crepe',\n",
       " 'gai lan',\n",
       " 'culantro',\n",
       " 'drambuie',\n",
       " 'mulling spices',\n",
       " 'sloe gin',\n",
       " 'margaritas',\n",
       " 'arrack',\n",
       " 'scallop',\n",
       " 'moscow mule',\n",
       " 'semifreddo',\n",
       " 'pineapples',\n",
       " 'chicory',\n",
       " 'donuts',\n",
       " 'jujubes',\n",
       " 'latte',\n",
       " 'xo sauce',\n",
       " 'candlenuts',\n",
       " 'enchiladas',\n",
       " 'arepas',\n",
       " 'arepa',\n",
       " 'potato onion',\n",
       " 'papayas',\n",
       " 'chayotes',\n",
       " 'midori',\n",
       " 'garlic chives',\n",
       " 'boysenberries',\n",
       " 'cardoon',\n",
       " 'lambs',\n",
       " 'conchiglie',\n",
       " 'country time',\n",
       " 'coconut juice',\n",
       " 'paratha',\n",
       " 'pitaya',\n",
       " 'dulse',\n",
       " 'corn salsa',\n",
       " 'spinach beet',\n",
       " 'borage',\n",
       " 'winter melon',\n",
       " 'bao',\n",
       " 'farinata',\n",
       " 'corn salad',\n",
       " 'tamales',\n",
       " 'soju',\n",
       " 'artichoke dip',\n",
       " 'swede',\n",
       " 'whisky',\n",
       " 'carambola',\n",
       " 'meats',\n",
       " 'cured meats',\n",
       " 'thai tea',\n",
       " 'carp',\n",
       " 'tamale',\n",
       " 'sauces',\n",
       " 'watermelons',\n",
       " 'pastina',\n",
       " 'lemon drink',\n",
       " 'perch',\n",
       " 'jim beam',\n",
       " 'squash blossoms',\n",
       " 'irish coffee',\n",
       " 'amaro',\n",
       " 'serviceberries',\n",
       " 'ajvar',\n",
       " 'yu choy',\n",
       " 'curly fries',\n",
       " 'hazelnut oil',\n",
       " 'angelica',\n",
       " 'rose hip',\n",
       " 'strawberry juice',\n",
       " 'chrysanthemum',\n",
       " 'peanut milk',\n",
       " 'sunkist',\n",
       " 'rice water',\n",
       " 'french 75',\n",
       " 'paella',\n",
       " 'fonio',\n",
       " 'drumstick',\n",
       " 'soppressata',\n",
       " 'ajwain',\n",
       " 'omelet',\n",
       " 'muesli',\n",
       " 'soymilk',\n",
       " 'crabapples',\n",
       " 'lorraine',\n",
       " 'quince',\n",
       " 'armagnac',\n",
       " 'amchoor',\n",
       " 'lingonberries',\n",
       " 'dosas',\n",
       " 'rock and rye',\n",
       " 'nutmegs',\n",
       " 'bannock',\n",
       " 'shiso',\n",
       " 'pistachio oil',\n",
       " 'lobster mushroom',\n",
       " 'fiori',\n",
       " 'camphor',\n",
       " 'confectioners',\n",
       " 'beers',\n",
       " 'biryani',\n",
       " 'wontons',\n",
       " 'endives',\n",
       " 'biga',\n",
       " 'abuelita',\n",
       " 'mini wheats',\n",
       " 'dewberries',\n",
       " 'cherry heering',\n",
       " 'martini',\n",
       " 'turkeys',\n",
       " 'meatball',\n",
       " 'irish mist',\n",
       " 'macaroni salad',\n",
       " 'luffa',\n",
       " 'durian',\n",
       " 'poppyseed oil',\n",
       " 'salmonberries',\n",
       " 'cassia',\n",
       " 'cavatelli',\n",
       " 'fizz',\n",
       " 'new zealand spinach',\n",
       " 'cashewmilk',\n",
       " 'bitter gourd',\n",
       " 'hashbrown',\n",
       " 'kettle chips',\n",
       " 'wieners',\n",
       " 'kalonji',\n",
       " 'milks',\n",
       " 'rabbits',\n",
       " 'ssamjang',\n",
       " 'lettuces',\n",
       " 'croquettes',\n",
       " 'sweet lemon',\n",
       " 'protein bar',\n",
       " 'courgette',\n",
       " 'perilla',\n",
       " 'snickers',\n",
       " 'donut',\n",
       " 'tigernut',\n",
       " 'cress',\n",
       " 'tare sauce',\n",
       " 'soursop',\n",
       " 'dried lime',\n",
       " 'fiddleheads',\n",
       " 'hp sauce',\n",
       " 'latik',\n",
       " 'coors',\n",
       " 'chartreuse',\n",
       " 'sapodilla',\n",
       " 'perrier',\n",
       " 'campanelle',\n",
       " 'sweet tea',\n",
       " 'jeremiah weed',\n",
       " 'jellyfish',\n",
       " 'potato salad',\n",
       " 'marie rose sauce',\n",
       " 'hawaij',\n",
       " 'lychee',\n",
       " 'coke',\n",
       " 'puffed grain',\n",
       " 'yardlong bean',\n",
       " 'casein',\n",
       " 'prawn',\n",
       " 'mint sauce',\n",
       " 'winged bean',\n",
       " 'horchata',\n",
       " 'carnations',\n",
       " 'raita',\n",
       " 'coconuts',\n",
       " 'shrimps',\n",
       " 'seasonings',\n",
       " 'san pellegrino',\n",
       " 'mangosteen',\n",
       " 'kokum',\n",
       " 'jambalaya',\n",
       " 'loquat',\n",
       " 'bratwursts',\n",
       " 'kangaroo',\n",
       " 'welsh onion',\n",
       " 'scotch fillet',\n",
       " 'eye fillet',\n",
       " 'azuki bean',\n",
       " 'herring',\n",
       " 'puri',\n",
       " 'partridge',\n",
       " 'pumpkins',\n",
       " 'michelada',\n",
       " 'triticale',\n",
       " 'moringa',\n",
       " 'nigella',\n",
       " 'mizuna greens',\n",
       " 'grains of paradise',\n",
       " 'grains of selim',\n",
       " 'pupusa',\n",
       " 'kumquat',\n",
       " 'groundnut',\n",
       " 'pear cider',\n",
       " 'applejack',\n",
       " 'kingfish',\n",
       " 'sour cabbage',\n",
       " 'pineapple jam',\n",
       " 'canada dry',\n",
       " 'holy basil',\n",
       " 'hawaiian punch',\n",
       " 'boudin',\n",
       " 'eel',\n",
       " 'huckleberry',\n",
       " 'hashbrowns',\n",
       " 'pacific saury',\n",
       " 'guava juice',\n",
       " 'calamansis',\n",
       " 'omelets',\n",
       " 'blue moon']"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 159 ms\n"
     ]
    }
   ],
   "source": [
    "# count the occurrences of ingr indentified by salvador\n",
    "count =  dict(Counter([t for tr in transformeds if tr for t in tr]))\n",
    "rare = [k for k, v in count.items() if v < 5]\n",
    "rare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
