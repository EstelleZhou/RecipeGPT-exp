{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 6.44 Âµs\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "%load_ext autotime\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "# if cannot import the modules, add the parent directory to system path might help\n",
    "\n",
    "import os, tqdm, sys\n",
    "parent_dir = os.path.abspath(os.getcwd()+'/..')+'/'\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "from utils.path import dir_HugeFiles\n",
    "from utils.preprocessing import load\n",
    "from utils.words import make_corpus_0, get_wordcount_list\n",
    "from utils.save import make_dir, save_pickle, load_pickle, auto_save_csv, print_time\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import inflect\n",
    "from collections import Counter\n",
    "\n",
    "#dir_save = os.path.normpath(dir_HugeFiles+'dph/dic_20190607.pickle')\n",
    "#dic = load(dir_save)\n",
    "random_seed = 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exist\n",
      "drop 46 recipes with less than 2 ingredients\n",
      "furthur drop 1026 recipes with less than 2 instructions\n",
      "drop 0 recipes with no description\n",
      "now we are using recipe54k 54076\n",
      "time: 3.79 s\n"
     ]
    }
   ],
   "source": [
    "dic = load(dir_save = '../big_data/dic_20190830.pickle')\n",
    "ls = [i for i,v in dic.items() if len(v['ingredients'])>1]\n",
    "print('drop %d recipes with less than 2 ingredients' %(len(dic)-len(ls)))\n",
    "ls = [i for i in ls if len(dic[i]['directions'])>1]\n",
    "print('furthur drop %d recipes with less than 2 instructions' %(len(dic)-len(ls)))\n",
    "desc = [i for i in ls if len(dic[i]['description'])<1]\n",
    "print('drop %d recipes with no description' %(len(desc)))\n",
    "print('now we are using recipe54k %d' % len(ls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 42.9 ms\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(dir_HugeFiles+'raw_data/food_taxonomy.txt',delimiter='\\t', header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "origin: length of data: 4294\n",
      "drop some fields: length of data: 2682\n",
      "drop duplicates: length of data: 2582\n",
      "time: 1.69 s\n"
     ]
    }
   ],
   "source": [
    "def cleaning(df):\n",
    "    '''\n",
    "    eliminate the row if it contains the following non-ingredient words\n",
    "    '''\n",
    "    print('origin: length of data: %d' % len(df))\n",
    "    eliminate = ['Snack brand', 'Preparation', 'Fast food', 'Dietary Supplement', 'Dessert']\n",
    "    for i in range(2):\n",
    "        df  = df[df.apply(lambda x: x[i] not in eliminate, axis = 1)]\n",
    "    # uncased\n",
    "    for i in range(3):\n",
    "        df[i]  = df.apply(lambda x: x[i].lower(), axis = 1)\n",
    "    print('drop some fields: length of data: %d' % len(df))    \n",
    "    \n",
    "    # drop the duplicates\n",
    "    df = df[~df[2].duplicated()]\n",
    "    df = df.reset_index(drop = True)\n",
    "    print('drop duplicates: length of data: %d' % len(df))\n",
    "        \n",
    "    return df\n",
    "df = cleaning(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bean and legume' 'beverage' 'breakfast cereal' 'condiment'\n",
      " 'egg and dairy' 'fruit' 'herb and spice' 'meat' 'mushroom' 'nut and seed'\n",
      " 'side dish' 'snack' 'staple' 'vegetable']\n",
      "['legume' 'soy product' 'alcohol' 'chocolate' 'coffee' 'energy drink'\n",
      " 'fruit juice' 'hot beverage' 'lemon beverage' 'milk substitutes'\n",
      " 'rice beverage' 'soft drink' 'breakfast cereal' 'condiment'\n",
      " 'dairy product' 'egg' 'berry' 'mediterranean' 'temperate' 'tropical'\n",
      " 'herbs' 'mixtures' 'peppers' 'spices' 'beef' 'fish' 'game' 'lamb' 'meat'\n",
      " 'meatball' 'pork' 'poultry' 'sausage' 'seafood' 'shellfish' 'mushroom'\n",
      " 'gymnosperm seed' 'nut' 'other' 'pseudocereal' 'antipasto' 'fries'\n",
      " 'legumes' 'maize' 'pasta' 'potatoes' 'salad' 'soup' 'snack' 'banana'\n",
      " 'other cereal' 'rice' 'root and tuber' 'wheat' 'bulb and stem vegetables'\n",
      " 'flowers and flower buds' 'fruits' 'leafy and salad' 'podded vegetables'\n",
      " 'root and tuberous vegetables' 'sea vegetables' 'vegetables']\n",
      "['bean' 'chickpea' 'cowpea' ... 'vegetables' 'vegetarian' 'veggie']\n",
      "time: 33.6 ms\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    print(df[i].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 32.8 ms\n"
     ]
    }
   ],
   "source": [
    "p = inflect.engine()\n",
    "class closest:\n",
    "    def __init__(self, series):\n",
    "        find_ngram = series.apply(lambda x: ' ' in x)\n",
    "        self.unigram_ingredients, self.ngram_ingredients = series[~find_ngram], series[find_ngram]\n",
    "        # self.unigram_ingredients_pluraled = [p.plural(ingr) for ingr in self.unigram_ingredients]\n",
    "    \n",
    "    def ngram(self, listofline, pluraled_listofline):\n",
    "        answer = []\n",
    "        for ngram in self.ngram_ingredients.values:\n",
    "            n_list= ngram.split(' ')\n",
    "            intersection = set(listofline) & set(n_list)\n",
    "            if len(intersection) >= 2 and len(intersection) == len(n_list):\n",
    "                answer.append(ngram)\n",
    "            else:\n",
    "                # repeat\n",
    "                intersection = (set(pluraled_listofline) | set(intersection)) & set(n_list)\n",
    "                if len(intersection) >= 2 and len(intersection) == len(n_list):\n",
    "                    answer.append(ngram)\n",
    "        return set(answer)\n",
    "    \n",
    "    def unigram(self, listofline, pluraled_listofline):\n",
    "        first =  set(listofline) & set(self.unigram_ingredients)\n",
    "        if first:\n",
    "            return first\n",
    "        second = set(pluraled_listofline) & set(self.unigram_ingredients)\n",
    "        if second:\n",
    "            return second\n",
    "        \n",
    "    def check(self, listofline):\n",
    "        '''\n",
    "        assign higher priority to n-grams over uni-gram\n",
    "        '''\n",
    "        pluraled_listofline = [p.plural(word) for word in listofline]\n",
    "        ngram = self.ngram(listofline, pluraled_listofline)\n",
    "        if ngram:\n",
    "            return ngram\n",
    "        unigram = self.unigram(listofline, pluraled_listofline)\n",
    "        if unigram:\n",
    "            return unigram\n",
    "        \n",
    "    def equal_check(self, listofline):\n",
    "        '''\n",
    "        equally care about unigram and n gram\n",
    "        '''\n",
    "        pluraled_listofline = [p.plural(word) for word in listofline]\n",
    "        ngram = self.ngram(listofline, pluraled_listofline)\n",
    "        unigram = self.unigram(listofline, pluraled_listofline)\n",
    "        if ngram and unigram:\n",
    "            return ngram | unigram\n",
    "        if ngram:\n",
    "            return ngram\n",
    "        if unigram:\n",
    "            return unigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before processing: length of data: 2582\n",
      "add some rows: length of data: 2685\n",
      "drop duplicates: length of data: 2684\n",
      "time: 758 ms\n"
     ]
    }
   ],
   "source": [
    "# firstly, we notice salvador identified several useful ingredients that are not found in our taxnomy\n",
    "# then, we selected those words based on frequency and manually add words to our taxnomy\n",
    "additional_ingr=\\\n",
    "[\n",
    "['Condiment', 'Sweet', 'sugar'],\n",
    "['Condiment', 'Sweet', 'applesauce'],\n",
    "['Flour', 'Flour','flour'],\n",
    "['Baking powder','Baking powder','baking powder'],\n",
    "['Water','Water','water'],\n",
    "['Water','Water','iced'],\n",
    "['Water','Water','ice'],\n",
    "['Herb and spice','spices','jalapeno'],\n",
    "['Condiment','Condiment', 'oil'],\n",
    "['Beverage','Fruit juice', 'juice'],\n",
    "['Staple','Maize','enchilada'],\n",
    "['Condiment','Condiment', 'dressing mix'],\n",
    "['Condiment','Condiment', 'cheese mix'],\n",
    "['Baking powder','Baking powder','baking soda'],\n",
    "['Condiment','Condiment', 'dry mix'],\n",
    "['Condiment','Condiment','chocolate'],\n",
    "['Vegetable','Bulb and stem vegetables','tapioca'],\n",
    "['Flour', 'Flour','xanthan gum'],\n",
    "['Flour', 'Flour','starch'],\n",
    "['Egg and dairy', 'Dairy product','buttermilk'],\n",
    "['Condiment','Condiment','chili'],\n",
    "['Condiment','Condiment','chile'],\n",
    "['Condiment','Condiment','chilis'],\n",
    "['Condiment','Condiment','chiles'],\n",
    "['Condiment','Condiment','chilies'],\n",
    "['Flour', 'Flour','corn muffin mix'],\n",
    "['Beverage','Chocolate','chocolate mix'],\n",
    "['Meat','dumpling','dumpling'],\n",
    "['Meat','dumpling','wonton'],\n",
    "['Staple','Wheat','pizza dough'],\n",
    "['Staple','Wheat','dough'],\n",
    "['Condiment','Condiment', 'pizza sauce'],\n",
    "['Flour', 'Flour','yeast'],\n",
    "['Condiment','Sweet','cocoa'],\n",
    "['Staple','Maize','chip'],\n",
    "['Egg and dairy','Dairy product','ricotta'],\n",
    "['Condiment','Condiment','seasoning'],\n",
    "['Beverage','Alcohol','sherry'],\n",
    "['Staple','Rice','grain rice'], \n",
    "['Staple','Wheat','shell'],\n",
    "['Meat','Beef','fillet'],\n",
    "['Staple','Maize','cornmeal'],\n",
    "['Condiment','Condiment','seed oil'],\n",
    "['Nut and seed','Other','seed'],\n",
    "['Condiment', 'Sweet', 'sugar blend'],\n",
    "['Soup','Soup','broth'],\n",
    "['Soup','Soup','stock'],\n",
    "['Condiment', 'Sweet', 'marshmallow'],\n",
    "['Condiment', 'Dry Condiment', 'dried vegetable flakes'],\n",
    "['Condiment', 'Dry Condiment', 'dried celery flakes'],\n",
    "['Flour', 'Flour','cornstarch'],\n",
    "['Staple','Wheat','double crust'],\n",
    "['Staple','Wheat','crust'],\n",
    "['Staple','Wheat','pastry crust'],\n",
    "['Egg and dairy','Dairy product','gorgonzola'],\n",
    "['Beverage','juice','drink mix'],\n",
    "['Egg and dairy','Egg','Egg whites'],\n",
    "['Baking powder','Baking powder','baking mix'],\n",
    "['Staple','Rice','brown rice'],\n",
    "['Condiment','Condiment','five spice'],\n",
    "['Meat','Beef','tenderloin'],\n",
    "['Meat','Pork','prosciutto'],\n",
    "['Condiment', 'Sweet', 'whipped topping'],\n",
    "['Condiment', 'Sweet', 'topping'],\n",
    "['Beverage','Alcohol','cider'],\n",
    "['Meat','Shellfish','crabmeat'],\n",
    "['Condiment', 'Sweet', 'candy'],\n",
    "['Condiment', 'Sweet', 'caramel'],\n",
    "['Condiment', 'Sweet', 'molasses'],\n",
    "['Vegetable','Podded vegetables','cannellini'],\n",
    "['Vegetable','Fruits','fruit'],\n",
    "['Staple','Wheat','saltine'],\n",
    "['Condiment','Condiment', 'habanero'],\n",
    "['Beverage','Juice','jell o'],\n",
    "['Beverage','Juice','jelly'],\n",
    "['Beverage','Soft drink','carbonated beverage'],\n",
    "['Egg and dairy','Dairy product','gruyere'],\n",
    "['Vegetable','Leafy and Salad','beet'],\n",
    "['Water','Water','icing'],\n",
    "['Egg and dairy','Dairy product','parmigiano'],\n",
    "['Beverage','Alcohol','liqueur'],\n",
    "['Condiment','Condiment', 'lard'],\n",
    "['Staple','Wheat','crumb'],\n",
    "['Herb and spice','Herb','peppermint'],\n",
    "['Beverage','Alcohol','marsala'],\n",
    "['Side dish','Potatoes','hash brown'],\n",
    "['Meat','Beef','steak'],\n",
    "['Condiment','Condiment','gelatin'],\n",
    "['Meat','Beef','chuck'],\n",
    "['Egg and dairy','Dairy product','colby'],\n",
    "['Condiment', 'Sweet', 'jam'],\n",
    "['Condiment', 'Sweet', 'cool whip'],\n",
    "['Condiment', 'Sweet', 'stevia'],\n",
    "['Staple','Wheat','bran'],\n",
    "['Condiment','Condiment','pimento'],\n",
    "['Condiment','Condiment','food coloring'],\n",
    "['Meat','Meat','rib'],\n",
    "['Condiment','Condiment','shortening'],\n",
    "['Vegetable','Fruits','sweet pickles'],\n",
    "['Condiment', 'Sweet', 'white confectioner'],\n",
    "['Condiment', 'Sweet', 'confectioner'],  \n",
    "['Vegetable','Root and tuberous vegetabless','rhubarb'],\n",
    "['Condiment', 'Condiment', 'cooking spray']\n",
    "]\n",
    "\n",
    "def add_rows(df, additional_ingr):\n",
    "    add = pd.DataFrame(additional_ingr)\n",
    "    print('before processing: length of data: %d' % len(df))\n",
    "    df = pd.concat([df,add]).reset_index(drop =True)\n",
    "\n",
    "    # uncased\n",
    "    for i in range(3):\n",
    "        df[i]  = df.apply(lambda x: x[i].lower().strip(), axis = 1)\n",
    "    print('add some rows: length of data: %d' % len(df))    \n",
    "    \n",
    "    # drop the duplicates\n",
    "    df = df[~df[2].duplicated()]\n",
    "    df = df.reset_index(drop = True)\n",
    "    print('drop duplicates: length of data: %d' % len(df))\n",
    "    return df\n",
    "\n",
    "df = add_rows(df, additional_ingr)\n",
    "\n",
    "\n",
    "unwelcomed_ingr =['salt and pepper', 'muffin']\n",
    "def delete_rows(df, unwelcomed_ingr):\n",
    "    return df[df[2].apply(lambda x: x not in unwelcomed_ingr)]\n",
    "\n",
    "df = delete_rows(df, unwelcomed_ingr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 29.6 ms\n"
     ]
    }
   ],
   "source": [
    "class closest_lighter(closest):\n",
    "    def __init__(self, set_grams):\n",
    "        self.unigram_ingredients = pd.Series([x for x in set_grams if ' ' not in x])\n",
    "        self.ngram_ingredients = pd.Series([x for x in set_grams if ' ' in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 35.8 ms\n"
     ]
    }
   ],
   "source": [
    "# prepare the ingredient detection algorithm\n",
    "model = closest(df[2])\n",
    "def multiframe_recall(ingred_level2, directions):\n",
    "    '''\n",
    "    ingred_level2: dic[i]['ingred_level2']; list of set; ground truth;\n",
    "    directions: dic[i]['directions']; list of words; prediciton\n",
    "    denominator: number of identified n-grams\n",
    "    '''\n",
    "    try:\n",
    "        # recall \n",
    "        true_flatten = set.union(*[line for line in ingred_level2 if line])\n",
    "        model_lighter = closest_lighter(true_flatten)\n",
    "        direct_level2 = [model_lighter.equal_check(instr) for instr in directions]\n",
    "        pred_flatten = set.union(*[line for line in direct_level2 if line])\n",
    "        true_positive = true_flatten & pred_flatten\n",
    "\n",
    "        recall = len(true_positive)/len(true_flatten)\n",
    "        #precision = len(true_positive)/len(pred_flatten)\n",
    "        #f1 = 2* recall * precision / (recall + precision)\n",
    "        return recall #, precision, f1\n",
    "    except TypeError:\n",
    "        return 0\n",
    "    \n",
    "\n",
    "def anymatched_recall(ingred_level2, directions):\n",
    "    '''\n",
    "    ingred_level2: dic[i]['ingred_level2']; list of set; ground truth;\n",
    "    directions: dic[i]['directions']; list of words; prediciton\n",
    "    denominator: number of ingredients\n",
    "    '''\n",
    "    try:\n",
    "        # recall \n",
    "        true_flatten = set.union(*[line for line in ingred_level2 if line])\n",
    "        model_lighter = closest_lighter(true_flatten)\n",
    "        direct_level2 = [model_lighter.equal_check(instr) for instr in directions]\n",
    "        pred_flatten = set.union(*[line for line in direct_level2 if line])\n",
    "        true_positive = true_flatten & pred_flatten\n",
    "\n",
    "        recall = len(true_positive)/len(true_flatten)\n",
    "        return np.mean([1 if line & true_positive else 0 for line in ingred_level2 if line])\n",
    "    except TypeError:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 118 ms\n"
     ]
    }
   ],
   "source": [
    "filename = '../../to_gpt2/generation_1221k_top0.95_new/'\n",
    "def load_dir_data(filename):\n",
    "    ls = []\n",
    "    if os.path.isdir(filename):\n",
    "        # Directory\n",
    "        for (dirpath, _, fnames) in os.walk(filename):\n",
    "            for fname in fnames:\n",
    "                path = os.path.join(dirpath, fname)\n",
    "                with open(path, 'r') as fp:\n",
    "                    raw_text = fp.read()\n",
    "                # if it contain instr\n",
    "                if fname[-5] == 'd':\n",
    "                    dic[int(fname[:-5])]['generated_instr'] = [raw_text]\n",
    "                # if it contain ingred\n",
    "                if fname[-5] == 'i':\n",
    "                    dic[int(fname[:-5])]['generated_ingred'] = raw_text.split('$')\n",
    "                # if it contain name\n",
    "                if fname[-5] == 'n':\n",
    "                    dic[int(fname[:-5])]['generated_name'] = raw_text\n",
    "                ls.append(int(fname[:-5]))\n",
    "    return sorted(list(set(ls)))\n",
    "ls = load_dir_data(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### example: model 1221k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 135 ms\n"
     ]
    }
   ],
   "source": [
    "filename = '../../to_gpt2/generation_1221k_top0.95_new/'\n",
    "ls = load_dir_data(filename)\n",
    "assert ls != []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|ââââââââââ| 55102/55102 [01:15<00:00, 727.87it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "anymatched_recall       0.910873\n",
       "multiframe_recall       0.850025\n",
       "multiframe_precision    0.841702\n",
       "dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1min 19s\n"
     ]
    }
   ],
   "source": [
    "# ground truth instruction\n",
    "for i, v in tqdm.tqdm(dic.items()):\n",
    "    if i in ls:\n",
    "        ingredients = [sent.split(' ') for sent in v['ingredients']]\n",
    "        dic[i]['ingred_level2'] = [model.equal_check(ingred) for ingred in ingredients]\n",
    "        generated_ingredients = [sent.split(' ') for sent in v['directions']]\n",
    "        dic[i]['generated_ingredients_level2'] = [model.equal_check(instr) for instr in generated_ingredients]\n",
    "        dic[i]['anymatched_recall'] = anymatched_recall(dic[i]['ingred_level2'], generated_ingredients)\n",
    "        dic[i]['multiframe_recall'] = multiframe_recall(dic[i]['ingred_level2'], generated_ingredients)\n",
    "        dic[i]['multiframe_precision'] = multiframe_recall(dic[i]['generated_ingredients_level2'], ingredients)\n",
    "df1 = pd.DataFrame.from_dict(dic, orient = 'index')\n",
    "df1[['anymatched_recall','multiframe_recall','multiframe_precision']].iloc[ls].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|ââââââââââ| 55102/55102 [00:38<00:00, 1447.78it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "anymatched_recall       0.817189\n",
       "multiframe_recall       0.754704\n",
       "multiframe_precision    0.775266\n",
       "dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 40.7 s\n"
     ]
    }
   ],
   "source": [
    "# ingredients\n",
    "for i, v in tqdm.tqdm(dic.items()):\n",
    "    if i in ls:\n",
    "        ingredients = [sent.split(' ') for sent in v['ingredients']]\n",
    "        dic[i]['ingred_level2'] = [model.equal_check(ingred) for ingred in ingredients]\n",
    "        generated_ingredients = [sent.split(' ') for sent in v['generated_ingred']]\n",
    "        \n",
    "        dic[i]['generated_ingredients_level2'] = [model.equal_check(instr) for instr in generated_ingredients]\n",
    "        dic[i]['anymatched_recall'] = anymatched_recall(dic[i]['ingred_level2'], generated_ingredients)\n",
    "        dic[i]['multiframe_recall'] = multiframe_recall(dic[i]['ingred_level2'], generated_ingredients)\n",
    "        dic[i]['multiframe_precision'] = multiframe_recall(dic[i]['generated_ingredients_level2'], ingredients)\n",
    "        \n",
    "df2 = pd.DataFrame.from_dict(dic, orient = 'index')\n",
    "df2[['anymatched_recall','multiframe_recall','multiframe_precision']].iloc[ls].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|ââââââââââ| 55102/55102 [00:33<00:00, 1629.92it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "anymatched_recall       0.803427\n",
       "multiframe_recall       0.748915\n",
       "multiframe_precision    0.711824\n",
       "dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 36.4 s\n"
     ]
    }
   ],
   "source": [
    "# instructions\n",
    "for i, v in tqdm.tqdm(dic.items()):\n",
    "    if i in ls:\n",
    "        ingredients = [sent.split(' ') for sent in v['ingredients']]\n",
    "        dic[i]['ingred_level2'] = [model.equal_check(ingred) for ingred in ingredients]\n",
    "        generated_ingredients = [sent.split(' ') for sent in v['generated_instr']]\n",
    "        \n",
    "        dic[i]['generated_ingredients_level2'] = [model.equal_check(instr) for instr in generated_ingredients]\n",
    "        dic[i]['anymatched_recall'] = anymatched_recall(dic[i]['ingred_level2'], generated_ingredients)\n",
    "        dic[i]['multiframe_recall'] = multiframe_recall(dic[i]['ingred_level2'], generated_ingredients)\n",
    "        dic[i]['multiframe_precision'] = multiframe_recall(dic[i]['generated_ingredients_level2'], ingredients)\n",
    "        \n",
    "df2 = pd.DataFrame.from_dict(dic, orient = 'index')\n",
    "df2[['anymatched_recall','multiframe_recall','multiframe_precision']].iloc[ls].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 114 ms\n"
     ]
    }
   ],
   "source": [
    "filename = '../../to_gpt2/generation_1221k_topk/'\n",
    "ls = load_dir_data(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|ââââââââââ| 55102/55102 [00:39<00:00, 1404.96it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "anymatched_recall       0.844249\n",
       "multiframe_recall       0.791609\n",
       "multiframe_precision    0.757536\n",
       "dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 41.6 s\n"
     ]
    }
   ],
   "source": [
    "# ingredients\n",
    "for i, v in tqdm.tqdm(dic.items()):\n",
    "    if i in ls:\n",
    "        ingredients = [sent.split(' ') for sent in v['ingredients']]\n",
    "        dic[i]['ingred_level2'] = [model.equal_check(ingred) for ingred in ingredients]\n",
    "        generated_ingredients = [sent.split(' ') for sent in v['generated_ingred']]\n",
    "        \n",
    "        dic[i]['generated_ingredients_level2'] = [model.equal_check(instr) for instr in generated_ingredients]\n",
    "        dic[i]['anymatched_recall'] = anymatched_recall(dic[i]['ingred_level2'], generated_ingredients)\n",
    "        dic[i]['multiframe_recall'] = multiframe_recall(dic[i]['ingred_level2'], generated_ingredients)\n",
    "        dic[i]['multiframe_precision'] = multiframe_recall(dic[i]['generated_ingredients_level2'], ingredients)\n",
    "        \n",
    "df2 = pd.DataFrame.from_dict(dic, orient = 'index')\n",
    "df2[['anymatched_recall','multiframe_recall','multiframe_precision']].iloc[ls].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|ââââââââââ| 55102/55102 [00:31<00:00, 1732.96it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "anymatched_recall       0.813550\n",
       "multiframe_recall       0.761658\n",
       "multiframe_precision    0.769062\n",
       "dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 34.2 s\n"
     ]
    }
   ],
   "source": [
    "# instructions\n",
    "for i, v in tqdm.tqdm(dic.items()):\n",
    "    if i in ls:\n",
    "        ingredients = [sent.split(' ') for sent in v['ingredients']]\n",
    "        dic[i]['ingred_level2'] = [model.equal_check(ingred) for ingred in ingredients]\n",
    "        generated_ingredients = [sent.split(' ') for sent in v['generated_instr']]\n",
    "        \n",
    "        dic[i]['generated_ingredients_level2'] = [model.equal_check(instr) for instr in generated_ingredients]\n",
    "        dic[i]['anymatched_recall'] = anymatched_recall(dic[i]['ingred_level2'], generated_ingredients)\n",
    "        dic[i]['multiframe_recall'] = multiframe_recall(dic[i]['ingred_level2'], generated_ingredients)\n",
    "        dic[i]['multiframe_precision'] = multiframe_recall(dic[i]['generated_ingredients_level2'], ingredients)\n",
    "        \n",
    "df2 = pd.DataFrame.from_dict(dic, orient = 'index')\n",
    "df2[['anymatched_recall','multiframe_recall','multiframe_precision']].iloc[ls].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
