{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 7.87 Âµs\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "%load_ext autotime\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "# if cannot import the modules, add the parent directory to system path might help\n",
    "\n",
    "import os\n",
    "import sys\n",
    "parent_dir = os.path.abspath(os.getcwd()+'/..')+'/'\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "\n",
    "import os\n",
    "from utils.path import dir_HugeFiles\n",
    "from utils.preprocessing import load\n",
    "from utils.words import make_corpus_0, get_wordcount_list\n",
    "from utils.save import make_dir, save_pickle, load_pickle, auto_save_csv, print_time\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import inflect\n",
    "from collections import Counter\n",
    "\n",
    "#dir_save = os.path.normpath(dir_HugeFiles+'dph/dic_20190607.pickle')\n",
    "#dic = load(dir_save)\n",
    "random_seed = 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exist\n",
      "drop 46 recipes with less than 2 ingredients\n",
      "furthur drop 1026 recipes with less than 2 instructions\n",
      "drop 0 recipes with no description\n",
      "now we are using recipe54k 54076\n",
      "time: 2.29 s\n"
     ]
    }
   ],
   "source": [
    "dic = load(dir_save = '../big_data/dic_20190830.pickle')\n",
    "ls = [i for i,v in dic.items() if len(v['ingredients'])>1]\n",
    "print('drop %d recipes with less than 2 ingredients' %(len(dic)-len(ls)))\n",
    "ls = [i for i in ls if len(dic[i]['directions'])>1]\n",
    "print('furthur drop %d recipes with less than 2 instructions' %(len(dic)-len(ls)))\n",
    "desc = [i for i in ls if len(dic[i]['description'])<1]\n",
    "print('drop %d recipes with no description' %(len(desc)))\n",
    "print('now we are using recipe54k %d' % len(ls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/data/yueliu/RecipeAnalytics_201906/'"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 30.8 ms\n"
     ]
    }
   ],
   "source": [
    "dir_HugeFiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 37.1 ms\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../big_data/food_taxonomy.txt',delimiter='\\t', header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "origin: length of data: 4294\n",
      "drop some fields: length of data: 2682\n",
      "drop duplicates: length of data: 2582\n",
      "time: 829 ms\n"
     ]
    }
   ],
   "source": [
    "def cleaning(df):\n",
    "    '''\n",
    "    eliminate the row if it contains the following non-ingredient words\n",
    "    '''\n",
    "    print('origin: length of data: %d' % len(df))\n",
    "    eliminate = ['Snack brand', 'Preparation', 'Fast food', 'Dietary Supplement', 'Dessert']\n",
    "    for i in range(2):\n",
    "        df  = df[df.apply(lambda x: x[i] not in eliminate, axis = 1)]\n",
    "    # uncased\n",
    "    for i in range(3):\n",
    "        df[i]  = df.apply(lambda x: x[i].lower(), axis = 1)\n",
    "    print('drop some fields: length of data: %d' % len(df))    \n",
    "    \n",
    "    # drop the duplicates\n",
    "    df = df[~df[2].duplicated()]\n",
    "    df = df.reset_index(drop = True)\n",
    "    print('drop duplicates: length of data: %d' % len(df))\n",
    "        \n",
    "    return df\n",
    "df = cleaning(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bean and legume' 'beverage' 'breakfast cereal' 'condiment'\n",
      " 'egg and dairy' 'fruit' 'herb and spice' 'meat' 'mushroom' 'nut and seed'\n",
      " 'side dish' 'snack' 'staple' 'vegetable']\n",
      "['legume' 'soy product' 'alcohol' 'chocolate' 'coffee' 'energy drink'\n",
      " 'fruit juice' 'hot beverage' 'lemon beverage' 'milk substitutes'\n",
      " 'rice beverage' 'soft drink' 'breakfast cereal' 'condiment'\n",
      " 'dairy product' 'egg' 'berry' 'mediterranean' 'temperate' 'tropical'\n",
      " 'herbs' 'mixtures' 'peppers' 'spices' 'beef' 'fish' 'game' 'lamb' 'meat'\n",
      " 'meatball' 'pork' 'poultry' 'sausage' 'seafood' 'shellfish' 'mushroom'\n",
      " 'gymnosperm seed' 'nut' 'other' 'pseudocereal' 'antipasto' 'fries'\n",
      " 'legumes' 'maize' 'pasta' 'potatoes' 'salad' 'soup' 'snack' 'banana'\n",
      " 'other cereal' 'rice' 'root and tuber' 'wheat' 'bulb and stem vegetables'\n",
      " 'flowers and flower buds' 'fruits' 'leafy and salad' 'podded vegetables'\n",
      " 'root and tuberous vegetables' 'sea vegetables' 'vegetables']\n",
      "['bean' 'chickpea' 'cowpea' ... 'vegetables' 'vegetarian' 'veggie']\n",
      "time: 19.2 ms\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    print(df[i].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before processing: length of data: 2582\n",
      "add some rows: length of data: 2685\n",
      "drop duplicates: length of data: 2684\n",
      "time: 472 ms\n"
     ]
    }
   ],
   "source": [
    "additional_ingr=\\\n",
    "[\n",
    "['Condiment', 'Sweet', 'sugar'],\n",
    "['Condiment', 'Sweet', 'applesauce'],\n",
    "['Flour', 'Flour','flour'],\n",
    "['Baking powder','Baking powder','baking powder'],\n",
    "['Water','Water','water'],\n",
    "['Water','Water','iced'],\n",
    "['Water','Water','ice'],\n",
    "['Herb and spice','spices','jalapeno'],\n",
    "['Condiment','Condiment', 'oil'],\n",
    "['Beverage','Fruit juice', 'juice'],\n",
    "['Staple','Maize','enchilada'],\n",
    "['Condiment','Condiment', 'dressing mix'],\n",
    "['Condiment','Condiment', 'cheese mix'],\n",
    "['Baking powder','Baking powder','baking soda'],\n",
    "['Condiment','Condiment', 'dry mix'],\n",
    "['Condiment','Condiment','chocolate'],\n",
    "['Vegetable','Bulb and stem vegetables','tapioca'],\n",
    "['Flour', 'Flour','xanthan gum'],\n",
    "['Flour', 'Flour','starch'],\n",
    "['Egg and dairy', 'Dairy product','buttermilk'],\n",
    "['Condiment','Condiment','chili'],\n",
    "['Condiment','Condiment','chile'],\n",
    "['Condiment','Condiment','chilis'],\n",
    "['Condiment','Condiment','chiles'],\n",
    "['Condiment','Condiment','chilies'],\n",
    "['Flour', 'Flour','corn muffin mix'],\n",
    "['Beverage','Chocolate','chocolate mix'],\n",
    "['Meat','dumpling','dumpling'],\n",
    "['Meat','dumpling','wonton'],\n",
    "['Staple','Wheat','pizza dough'],\n",
    "['Staple','Wheat','dough'],\n",
    "['Condiment','Condiment', 'pizza sauce'],\n",
    "['Flour', 'Flour','yeast'],\n",
    "['Condiment','Sweet','cocoa'],\n",
    "['Staple','Maize','chip'],\n",
    "['Egg and dairy','Dairy product','ricotta'],\n",
    "['Condiment','Condiment','seasoning'],\n",
    "['Beverage','Alcohol','sherry'],\n",
    "['Staple','Rice','grain rice'], \n",
    "['Staple','Wheat','shell'],\n",
    "['Meat','Beef','fillet'],\n",
    "['Staple','Maize','cornmeal'],\n",
    "['Condiment','Condiment','seed oil'],\n",
    "['Nut and seed','Other','seed'],\n",
    "['Condiment', 'Sweet', 'sugar blend'],\n",
    "['Soup','Soup','broth'],\n",
    "['Soup','Soup','stock'],\n",
    "['Condiment', 'Sweet', 'marshmallow'],\n",
    "['Condiment', 'Dry Condiment', 'dried vegetable flakes'],\n",
    "['Condiment', 'Dry Condiment', 'dried celery flakes'],\n",
    "['Flour', 'Flour','cornstarch'],\n",
    "['Staple','Wheat','double crust'],\n",
    "['Staple','Wheat','crust'],\n",
    "['Staple','Wheat','pastry crust'],\n",
    "['Egg and dairy','Dairy product','gorgonzola'],\n",
    "['Beverage','juice','drink mix'],\n",
    "['Egg and dairy','Egg','Egg whites'],\n",
    "['Baking powder','Baking powder','baking mix'],\n",
    "['Staple','Rice','brown rice'],\n",
    "['Condiment','Condiment','five spice'],\n",
    "['Meat','Beef','tenderloin'],\n",
    "['Meat','Pork','prosciutto'],\n",
    "['Condiment', 'Sweet', 'whipped topping'],\n",
    "['Condiment', 'Sweet', 'topping'],\n",
    "['Beverage','Alcohol','cider'],\n",
    "['Meat','Shellfish','crabmeat'],\n",
    "['Condiment', 'Sweet', 'candy'],\n",
    "['Condiment', 'Sweet', 'caramel'],\n",
    "['Condiment', 'Sweet', 'molasses'],\n",
    "['Vegetable','Podded vegetables','cannellini'],\n",
    "['Vegetable','Fruits','fruit'],\n",
    "['Staple','Wheat','saltine'],\n",
    "['Condiment','Condiment', 'habanero'],\n",
    "['Beverage','Juice','jell o'],\n",
    "['Beverage','Juice','jelly'],\n",
    "['Beverage','Soft drink','carbonated beverage'],\n",
    "['Egg and dairy','Dairy product','gruyere'],\n",
    "['Vegetable','Leafy and Salad','beet'],\n",
    "['Water','Water','icing'],\n",
    "['Egg and dairy','Dairy product','parmigiano'],\n",
    "['Beverage','Alcohol','liqueur'],\n",
    "['Condiment','Condiment', 'lard'],\n",
    "['Staple','Wheat','crumb'],\n",
    "['Herb and spice','Herb','peppermint'],\n",
    "['Beverage','Alcohol','marsala'],\n",
    "['Side dish','Potatoes','hash brown'],\n",
    "['Meat','Beef','steak'],\n",
    "['Condiment','Condiment','gelatin'],\n",
    "['Meat','Beef','chuck'],\n",
    "['Egg and dairy','Dairy product','colby'],\n",
    "['Condiment', 'Sweet', 'jam'],\n",
    "['Condiment', 'Sweet', 'cool whip'],\n",
    "['Condiment', 'Sweet', 'stevia'],\n",
    "['Staple','Wheat','bran'],\n",
    "['Condiment','Condiment','pimento'],\n",
    "['Condiment','Condiment','food coloring'],\n",
    "['Meat','Meat','rib'],\n",
    "['Condiment','Condiment','shortening'],\n",
    "['Vegetable','Fruits','sweet pickles'],\n",
    "['Condiment', 'Sweet', 'white confectioner'],\n",
    "['Condiment', 'Sweet', 'confectioner'],  \n",
    "['Vegetable','Root and tuberous vegetabless','rhubarb'],\n",
    "['Condiment', 'Condiment', 'cooking spray']\n",
    "]\n",
    "\n",
    "def add_rows(df, additional_ingr):\n",
    "    add = pd.DataFrame(additional_ingr)\n",
    "    print('before processing: length of data: %d' % len(df))\n",
    "    df = pd.concat([df,add]).reset_index(drop =True)\n",
    "\n",
    "    # uncased\n",
    "    for i in range(3):\n",
    "        df[i]  = df.apply(lambda x: x[i].lower().strip(), axis = 1)\n",
    "    print('add some rows: length of data: %d' % len(df))    \n",
    "    \n",
    "    # drop the duplicates\n",
    "    df = df[~df[2].duplicated()]\n",
    "    df = df.reset_index(drop = True)\n",
    "    print('drop duplicates: length of data: %d' % len(df))\n",
    "    return df\n",
    "\n",
    "df = add_rows(df, additional_ingr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bean and legume</td>\n",
       "      <td>legume</td>\n",
       "      <td>bean</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0       1     2\n",
       "0  bean and legume  legume  bean"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 33 ms\n"
     ]
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 35.9 ms\n"
     ]
    }
   ],
   "source": [
    "def exact_match(ny_ingred):\n",
    "    '''\n",
    "    Args: ingred: a str\n",
    "    Return: str: the first exact match or no change\n",
    "    '''\n",
    "    assert type(ny_ingred) == str\n",
    "    phrases_to_sentences = 'Mix the %s and water.'%(ny_ingred)\n",
    "    doc = nlp(phrases_to_sentences)\n",
    "    exact_match, root_match = [],[]\n",
    "    for chunk in doc.noun_chunks:\n",
    "        if chunk.text != 'water':\n",
    "            root_lemma = [token.lemma_ for token in doc if token.text == chunk.root.text][0]\n",
    "            exact_match.append(chunk.lemma_.replace('the ',''))\n",
    "            root_match.append(root_lemma)\n",
    "    if exact_match:\n",
    "        return exact_match[0]\n",
    "    else:\n",
    "        return ny_ingred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 27.5 s\n"
     ]
    }
   ],
   "source": [
    "### add root\n",
    "df[3] = df[2].apply(lambda x: exact_match(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exist\n",
      "drop 46 recipes with less than 2 ingredients\n",
      "furthur drop 1026 recipes with less than 2 instructions\n",
      "drop 0 recipes with no description\n",
      "now we are using recipe54k 54076\n",
      "time: 8.57 s\n"
     ]
    }
   ],
   "source": [
    "dic = load(dir_save = '../big_data/dic_regional_20190925.pickle')\n",
    "\n",
    "ls = [i for i,v in dic.items() if len(v['ingredients'])>1]\n",
    "print('drop %d recipes with less than 2 ingredients' %(len(dic)-len(ls)))\n",
    "ls = [i for i in ls if len(dic[i]['directions'])>1]\n",
    "print('furthur drop %d recipes with less than 2 instructions' %(len(dic)-len(ls)))\n",
    "desc = [i for i in ls if len(dic[i]['description'])<1]\n",
    "print('drop %d recipes with no description' %(len(desc)))\n",
    "print('now we are using recipe54k %d' % len(ls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 916 ms\n"
     ]
    }
   ],
   "source": [
    "### \n",
    "level3 = df.groupby([3])[1].apply(list).index.tolist()\n",
    "gb = df.groupby([3])[1].apply(list)\n",
    "level3_set = [set(ingr.split(' ')) for ingr in level3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 26.2 ms\n"
     ]
    }
   ],
   "source": [
    "import random \n",
    "random.seed(2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.sample(matched, 1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 31.4 ms\n"
     ]
    }
   ],
   "source": [
    "exact = dic[9]['ny_ingredients']['exact']\n",
    "def delexicalized(exact_ingr):\n",
    "    '''\n",
    "    input: dic[9]['ny_ingredients']['exact'][0]\n",
    "    e.g. 'onion'\n",
    "    '''\n",
    "    matched = []\n",
    "    for ingr, ingr_set in zip(level3, level3_set):\n",
    "        if len(ingr_set) == len(ingr_set & set(exact_ingr.split(' '))):\n",
    "            matched += gb[ingr]\n",
    "    if matched:\n",
    "        return '%s#%s' % (random.sample(matched, 1)[0], exact_ingr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['poultry#turkey',\n",
       " 'bulb and stem vegetables#celery',\n",
       " 'bulb and stem vegetables#onion',\n",
       " 'tropical#pecan',\n",
       " 'condiment#salt',\n",
       " 'condiment#mayonnaise',\n",
       " 'mediterranean#lemon juice',\n",
       " 'dairy product#cheddar cheese',\n",
       " 'maize#potato chip']"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 44.3 ms\n"
     ]
    }
   ],
   "source": [
    "[delexicalized(x) for x in dic[9]['ny_ingredients']['exact']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 29.3 ms\n"
     ]
    }
   ],
   "source": [
    "def delexicalized_sent(sent):\n",
    "    '''\n",
    "    For example\n",
    "    sent = 'Mix the porks, chicken, white sugar with the grain rice in a pot.'\n",
    "    delexicalized_sent(sent) = \n",
    "    'Mix the pork#pork, poultry#chicken, sweet#white sugar with the rice#grain rice in a pot.'\n",
    "    '''\n",
    "    output = sent\n",
    "    doc = nlp(sent)\n",
    "    for chunk in doc.noun_chunks:\n",
    "        food_matching = delexicalized(chunk.lemma_.replace('the ',''))\n",
    "        if food_matching:\n",
    "            output = output.replace(chunk.text.replace('the ',''), food_matching)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mix the pork#pork, poultry#chicken, sweet#white sugar with the rice#grain rice in a pot.'"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 55.9 ms\n"
     ]
    }
   ],
   "source": [
    "delexicalized_sent('Mix the porks, chicken, white sugar with the grain rice in a pot.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 36.8 ms\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import spacy\n",
    "class food_taxonomy:\n",
    "    def __init__(self, df):\n",
    "        ### \n",
    "        self.level3 = df.groupby([3])[1].apply(list).index.tolist()\n",
    "        self.gb = df.groupby([3])[1].apply(list)\n",
    "        self.level3_set = [set(ingr.split(' ')) for ingr in level3]\n",
    "        self.random = random\n",
    "        self.random.seed(2019)\n",
    "        self.spacy = spacy.load('en_core_web_lg')\n",
    "        \n",
    "    def delexicalized(self, exact_ingr):\n",
    "        '''\n",
    "        input: dic[9]['ny_ingredients']['exact'][0]\n",
    "        e.g. 'onion'\n",
    "        '''\n",
    "        matched = []\n",
    "        for ingr, ingr_set in zip(self.level3, self.level3_set):\n",
    "            if len(ingr_set) == len(ingr_set & set(exact_ingr.split(' '))):\n",
    "                matched += self.gb[ingr]\n",
    "        if matched:\n",
    "            return '%s#%s' % (self.random.sample(matched, 1)[0], exact_ingr)\n",
    "    \n",
    "    def delexicalized_sent(self, sent):\n",
    "        '''\n",
    "        For example\n",
    "        sent = 'Mix the porks, chicken, white sugar with the grain rice in a pot.'\n",
    "        delexicalized_sent(sent) = \n",
    "        'Mix the pork#pork, poultry#chicken, sweet#white sugar with the rice#grain rice in a pot.'\n",
    "        '''\n",
    "        output = sent\n",
    "        doc = self.spacy(sent)\n",
    "        for chunk in doc.noun_chunks:\n",
    "            food_matching = self.delexicalized(chunk.lemma_.replace('the ',''))\n",
    "            if food_matching:\n",
    "                output = output.replace(chunk.text.replace('the ',''), food_matching)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 16.1 s\n"
     ]
    }
   ],
   "source": [
    "model = food_taxonomy(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mix the pork#pork, poultry#chicken, sweet#white sugar with the spices#grain rice in a pot.'"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 61.7 ms\n"
     ]
    }
   ],
   "source": [
    "model.delexicalized_sent('Mix the porks, chicken, white sugar with the grain rice in a pot.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tater tot taco casserole']"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 28.6 ms\n"
     ]
    }
   ],
   "source": [
    "dic[388]['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
